{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare means\n",
    "\n",
    "For the 2017-18 Elveovervåkingsprogrammet, Øyvind would like to compare average concentrations for the 20 \"main\" rivers over two time periods: (i) 2013 to 2017 inclusive, and (ii) 2017 only. This procedure is complicated slightly by the OSPAR methodology for handling detection limits (described [here](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/rid_data_exploration.ipynb#2.3.2.-Limit-of-detection-values)).\n",
    "\n",
    "This notebook extracts all the water chemistry data for the stations of interest over the two time periods. It then calculates corrected and uncorrected mean values for each period, for each of the \"standard\" RID parameters.\n",
    "\n",
    " * **Uncorrected means**. The mean of the raw data for the time period, where detection limit values are assumed to be equal to the detection limit <br><br>\n",
    " \n",
    " * **Corrected means**. The mean of the raw data for the time period, where detection limit values are adjusted according to the [OSPAR methodology](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/rid_data_exploration.ipynb#2.3.2.-Limit-of-detection-values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "resa2_basic_path = (r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\Upload_Template'\n",
    "                    r'\\useful_resa2_code.py')\n",
    "resa2_basic = imp.load_source('useful_resa2_code', resa2_basic_path)\n",
    "engine, conn = resa2_basic.connect_to_resa2()\n",
    "\n",
    "# Import custom RID functions\n",
    "rid_func_path = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "                 r'\\Python\\rid\\notebooks\\useful_rid_code.py')\n",
    "rid = imp.load_source('useful_rid_code', rid_func_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. List of stations of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_name</th>\n",
       "      <th>old_rid_group</th>\n",
       "      <th>new_rid_group</th>\n",
       "      <th>ospar_region</th>\n",
       "      <th>station_type</th>\n",
       "      <th>nve_vassdrag_nr</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>utm_north</th>\n",
       "      <th>utm_east</th>\n",
       "      <th>utm_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29612</td>\n",
       "      <td>BUSEDRA</td>\n",
       "      <td>Drammenselva</td>\n",
       "      <td>rid_11</td>\n",
       "      <td>rid_20</td>\n",
       "      <td>SKAGERAK</td>\n",
       "      <td>R</td>\n",
       "      <td>012.A3</td>\n",
       "      <td>59.753995</td>\n",
       "      <td>10.008990</td>\n",
       "      <td>6624446.0</td>\n",
       "      <td>556695.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29779</td>\n",
       "      <td>FINEALT</td>\n",
       "      <td>Altaelva</td>\n",
       "      <td>rid_11</td>\n",
       "      <td>rid_20</td>\n",
       "      <td>LOFOTEN-BARENTS SEA</td>\n",
       "      <td>R</td>\n",
       "      <td>212.A0</td>\n",
       "      <td>69.900992</td>\n",
       "      <td>23.286977</td>\n",
       "      <td>7759686.0</td>\n",
       "      <td>586586.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29820</td>\n",
       "      <td>FINETAN</td>\n",
       "      <td>Tanaelva</td>\n",
       "      <td>rid_36</td>\n",
       "      <td>rid_20</td>\n",
       "      <td>LOFOTEN-BARENTS SEA</td>\n",
       "      <td>R</td>\n",
       "      <td>234.B41</td>\n",
       "      <td>70.229993</td>\n",
       "      <td>28.173988</td>\n",
       "      <td>7791949.0</td>\n",
       "      <td>544316.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29821</td>\n",
       "      <td>HOREVOS</td>\n",
       "      <td>Vosso(Bolstadelvi)</td>\n",
       "      <td>rid_11</td>\n",
       "      <td>rid_20</td>\n",
       "      <td>NORTH SEA</td>\n",
       "      <td>R</td>\n",
       "      <td>062.C1</td>\n",
       "      <td>60.647000</td>\n",
       "      <td>6.112000</td>\n",
       "      <td>6726970.0</td>\n",
       "      <td>342124.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29782</td>\n",
       "      <td>NOREVEF</td>\n",
       "      <td>Vefsna</td>\n",
       "      <td>rid_11</td>\n",
       "      <td>rid_20</td>\n",
       "      <td>NORWEGIAN SEA2</td>\n",
       "      <td>R</td>\n",
       "      <td>151.A4</td>\n",
       "      <td>65.749000</td>\n",
       "      <td>13.239000</td>\n",
       "      <td>7293064.0</td>\n",
       "      <td>419297.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id station_code        station_name old_rid_group new_rid_group  \\\n",
       "0       29612      BUSEDRA        Drammenselva        rid_11        rid_20   \n",
       "1       29779      FINEALT            Altaelva        rid_11        rid_20   \n",
       "2       29820      FINETAN            Tanaelva        rid_36        rid_20   \n",
       "3       29821      HOREVOS  Vosso(Bolstadelvi)        rid_11        rid_20   \n",
       "4       29782      NOREVEF              Vefsna        rid_11        rid_20   \n",
       "\n",
       "          ospar_region station_type nve_vassdrag_nr        lat        lon  \\\n",
       "0             SKAGERAK            R          012.A3  59.753995  10.008990   \n",
       "1  LOFOTEN-BARENTS SEA            R          212.A0  69.900992  23.286977   \n",
       "2  LOFOTEN-BARENTS SEA            R         234.B41  70.229993  28.173988   \n",
       "3            NORTH SEA            R          062.C1  60.647000   6.112000   \n",
       "4       NORWEGIAN SEA2            R          151.A4  65.749000  13.239000   \n",
       "\n",
       "   utm_north  utm_east  utm_zone  \n",
       "0  6624446.0  556695.0        32  \n",
       "1  7759686.0  586586.0        34  \n",
       "2  7791949.0  544316.0        35  \n",
       "3  6726970.0  342124.0        32  \n",
       "4  7293064.0  419297.0        33  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of stations of interest\n",
    "stn_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "            r'\\Data\\RID_Sites_List_2017-2020.xlsx')\n",
    "stn_df = pd.read_excel(stn_xlsx, sheet_name ='RID_20')\n",
    "\n",
    "stn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract water chemistry and adjust LOD values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    WARNING\n",
      "    The database contains duplicated values for some station-date-parameter combinations.\n",
      "    Only the most recent values will be used, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pars of interest\n",
    "par_list = ['SPM', 'TOC', 'PO4-P', 'TOTP', 'NO3-N', 'NH4-N', \n",
    "            'TOTN', 'SiO2', 'Ag', 'As', 'Pb', 'Cd', 'Cu', \n",
    "            'Zn', 'Ni', 'Cr', 'Hg']\n",
    "\n",
    "# Container for results\n",
    "df_list = []\n",
    "\n",
    "# Loop over stations\n",
    "for stn_id in stn_df['station_id'].values:\n",
    "    # Get raw data between 2013 and 2017\n",
    "    wc_df, dup_df = rid.extract_water_chem(stn_id, par_list, \n",
    "                                           '2013-01-01', '2017-12-31',\n",
    "                                           engine, plot=False)\n",
    "\n",
    "    # Calculate means for uncorrected data\n",
    "    uncor_df_1 = pd.DataFrame(wc_df.mean()).reset_index()\n",
    "    uncor_df_1.columns = ['par', 'uncor_mean_2013-17']\n",
    "    uncor_df_1['par'], uncor_df_1['unit'] = uncor_df_1['par'].str.split('_', 1).str\n",
    "    uncor_df_1 = uncor_df_1.query('unit != \"flag\"')\n",
    "    uncor_df_1['par'] = uncor_df_1['par'] + '_' + uncor_df_1['unit']\n",
    "    uncor_df_1.index = uncor_df_1['par']\n",
    "    del uncor_df_1['unit'], uncor_df_1['par']\n",
    "\n",
    "    # Apply LOD correction\n",
    "    wc_df = rid.adjust_lod_values(wc_df)\n",
    "\n",
    "    # Calculate means for corrected data\n",
    "    cor_df_1 = pd.DataFrame(wc_df.mean()).reset_index()\n",
    "    cor_df_1.columns = ['par', 'cor_mean_2013-17']\n",
    "    cor_df_1['par'], cor_df_1['unit'] = cor_df_1['par'].str.split('_', 1).str\n",
    "    cor_df_1 = cor_df_1.query('unit != \"flag\"')\n",
    "    cor_df_1['par'] = cor_df_1['par'] + '_' + cor_df_1['unit']\n",
    "    cor_df_1.index = cor_df_1['par']\n",
    "    del cor_df_1['unit'], cor_df_1['par']\n",
    "\n",
    "    # Get raw data for 2017\n",
    "    wc_df, dup_df = rid.extract_water_chem(stn_id, par_list, \n",
    "                                           '2017-01-01', '2017-12-31',\n",
    "                                           engine, plot=False)\n",
    "\n",
    "    # Calculate means for uncorrected data\n",
    "    uncor_df_2 = pd.DataFrame(wc_df.mean()).reset_index()\n",
    "    uncor_df_2.columns = ['par', 'uncor_mean_2017']\n",
    "    uncor_df_2['par'], uncor_df_2['unit'] = uncor_df_2['par'].str.split('_', 1).str\n",
    "    uncor_df_2 = uncor_df_2.query('unit != \"flag\"')\n",
    "    uncor_df_2['par'] = uncor_df_2['par'] + '_' + uncor_df_2['unit']\n",
    "    uncor_df_2.index = uncor_df_2['par']\n",
    "    del uncor_df_2['unit'], uncor_df_2['par']\n",
    "\n",
    "    # Apply LOD correction\n",
    "    wc_df = rid.adjust_lod_values(wc_df)\n",
    "\n",
    "    # Calculate means for corrected data\n",
    "    cor_df_2 = pd.DataFrame(wc_df.mean()).reset_index()\n",
    "    cor_df_2.columns = ['par', 'cor_mean_2017']\n",
    "    cor_df_2['par'], cor_df_2['unit'] = cor_df_2['par'].str.split('_', 1).str\n",
    "    cor_df_2 = cor_df_2.query('unit != \"flag\"')\n",
    "    cor_df_2['par'] = cor_df_2['par'] + '_' + cor_df_2['unit']\n",
    "    cor_df_2.index = cor_df_2['par']\n",
    "    del cor_df_2['unit'], cor_df_2['par']\n",
    "    \n",
    "    # Concatenate to single df\n",
    "    df = pd.concat([uncor_df_1, cor_df_1, uncor_df_2, cor_df_2], \n",
    "                   axis=1, \n",
    "                   sort=False)\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    # Tidy\n",
    "    df['station_id'] = stn_id\n",
    "    df = df[['station_id', 'par', 'uncor_mean_2013-17', \n",
    "             'cor_mean_2013-17', 'uncor_mean_2017', 'cor_mean_2017']]    \n",
    "    df_list.append(df)\n",
    "\n",
    "# Combine results\n",
    "df = pd.concat(df_list, axis=0, sort=False)\n",
    "\n",
    "# Join station details\n",
    "df = pd.merge(df,\n",
    "              stn_df[['station_id', 'station_code', 'station_name', \n",
    "                      'old_rid_group', 'new_rid_group']],\n",
    "              how='left',\n",
    "              on='station_id')\n",
    "df = df[['station_id', 'station_code', 'station_name', 'old_rid_group', \n",
    "         'new_rid_group', 'par', 'uncor_mean_2013-17', 'cor_mean_2013-17',\n",
    "         'uncor_mean_2017', 'cor_mean_2017']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_name</th>\n",
       "      <th>old_rid_group</th>\n",
       "      <th>new_rid_group</th>\n",
       "      <th>par</th>\n",
       "      <th>uncor_mean_2013-17</th>\n",
       "      <th>cor_mean_2013-17</th>\n",
       "      <th>uncor_mean_2017</th>\n",
       "      <th>cor_mean_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29612</td>\n",
       "      <td>BUSEDRA</td>\n",
       "      <td>Drammenselva</td>\n",
       "      <td>rid_11</td>\n",
       "      <td>rid_20</td>\n",
       "      <td>Ag_µg/l</td>\n",
       "      <td>0.026254</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29612</td>\n",
       "      <td>BUSEDRA</td>\n",
       "      <td>Drammenselva</td>\n",
       "      <td>rid_11</td>\n",
       "      <td>rid_20</td>\n",
       "      <td>As_µg/l</td>\n",
       "      <td>0.159686</td>\n",
       "      <td>0.159686</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29612</td>\n",
       "      <td>BUSEDRA</td>\n",
       "      <td>Drammenselva</td>\n",
       "      <td>rid_11</td>\n",
       "      <td>rid_20</td>\n",
       "      <td>Cd_µg/l</td>\n",
       "      <td>0.009189</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>0.008025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29612</td>\n",
       "      <td>BUSEDRA</td>\n",
       "      <td>Drammenselva</td>\n",
       "      <td>rid_11</td>\n",
       "      <td>rid_20</td>\n",
       "      <td>Cr_µg/l</td>\n",
       "      <td>0.193544</td>\n",
       "      <td>0.191544</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.142500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29612</td>\n",
       "      <td>BUSEDRA</td>\n",
       "      <td>Drammenselva</td>\n",
       "      <td>rid_11</td>\n",
       "      <td>rid_20</td>\n",
       "      <td>Cu_µg/l</td>\n",
       "      <td>0.827329</td>\n",
       "      <td>0.827329</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id station_code  station_name old_rid_group new_rid_group      par  \\\n",
       "0       29612      BUSEDRA  Drammenselva        rid_11        rid_20  Ag_µg/l   \n",
       "1       29612      BUSEDRA  Drammenselva        rid_11        rid_20  As_µg/l   \n",
       "2       29612      BUSEDRA  Drammenselva        rid_11        rid_20  Cd_µg/l   \n",
       "3       29612      BUSEDRA  Drammenselva        rid_11        rid_20  Cr_µg/l   \n",
       "4       29612      BUSEDRA  Drammenselva        rid_11        rid_20  Cu_µg/l   \n",
       "\n",
       "   uncor_mean_2013-17  cor_mean_2013-17  uncor_mean_2017  cor_mean_2017  \n",
       "0            0.026254          0.004269         0.002000       0.000000  \n",
       "1            0.159686          0.159686         0.152000       0.152000  \n",
       "2            0.009189          0.009172         0.008025       0.008025  \n",
       "3            0.193544          0.191544         0.142500       0.142500  \n",
       "4            0.827329          0.827329         0.687500       0.687500  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write output\n",
    "out_csv = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Results\\Loads_CSVs\\mean_chemistry_2013-17.csv')\n",
    "df.to_csv(out_csv, index=False, encoding='utf-8')\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
