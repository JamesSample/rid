{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import geopandas as gpd\n",
    "import geopandas.tools\n",
    "import matplotlib.pyplot as plt\n",
    "import nivapy3 as nivapy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import seaborn as sn\n",
    "import useful_rid_code as rid\n",
    "from shapely.geometry import Point\n",
    "from sqlalchemy import types\n",
    "\n",
    "sn.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process model input datasets (2020-21)\n",
    "\n",
    "Modelling for the RID programme makes use of the following input datasets:\n",
    "\n",
    " * **Avløp** (sewage and other drainage). These datasets are provided by **Gisle Berge at SSB** and are sub-divided into\n",
    "     * Large treatment works (\"store anlegg\"; ≥ 50 p.e.)\n",
    "     * Small treatment works (\"små anlegg\"; < 50 p.e.)\n",
    "     * Other environmental pollutants (\"miljøgifter\") <br><br>\n",
    "     \n",
    " * **Fiskeoppdret** (Fish farming). Provided by **Knut Johan Johnsen at Fiskeridirektoratet** <br><br>\n",
    " \n",
    " * **Industri** (industrial point sources). Provided by **Preben Danielsen at Miljødirektoratet** <br><br>\n",
    " \n",
    " * **Jordbruk** (land use and management activities). Provided by **Hans Olav Eggestad at NIBIO**\n",
    " \n",
    "In addition, an annual figure for the use of **copper in aquaculture** is provided by **Preben Danielsen at Miljødirektoratet**.\n",
    " \n",
    "The raw datasets must be restructured into a standardised format and added to the RESA2 database. Once in the database, they can be used to generate input files for TEOTIL2.\n",
    "\n",
    "This notebook processes the raw data and adds it to RESA2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Username:  ···\n",
      "Password:  ··············\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "# Connect to db\n",
    "engine = nivapy.da.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year of interest\n",
    "year = 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Store anlegg, Miljøgifter and Industri\n",
    "\n",
    "These three datasets are all treated similarly, and there is some duplication between the files. \n",
    "\n",
    " * The **store anlegg** dataset is in wide format. Copy and rename the file, then change the worksheet name to `store_anlegg_{year}`. The header must also be tidied (see example datasets from previous years) and blank rows at the end of the worksheet can be deleted <br><br>\n",
    " \n",
    " * The **miljøgifter** dataset is in wide format. Copy and rename the file, then change the worksheet name to `miljogifter_{year}`. Also check that column headings are the same as in previous years <br><br>\n",
    " \n",
    " * The **industri** dataset is in long format and usually contains data for multiple years. Copy and rename the file, then rename the worksheet to `industry_{year}`. Delete rows above the header and check the header is the same as in previous years. Remember to filter the data to **only include the year of interest** (i.e. delete rows for other years)\n",
    "\n",
    "The data in these files must be added to two tables in RESA2:\n",
    "\n",
    " * The site data must be added to `RESA2.RID_PUNKTKILDER`. Most of the sites should already be there, but occasionally new sites are added. Any new stations must be be assigned lat/lon co-ordinates and the appropriate \"regine\" catchment ID (the latter being most important). This usually requires geocoding plus co-ordinate conversions and/or a spatial join to determine catchment IDs. <br><br>\n",
    " \n",
    "    **Note:** As of 2017, many (>120) of the stations already in the database were missing regine IDs and many more (>3000) were missing co-ordinate information. John Rune says we have previously asked Miljødirektoratet about this, but they have not been able to provide the missing data. During data processing for 2019/20, I noticed that some of the missing co-ordinate information *was* provided in more recent data submissions. However, if a site is already in the database (with missing spatial information), it will not be updated even if co-ordinates are provided in later years. In 2020, I created a notebook ([here](https://nbviewer.org/github/JamesSample/rid/blob/master/notebooks/update_renseanlegg_coords.ipynb)) to update co-ordinates where possible based on data submitted since 2016. This has reduced the number of sites without regine IDs to 30 (`SELECT count(*) from resa2.rid_punktkilder WHERE regine IS NULL;`). I have also modified the code in this notebook so that sites are only added to `RESA2.RID_PUNKTKILDER` when co-ordinate information is available and a regine ID has been successfully assigned. This usually means that some sites in the submission for each year must be ignored, but the benefit is that if the same sites are reported with complete information at a later date, they can then be added to the database and processed correctly. This seems preferable to adding incomplete data that cannot be used. <br><br>\n",
    " \n",
    " * The chemistry data for each site must be extracted and converted to \"long\" format, then added to `RESA2.RID_PUNKTKILDER_INPAR_VALUES`. Parameter IDs etc. are taken from `RESA2.RID_PUNKTKILDER_INPAR_DEF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw (tidied) data\n",
    "\n",
    "# Store anlegg\n",
    "in_xlsx = f\"../../../Data/point_data_{year}/avlop_stor_anlegg_{year}_raw.xlsx\"\n",
    "stan_df = pd.read_excel(in_xlsx, sheet_name=f\"store_anlegg_{year}\")\n",
    "\n",
    "# Miljøgifter\n",
    "in_xlsx = f\"../../../Data/point_data_{year}/avlop_miljogifter_{year}_raw.xlsx\"\n",
    "milo_df = pd.read_excel(in_xlsx, sheet_name=f\"miljogifter_{year}\")\n",
    "\n",
    "# Industri\n",
    "in_xlsx = f\"../../../Data/point_data_{year}/industri_{year}_raw.xlsx\"\n",
    "ind_df = pd.read_excel(in_xlsx, sheet_name=f\"industry_{year}\")\n",
    "\n",
    "# Drop blank rows\n",
    "stan_df.dropna(how=\"all\", inplace=True)\n",
    "milo_df.dropna(how=\"all\", inplace=True)\n",
    "ind_df.dropna(how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Basic data checking\n",
    "\n",
    "All of the store anlegg and miljøgifter sites are classified as `RENSEANLEGG` in the `TYPE` column of `RESA2.RID_PUNKTKILDER`; industri sites are labeled `INDUSTRI`.\n",
    "\n",
    "The code below adds `TYPE` columns, merges site data from different sources, converts UTM co-ordinates to WGS84 decimal degrees and identifies sites not already in the database. Issues identified below (e.g. missing co-ordinates) should be corrected if possible before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following 46 locations are not already in the database:\n",
      "         anlegg_nr                                  anlegg_navn\n",
      "1247      0429AL10                  Camp Rødsmoen, avløpsanlegg\n",
      "1389      0540AL13                       Ølnesseter renseanlegg\n",
      "987       0604AL92              Skrim - Omholtfjell renseanlegg\n",
      "1107      0618AL22                          Markegardslia avløp\n",
      "1558      1029AL13             Lande Eiendom Invest renseanlegg\n",
      "49    1101.0126.01                                Prima Protein\n",
      "63        1102AL24                                      Breivik\n",
      "92    1108.0247.01                 Hermod Teigen, Foss-Eikeland\n",
      "1742      1221AL27                                 Sæverhagen 2\n",
      "1789      1224AL39                                   Eidsvik SA\n",
      "552       1557AL14                                       Søvika\n",
      "643       1579AL00                                       Vevang\n",
      "733       1820AL13                          Bærøya avløpsanlegg\n",
      "734       1820AL14                        Offersøy avløpsanlegg\n",
      "735       1820AL15                            Siva avløpsanlegg\n",
      "545   3001.0104.01  VPK Packaging avd Berg - tidl. VPK Peterson\n",
      "730   3024.0287.01                  Franskleiv skiskytteranlegg\n",
      "1031      3024AL00                   Øvre skutuset avløpsanlegg\n",
      "969       3024AL00                   Øvre skutuset avløpsanlegg\n",
      "1098      3041AL00                         Storestølen skutuset\n",
      "1099      3041AL01                                 Sjauset RA 1\n",
      "1100      3041AL02                                  Sjauset RA2\n",
      "1110      3042AL00                              Muren hyttefelt\n",
      "1111      3042AL01                              Bergastølslåtta\n",
      "1112      3042AL02                                 Gravarsletto\n",
      "959       3043AL00                       Lyserhøgda renseanlegg\n",
      "1128      3043AL00                       Lyserhøgda renseanlegg\n",
      "1140      3044AL00                                Nedre Grøolia\n",
      "824   3407.0144.01                          Hunton Isolasjon AS\n",
      "878   3420.0027.01      Curida AS, Elverum (farmasøytisk prod.)\n",
      "1390      3449AL00                                Tollefsrud RA\n",
      "949   3802.0101.01                           Bonden Grønthandel\n",
      "1428      3802AL00                            Thorrud hyttefelt\n",
      "1452      3805AL00                   Siljuvannsåsen renseanlegg\n",
      "2277      5014AL01                                     Sandvika\n",
      "2278      5014AL02                                       Dyrvik\n",
      "2279      5014AL03                                    Mausund 1\n",
      "2280      5014AL04                                     Rabben 2\n",
      "2281      5014AL05                                   Nordskag 1\n",
      "2282      5014AL06                 Nordhammervik Industriområde\n",
      "2283      5014AL07                                       Skagan\n",
      "2284      5014AL08                              Uttian panorama\n",
      "1818  5421.0208.01                              Nergård Sild AS\n",
      "1824  5427.0030.01         Lerøy Aurora lakseslakteri, Skjervøy\n",
      "1831  5441.0021.01                        Tine Meieri avd. Tana\n",
      "1836  5444.0088.01          Kirkenes processing - lakseslakteri\n",
      "\n",
      "The following 46 locations do not have co-ordinates in this year's data:\n",
      "         anlegg_nr                           anlegg_navn\n",
      "1070      0612AL11                   Onsakervika camping\n",
      "1107      0618AL22                   Markegardslia avløp\n",
      "1122      0619AL76                 Skrindehaugen H23-H21\n",
      "1174      0631AL36                Neset Skysstasjon r.a.\n",
      "1499      0827AL07                Russmarken Renseanlegg\n",
      "11        1103AL26                                Vassøy\n",
      "96        1114AL20  Grønabakkane - Stavtjørn renseanlegg\n",
      "181       1146AL35          Tysvær renseanlegg Gismarvik\n",
      "1843      1238AL19        Tolo renseanlegg - Norheimsund\n",
      "1895      1244AL04                                   Vik\n",
      "1896      1244AL05                             Norevågen\n",
      "1897      1244AL06                            Bekkjarvik\n",
      "1692      1439AL06                               Bryggja\n",
      "608       1524AL00                                 Sylte\n",
      "609       1524AL04                          Tafjord vest\n",
      "610       1524AL07                  Eidsdal v/ fergekaia\n",
      "472       1532AL20                           GO5 - Alnes\n",
      "643       1579AL00                                Vevang\n",
      "724       1820AL00                   Steiro avløpsanlegg\n",
      "729       1820AL07                   Austbø avløpsanlegg\n",
      "733       1820AL13                   Bærøya avløpsanlegg\n",
      "734       1820AL14                 Offersøy avløpsanlegg\n",
      "735       1820AL15                     Siva avløpsanlegg\n",
      "529   2311.0001.01         Slakteskipet Norwegian Gannet\n",
      "1031      3024AL00            Øvre skutuset avløpsanlegg\n",
      "969       3024AL00            Øvre skutuset avløpsanlegg\n",
      "1098      3041AL00                  Storestølen skutuset\n",
      "1099      3041AL01                          Sjauset RA 1\n",
      "1100      3041AL02                           Sjauset RA2\n",
      "1110      3042AL00                       Muren hyttefelt\n",
      "1111      3042AL01                       Bergastølslåtta\n",
      "1112      3042AL02                          Gravarsletto\n",
      "1128      3043AL00                Lyserhøgda renseanlegg\n",
      "959       3043AL00                Lyserhøgda renseanlegg\n",
      "1140      3044AL00                         Nedre Grøolia\n",
      "1390      3449AL00                         Tollefsrud RA\n",
      "1428      3802AL00                     Thorrud hyttefelt\n",
      "1452      3805AL00            Siljuvannsåsen renseanlegg\n",
      "2277      5014AL01                              Sandvika\n",
      "2278      5014AL02                                Dyrvik\n",
      "2279      5014AL03                             Mausund 1\n",
      "2280      5014AL04                              Rabben 2\n",
      "2281      5014AL05                            Nordskag 1\n",
      "2282      5014AL06          Nordhammervik Industriområde\n",
      "2283      5014AL07                                Skagan\n",
      "2284      5014AL08                       Uttian panorama\n",
      "\n",
      "The following 27 locations are not in the database and do not have co-ordinates (and therefore must be ignored):\n",
      "     anlegg_nr                   anlegg_navn\n",
      "1107  0618AL22           Markegardslia avløp\n",
      "643   1579AL00                        Vevang\n",
      "733   1820AL13           Bærøya avløpsanlegg\n",
      "734   1820AL14         Offersøy avløpsanlegg\n",
      "735   1820AL15             Siva avløpsanlegg\n",
      "1031  3024AL00    Øvre skutuset avløpsanlegg\n",
      "969   3024AL00    Øvre skutuset avløpsanlegg\n",
      "1098  3041AL00          Storestølen skutuset\n",
      "1099  3041AL01                  Sjauset RA 1\n",
      "1100  3041AL02                   Sjauset RA2\n",
      "1110  3042AL00               Muren hyttefelt\n",
      "1111  3042AL01               Bergastølslåtta\n",
      "1112  3042AL02                  Gravarsletto\n",
      "1128  3043AL00        Lyserhøgda renseanlegg\n",
      "959   3043AL00        Lyserhøgda renseanlegg\n",
      "1140  3044AL00                 Nedre Grøolia\n",
      "1390  3449AL00                 Tollefsrud RA\n",
      "1428  3802AL00             Thorrud hyttefelt\n",
      "1452  3805AL00    Siljuvannsåsen renseanlegg\n",
      "2277  5014AL01                      Sandvika\n",
      "2278  5014AL02                        Dyrvik\n",
      "2279  5014AL03                     Mausund 1\n",
      "2280  5014AL04                      Rabben 2\n",
      "2281  5014AL05                    Nordskag 1\n",
      "2282  5014AL06  Nordhammervik Industriområde\n",
      "2283  5014AL07                        Skagan\n",
      "2284  5014AL08               Uttian panorama\n"
     ]
    }
   ],
   "source": [
    "# Add TYPE cols\n",
    "stan_df[\"TYPE\"] = \"RENSEANLEGG\"\n",
    "milo_df[\"TYPE\"] = \"RENSEANLEGG\"\n",
    "ind_df[\"TYPE\"] = \"INDUSTRI\"\n",
    "\n",
    "# Get just stn info from each df\n",
    "stan_loc = stan_df[\n",
    "    [\"ANLEGGSNR\", \"ANLEGGSNAVN\", \"Kommunenr\", \"TYPE\", \"Sone\", \"UTM_E\", \"UTM_N\"]\n",
    "].copy()\n",
    "\n",
    "milo_loc = milo_df[\n",
    "    [\"ANLEGGSNR\", \"ANLEGGSNAVN\", \"KOMMUNE_NR\", \"TYPE\", \"SONEBELTE\", \"UTMOST\", \"UTMNORD\"]\n",
    "].copy()\n",
    "\n",
    "ind_loc = ind_df[\n",
    "    [\n",
    "        \"Anleggsnr\",\n",
    "        \"Anleggsnavn\",\n",
    "        \"Komm.nr\",\n",
    "        \"TYPE\",\n",
    "        \"Geografisk Longitude\",\n",
    "        \"Geografisk Latitude\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "\n",
    "# Rename cols\n",
    "stan_loc.columns = [\n",
    "    \"anlegg_nr\",\n",
    "    \"anlegg_navn\",\n",
    "    \"komm_no\",\n",
    "    \"TYPE\",\n",
    "    \"zone\",\n",
    "    \"east\",\n",
    "    \"north\",\n",
    "]\n",
    "milo_loc.columns = [\n",
    "    \"anlegg_nr\",\n",
    "    \"anlegg_navn\",\n",
    "    \"komm_no\",\n",
    "    \"TYPE\",\n",
    "    \"zone\",\n",
    "    \"east\",\n",
    "    \"north\",\n",
    "]\n",
    "ind_loc.columns = [\"anlegg_nr\", \"anlegg_navn\", \"komm_no\", \"TYPE\", \"lon\", \"lat\"]\n",
    "\n",
    "# Drop duplicates\n",
    "stan_loc.drop_duplicates(inplace=True)\n",
    "milo_loc.drop_duplicates(inplace=True)\n",
    "ind_loc.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert UTM Zone col to Pandas' nullable integer data type\n",
    "# (because proj. now complains about float UTM zones)\n",
    "stan_loc[\"zone\"] = stan_loc[\"zone\"].astype(pd.Int64Dtype())\n",
    "milo_loc[\"zone\"] = milo_loc[\"zone\"].astype(pd.Int64Dtype())\n",
    "\n",
    "# Convert UTM to lat/lon\n",
    "# \"Industri\" data is already in dd\n",
    "stan_loc = nivapy.spatial.utm_to_wgs84_dd(stan_loc, \"zone\", \"east\", \"north\")\n",
    "milo_loc = nivapy.spatial.utm_to_wgs84_dd(milo_loc, \"zone\", \"east\", \"north\")\n",
    "\n",
    "# Remove UTM data\n",
    "del stan_loc[\"zone\"], stan_loc[\"east\"], stan_loc[\"north\"]\n",
    "del milo_loc[\"zone\"], milo_loc[\"east\"], milo_loc[\"north\"]\n",
    "\n",
    "# Combine into single df\n",
    "loc_df = pd.concat([stan_loc, milo_loc, ind_loc], axis=0, sort=True)\n",
    "\n",
    "# The same site can be in multiple files, so drop duplicates\n",
    "loc_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Kommune nr. should be a 4 char string, not a float\n",
    "fmt = lambda x: \"%04d\" % x\n",
    "loc_df[\"komm_no\"] = loc_df[\"komm_no\"].apply(fmt)\n",
    "\n",
    "# Check ANLEGG_NR is unique\n",
    "assert loc_df.index.duplicated().all() == False, 'Some \"ANLEGGSNRs\" are duplicated.'\n",
    "\n",
    "# Check if any sites are not already in db\n",
    "sql = \"SELECT UNIQUE(ANLEGG_NR) FROM resa2.rid_punktkilder\"\n",
    "annr_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "not_in_db = set(loc_df[\"anlegg_nr\"].values) - set(annr_df[\"anlegg_nr\"].values)\n",
    "not_in_db_df = loc_df[loc_df[\"anlegg_nr\"].isin(list(not_in_db))][\n",
    "    [\"anlegg_nr\", \"anlegg_navn\"]\n",
    "].sort_values(\"anlegg_nr\")\n",
    "no_coords_df = loc_df.query(\"(lat!=lat) or (lon!=lon)\")[\n",
    "    [\"anlegg_nr\", \"anlegg_navn\"]\n",
    "].sort_values(\"anlegg_nr\")\n",
    "not_in_db_no_coords_df = not_in_db_df[\n",
    "    not_in_db_df[\"anlegg_nr\"].isin(no_coords_df[\"anlegg_nr\"])\n",
    "].sort_values(\"anlegg_nr\")\n",
    "\n",
    "print(f\"The following {len(not_in_db_df)} locations are not already in the database:\")\n",
    "print(not_in_db_df)\n",
    "\n",
    "print(\n",
    "    f\"\\nThe following {len(no_coords_df)} locations do not have co-ordinates \"\n",
    "    \"in this year's data:\"\n",
    ")\n",
    "print(no_coords_df)\n",
    "\n",
    "print(\n",
    "    f\"\\nThe following {len(not_in_db_no_coords_df)} locations are not in the \"\n",
    "    \"database and do not have co-ordinates (and therefore must be ignored):\"\n",
    ")\n",
    "print(not_in_db_no_coords_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Identify Regine Vassdragsnummer\n",
    "\n",
    "The shapefile here:\n",
    "\n",
    "    K:/Kart/Regine_2006/RegMinsteF.shp\n",
    "\n",
    "shows locations for all the regine catchments used by TEOTIL (see e-mail from John Rune received 29/06/2017 at 17.26). I've copied this file locally here:\n",
    "\n",
    "    ../../../Data/gis/shapefiles/RegMinsteF.shp\n",
    "\n",
    "and re-projected it to WGS84 geographic co-ordinates. The new file is called `reg_minste_f_wgs84.shp`.\n",
    "\n",
    "The code cell below identifies which regine polygon each point is located in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Not all sites have complete co-ordinate information. These rows will be dropped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>anlegg_navn</th>\n",
       "      <th>anlegg_nr</th>\n",
       "      <th>komm_no</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>VASSDRAGNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Bekkelaget renseanlegg med tilførselstuneller ...</td>\n",
       "      <td>0301AL01</td>\n",
       "      <td>0301</td>\n",
       "      <td>59.882995</td>\n",
       "      <td>10.767014</td>\n",
       "      <td>006.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Mariholtet renseanlegg</td>\n",
       "      <td>0301AL14</td>\n",
       "      <td>0301</td>\n",
       "      <td>59.891822</td>\n",
       "      <td>10.906905</td>\n",
       "      <td>002.CBB5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Tryvannsstua renseanlegg</td>\n",
       "      <td>0301AL19</td>\n",
       "      <td>0301</td>\n",
       "      <td>59.997898</td>\n",
       "      <td>10.663006</td>\n",
       "      <td>007.A0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Grefsenkollen renseanlegg</td>\n",
       "      <td>0301AL27</td>\n",
       "      <td>0301</td>\n",
       "      <td>59.958846</td>\n",
       "      <td>10.803291</td>\n",
       "      <td>006.A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Kobberhaugshytta</td>\n",
       "      <td>0301AL30</td>\n",
       "      <td>0301</td>\n",
       "      <td>60.036105</td>\n",
       "      <td>10.663652</td>\n",
       "      <td>007.B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TYPE                                        anlegg_navn anlegg_nr  \\\n",
       "0  RENSEANLEGG  Bekkelaget renseanlegg med tilførselstuneller ...  0301AL01   \n",
       "1  RENSEANLEGG                             Mariholtet renseanlegg  0301AL14   \n",
       "2  RENSEANLEGG                           Tryvannsstua renseanlegg  0301AL19   \n",
       "3  RENSEANLEGG                          Grefsenkollen renseanlegg  0301AL27   \n",
       "4  RENSEANLEGG                                   Kobberhaugshytta  0301AL30   \n",
       "\n",
       "  komm_no        lat        lon VASSDRAGNR  \n",
       "0    0301  59.882995  10.767014     006.21  \n",
       "1    0301  59.891822  10.906905   002.CBB5  \n",
       "2    0301  59.997898  10.663006     007.A0  \n",
       "3    0301  59.958846  10.803291     006.A3  \n",
       "4    0301  60.036105  10.663652     007.B1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to Regine catchment shapefile\n",
    "reg_shp_path = r\"../../../Data/gis/shapefiles/reg_minste_f_wgs84.shp\"\n",
    "\n",
    "# Spatial join\n",
    "loc_df = nivapy.spatial.identify_point_in_polygon(\n",
    "    loc_df, reg_shp_path, \"anlegg_nr\", \"VASSDRAGNR\", \"lat\", \"lon\"\n",
    ")\n",
    "\n",
    "loc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Restructuring site data\n",
    "\n",
    "Rename columns to match RESA2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>ANLEGG_NR</th>\n",
       "      <th>ANLEGG_NAVN</th>\n",
       "      <th>KNO</th>\n",
       "      <th>REGINE</th>\n",
       "      <th>LON_UTL</th>\n",
       "      <th>LAT_UTL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>1102AL24</td>\n",
       "      <td>Breivik</td>\n",
       "      <td>1108</td>\n",
       "      <td>031.A3F</td>\n",
       "      <td>6.649710</td>\n",
       "      <td>58.997915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>1557AL14</td>\n",
       "      <td>Søvika</td>\n",
       "      <td>1557</td>\n",
       "      <td>108.223</td>\n",
       "      <td>7.599410</td>\n",
       "      <td>62.932531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0604AL92</td>\n",
       "      <td>Skrim - Omholtfjell renseanlegg</td>\n",
       "      <td>3006</td>\n",
       "      <td>015.C6B</td>\n",
       "      <td>9.759300</td>\n",
       "      <td>59.505362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0429AL10</td>\n",
       "      <td>Camp Rødsmoen, avløpsanlegg</td>\n",
       "      <td>3422</td>\n",
       "      <td>002.JB4</td>\n",
       "      <td>11.462672</td>\n",
       "      <td>61.201083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0540AL13</td>\n",
       "      <td>Ølnesseter renseanlegg</td>\n",
       "      <td>3449</td>\n",
       "      <td>012.HAZ</td>\n",
       "      <td>9.469820</td>\n",
       "      <td>60.781269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>1029AL13</td>\n",
       "      <td>Lande Eiendom Invest renseanlegg</td>\n",
       "      <td>4205</td>\n",
       "      <td>023.1</td>\n",
       "      <td>7.413042</td>\n",
       "      <td>58.009407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>1221AL27</td>\n",
       "      <td>Sæverhagen 2</td>\n",
       "      <td>4614</td>\n",
       "      <td>044.31</td>\n",
       "      <td>5.527282</td>\n",
       "      <td>59.799517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>1224AL39</td>\n",
       "      <td>Eidsvik SA</td>\n",
       "      <td>4617</td>\n",
       "      <td>042.94</td>\n",
       "      <td>5.685610</td>\n",
       "      <td>59.790565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>INDUSTRI</td>\n",
       "      <td>1101.0126.01</td>\n",
       "      <td>Prima Protein</td>\n",
       "      <td>1101</td>\n",
       "      <td>027.4</td>\n",
       "      <td>5.978354</td>\n",
       "      <td>58.438394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>INDUSTRI</td>\n",
       "      <td>1108.0247.01</td>\n",
       "      <td>Hermod Teigen, Foss-Eikeland</td>\n",
       "      <td>1108</td>\n",
       "      <td>028.B</td>\n",
       "      <td>5.734317</td>\n",
       "      <td>58.801950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>INDUSTRI</td>\n",
       "      <td>3001.0104.01</td>\n",
       "      <td>VPK Packaging avd Berg - tidl. VPK Peterson</td>\n",
       "      <td>3001</td>\n",
       "      <td>002.111Z</td>\n",
       "      <td>11.271744</td>\n",
       "      <td>59.133293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>INDUSTRI</td>\n",
       "      <td>3024.0287.01</td>\n",
       "      <td>Franskleiv skiskytteranlegg</td>\n",
       "      <td>3024</td>\n",
       "      <td>008.2Z</td>\n",
       "      <td>10.420466</td>\n",
       "      <td>59.886279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>INDUSTRI</td>\n",
       "      <td>3420.0027.01</td>\n",
       "      <td>Curida AS, Elverum (farmasøytisk prod.)</td>\n",
       "      <td>3420</td>\n",
       "      <td>002.H5</td>\n",
       "      <td>11.555479</td>\n",
       "      <td>60.905831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>INDUSTRI</td>\n",
       "      <td>3802.0101.01</td>\n",
       "      <td>Bonden Grønthandel</td>\n",
       "      <td>3802</td>\n",
       "      <td>013.B0</td>\n",
       "      <td>10.231688</td>\n",
       "      <td>59.629412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>INDUSTRI</td>\n",
       "      <td>5421.0208.01</td>\n",
       "      <td>Nergård Sild AS</td>\n",
       "      <td>5421</td>\n",
       "      <td>195.7</td>\n",
       "      <td>17.487831</td>\n",
       "      <td>69.495807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>INDUSTRI</td>\n",
       "      <td>5427.0030.01</td>\n",
       "      <td>Lerøy Aurora lakseslakteri, Skjervøy</td>\n",
       "      <td>5427</td>\n",
       "      <td>206.74</td>\n",
       "      <td>20.989503</td>\n",
       "      <td>70.036109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>INDUSTRI</td>\n",
       "      <td>5441.0021.01</td>\n",
       "      <td>Tine Meieri avd. Tana</td>\n",
       "      <td>5441</td>\n",
       "      <td>234.B30</td>\n",
       "      <td>28.171728</td>\n",
       "      <td>70.202167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>INDUSTRI</td>\n",
       "      <td>5444.0088.01</td>\n",
       "      <td>Kirkenes processing - lakseslakteri</td>\n",
       "      <td>5444</td>\n",
       "      <td>246.52</td>\n",
       "      <td>30.108253</td>\n",
       "      <td>69.732579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TYPE     ANLEGG_NR                                  ANLEGG_NAVN  \\\n",
       "63    RENSEANLEGG      1102AL24                                      Breivik   \n",
       "552   RENSEANLEGG      1557AL14                                       Søvika   \n",
       "987   RENSEANLEGG      0604AL92              Skrim - Omholtfjell renseanlegg   \n",
       "1247  RENSEANLEGG      0429AL10                  Camp Rødsmoen, avløpsanlegg   \n",
       "1389  RENSEANLEGG      0540AL13                       Ølnesseter renseanlegg   \n",
       "1560  RENSEANLEGG      1029AL13             Lande Eiendom Invest renseanlegg   \n",
       "1744  RENSEANLEGG      1221AL27                                 Sæverhagen 2   \n",
       "1791  RENSEANLEGG      1224AL39                                   Eidsvik SA   \n",
       "2745     INDUSTRI  1101.0126.01                                Prima Protein   \n",
       "2755     INDUSTRI  1108.0247.01                 Hermod Teigen, Foss-Eikeland   \n",
       "2850     INDUSTRI  3001.0104.01  VPK Packaging avd Berg - tidl. VPK Peterson   \n",
       "2879     INDUSTRI  3024.0287.01                  Franskleiv skiskytteranlegg   \n",
       "2912     INDUSTRI  3420.0027.01      Curida AS, Elverum (farmasøytisk prod.)   \n",
       "2930     INDUSTRI  3802.0101.01                           Bonden Grønthandel   \n",
       "3109     INDUSTRI  5421.0208.01                              Nergård Sild AS   \n",
       "3113     INDUSTRI  5427.0030.01         Lerøy Aurora lakseslakteri, Skjervøy   \n",
       "3115     INDUSTRI  5441.0021.01                        Tine Meieri avd. Tana   \n",
       "3116     INDUSTRI  5444.0088.01          Kirkenes processing - lakseslakteri   \n",
       "\n",
       "       KNO    REGINE    LON_UTL    LAT_UTL  \n",
       "63    1108   031.A3F   6.649710  58.997915  \n",
       "552   1557   108.223   7.599410  62.932531  \n",
       "987   3006   015.C6B   9.759300  59.505362  \n",
       "1247  3422   002.JB4  11.462672  61.201083  \n",
       "1389  3449   012.HAZ   9.469820  60.781269  \n",
       "1560  4205     023.1   7.413042  58.009407  \n",
       "1744  4614    044.31   5.527282  59.799517  \n",
       "1791  4617    042.94   5.685610  59.790565  \n",
       "2745  1101     027.4   5.978354  58.438394  \n",
       "2755  1108     028.B   5.734317  58.801950  \n",
       "2850  3001  002.111Z  11.271744  59.133293  \n",
       "2879  3024    008.2Z  10.420466  59.886279  \n",
       "2912  3420    002.H5  11.555479  60.905831  \n",
       "2930  3802    013.B0  10.231688  59.629412  \n",
       "3109  5421     195.7  17.487831  69.495807  \n",
       "3113  5427    206.74  20.989503  70.036109  \n",
       "3115  5441   234.B30  28.171728  70.202167  \n",
       "3116  5444    246.52  30.108253  69.732579  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename other cols to match RESA2\n",
    "loc_df[\"ANLEGG_NR\"] = loc_df[\"anlegg_nr\"]\n",
    "loc_df[\"ANLEGG_NAVN\"] = loc_df[\"anlegg_navn\"]\n",
    "loc_df[\"KNO\"] = loc_df[\"komm_no\"]\n",
    "loc_df[\"REGINE\"] = loc_df[\"VASSDRAGNR\"]\n",
    "loc_df[\"LON_UTL\"] = loc_df[\"lon\"]\n",
    "loc_df[\"LAT_UTL\"] = loc_df[\"lat\"]\n",
    "\n",
    "del loc_df[\"anlegg_nr\"], loc_df[\"anlegg_navn\"], loc_df[\"komm_no\"]\n",
    "del loc_df[\"VASSDRAGNR\"], loc_df[\"lon\"], loc_df[\"lat\"]\n",
    "\n",
    "# Get details for sites not already in db\n",
    "loc_upld = loc_df[loc_df[\"ANLEGG_NR\"].isin(list(not_in_db))].copy()\n",
    "\n",
    "# Drop rows where 'regine' is NaN (usually because of missing co-ordinates).\n",
    "# In the past, all rows have been added, leading to sites in the database \n",
    "# without co-ordinates. These then do not get updated if co-ordinates are \n",
    "# provided in later years. It is therefore better to only add sites with\n",
    "# co-ordinates, as sites with missing data this year may be completed in\n",
    "# subsequent years\n",
    "loc_upld.dropna(subset=['REGINE'], inplace=True)\n",
    "\n",
    "loc_upld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_PUNKTKILDER\n",
    "# loc_upld.to_sql('rid_punktkilder', con=engine, schema='resa2',\n",
    "#                if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Restructuring values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Anlegg\n",
    "# Get cols of interest\n",
    "stan_vals = stan_df[[\"ANLEGGSNR\", \"MENGDE_P_UT_kg\", \"MENGDE_N_UT_kg\"]]\n",
    "\n",
    "# In RESA2.RID_PUNKTKILDER_INPAR_DEF, N is par_id 44 and P par_id 45\n",
    "stan_vals.columns = [\"ANLEGG_NR\", 45, 44]\n",
    "\n",
    "# Melt to \"long\" format\n",
    "stan_vals = pd.melt(\n",
    "    stan_vals,\n",
    "    id_vars=\"ANLEGG_NR\",\n",
    "    value_vars=[45, 44],\n",
    "    var_name=\"INP_PAR_ID\",\n",
    "    value_name=\"VALUE\",\n",
    ")\n",
    "\n",
    "# Drop NaN values\n",
    "stan_vals.dropna(how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as I can tell from exploring the 2015 data in the database, the main columns of interest for Miljøgifter are given in `milo_dict`, below, together with the corresponding parameter IDs from `RESA2.RID_PUNKTKILDER_INPAR_DEF`. This hard-coding is a bit messy, but I can't see any database table providing a nice lookup between these values, so they're included here for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miljøgifter\n",
    "# Get cols of interest\n",
    "milo_dict = {\n",
    "    \"MILJOGIFTHG2\": 16,\n",
    "    \"MILJOGIFTPAH2\": 48,\n",
    "    \"MILJOGIFTPCB2\": 30,\n",
    "    \"MILJOGIFTCD2\": 8,\n",
    "    \"MILJOGIFTDEHP2\": 119,\n",
    "    \"MILJOGIFTAS2\": 2,\n",
    "    \"MILJOGIFTCR2\": 10,\n",
    "    \"MILJOGIFTPB2\": 28,\n",
    "    \"MILJOGIFTNI2\": 25,\n",
    "    \"MILJOGIFTCU2\": 15,\n",
    "    \"MILJOGIFTZN2\": 38,\n",
    "    \"KONSMENGDTOTP10\": 45,\n",
    "    \"KONSMENGDTOTN10\": 44,\n",
    "    \"KONSMENGDSS10\": 46,\n",
    "    \"ANLEGGSNR\": \"ANLEGG_NR\",\n",
    "}  # Make headings match RESA\n",
    "\n",
    "milo_vals = milo_df[milo_dict.keys()]\n",
    "\n",
    "# Get par IDs from dict\n",
    "milo_vals.columns = [milo_dict[i] for i in milo_vals.columns]\n",
    "\n",
    "# Melt to \"long\" format\n",
    "milo_vals = pd.melt(\n",
    "    milo_vals, id_vars=\"ANLEGG_NR\", var_name=\"INP_PAR_ID\", value_name=\"VALUE\"\n",
    ")\n",
    "\n",
    "# Drop NaN values\n",
    "milo_vals.dropna(how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The industry data is already in \"long\" format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9348/580307874.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ind_vals[\"unit\"] = ind_vals[\"unit\"].str.capitalize()\n"
     ]
    }
   ],
   "source": [
    "# Industri\n",
    "# Get cols of interest\n",
    "ind_vals = ind_df[[\"Anleggsnr\", \"Komp.kode\", \"Mengde\", \"Enhet\"]]\n",
    "ind_vals.columns = [\"anlegg_nr\", \"name\", \"value\", \"unit\"]\n",
    "\n",
    "# Get par defs from db\n",
    "# Check if any sites are not already in db\n",
    "sql = \"SELECT * \" \"FROM resa2.rid_punktkilder_inpar_def\"\n",
    "par_df = pd.read_sql_query(sql, engine)\n",
    "del par_df[\"descr\"]\n",
    "\n",
    "# Convert all units to capitals\n",
    "ind_vals[\"unit\"] = ind_vals[\"unit\"].str.capitalize()\n",
    "par_df[\"unit\"] = par_df[\"unit\"].str.capitalize()\n",
    "\n",
    "# Join\n",
    "ind_vals = pd.merge(ind_vals, par_df, how=\"left\", on=[\"name\", \"unit\"])\n",
    "\n",
    "# Some parameters that are not of interest are not matched\n",
    "# Drop these\n",
    "ind_vals.dropna(how=\"any\", inplace=True)\n",
    "\n",
    "# Get just cols of interest\n",
    "ind_vals = ind_vals[[\"anlegg_nr\", \"in_pid\", \"value\"]]\n",
    "\n",
    "# Rename for db\n",
    "ind_vals.columns = [\"ANLEGG_NR\", \"INP_PAR_ID\", \"VALUE\"]\n",
    "\n",
    "# Convert col types\n",
    "ind_vals[\"INP_PAR_ID\"] = ind_vals[\"INP_PAR_ID\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANLEGG_NR</th>\n",
       "      <th>INP_PAR_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101AL01</td>\n",
       "      <td>44</td>\n",
       "      <td>2020</td>\n",
       "      <td>815.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0101AL01</td>\n",
       "      <td>45</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0101AL01</td>\n",
       "      <td>46</td>\n",
       "      <td>2020</td>\n",
       "      <td>267.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0101AL06</td>\n",
       "      <td>44</td>\n",
       "      <td>2020</td>\n",
       "      <td>253.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0101AL06</td>\n",
       "      <td>45</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ANLEGG_NR  INP_PAR_ID  YEAR   VALUE\n",
       "0  0101AL01          44  2020  815.98\n",
       "1  0101AL01          45  2020    2.35\n",
       "2  0101AL01          46  2020  267.80\n",
       "3  0101AL06          44  2020  253.65\n",
       "4  0101AL06          45  2020    2.86"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine\n",
    "val_df = pd.concat([stan_vals, milo_vals, ind_vals], axis=0, sort=True)\n",
    "\n",
    "# Add column for year\n",
    "val_df[\"YEAR\"] = year\n",
    "\n",
    "# Explicitly set data types\n",
    "val_df[\"ANLEGG_NR\"] = val_df[\"ANLEGG_NR\"].astype(str)\n",
    "val_df[\"INP_PAR_ID\"] = val_df[\"INP_PAR_ID\"].astype(int)\n",
    "val_df[\"VALUE\"] = val_df[\"VALUE\"].astype(float)\n",
    "val_df[\"YEAR\"] = val_df[\"YEAR\"].astype(int)\n",
    "\n",
    "# Store Anlegg and Miljøgifter contain some duplicated information\n",
    "val_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Average any remaining duplciates (because sometimes the same value is reported with different precision)\n",
    "val_df = val_df.groupby([\"ANLEGG_NR\", \"INP_PAR_ID\", \"YEAR\"]).mean().reset_index()\n",
    "\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop any existing values for this year\n",
    "# sql = (\"DELETE FROM resa2.rid_punktkilder_inpar_values \"\n",
    "#       \"WHERE year = %s\" % year)\n",
    "# res = engine.execute(sql)\n",
    "#\n",
    "## Add to RESA2.RID_PUNKTKILDER_INPAR_VALUES\n",
    "# val_df.to_sql('rid_punktkilder_inpar_values', con=engine, schema='resa2',\n",
    "#              if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Små anlegg (small treatment works)\n",
    "\n",
    "Copy and rename the file, and rename the worksheet `sma_anlegg_{year}`. Delete rows above the header and delete unnecessary columns. The only columns required are `KOMMUNENR`, `SUM FOSFOR` and `SUM NITROGEN`, which should be renamed `KOMMUNENR`, `P_kg` and `N_kg`, respectively.\n",
    "\n",
    "This data is added directly to `RESA2.RID_KILDER_SPREDT_VALUES`. \n",
    "\n",
    "**Note:** The kommuner ID numbers in the små anlegg file should be present in \n",
    "\n",
    "    ../../../teotil2/data/core_input_data/regine_{year}.csv\n",
    "    \n",
    "Kommune IDs change from year to year, so they will usually need updating in TEOTIL - see [update_regine_kommune.ipynb](https://nbviewer.org/github/JamesSample/rid/blob/master/notebooks/update_regine_kommune.ipynb) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KOMM_NO</th>\n",
       "      <th>INP_PAR_ID</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>AR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0301</td>\n",
       "      <td>45</td>\n",
       "      <td>211.061250</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1101</td>\n",
       "      <td>45</td>\n",
       "      <td>830.907900</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1103</td>\n",
       "      <td>45</td>\n",
       "      <td>2895.169050</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1106</td>\n",
       "      <td>45</td>\n",
       "      <td>198.236249</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1108</td>\n",
       "      <td>45</td>\n",
       "      <td>1334.749972</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  KOMM_NO INP_PAR_ID        VALUE    AR\n",
       "0    0301         45   211.061250  2020\n",
       "1    1101         45   830.907900  2020\n",
       "2    1103         45  2895.169050  2020\n",
       "3    1106         45   198.236249  2020\n",
       "4    1108         45  1334.749972  2020"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read raw (tidied) data\n",
    "in_xlsx = f\"../../../Data/point_data_{year}/avlop_sma_anlegg_{year}_raw.xlsx\"\n",
    "sman_df = pd.read_excel(in_xlsx, sheet_name=f\"sma_anlegg_{year}\")\n",
    "\n",
    "# Drop blank rows\n",
    "sman_df.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "# Kommune nr. should be a 4 char string, not a float\n",
    "fmt = lambda x: \"%04d\" % x\n",
    "sman_df[\"KOMMUNENR\"] = sman_df[\"KOMMUNENR\"].apply(fmt)\n",
    "\n",
    "# Check if any kommuner are not already in TEOTIL\n",
    "reg_csv = f\"../../../teotil2/data/core_input_data/regine_{year}.csv\"\n",
    "kmnr_df = pd.read_csv(reg_csv, sep=\";\", encoding=\"utf-8\")\n",
    "kmnr_df[\"komnr\"] = kmnr_df[\"komnr\"].apply(fmt)\n",
    "\n",
    "not_in_db = set(sman_df[\"KOMMUNENR\"].values) - set(kmnr_df[\"komnr\"].values)\n",
    "if len(not_in_db) > 0:\n",
    "    print(f'\\nThe following {len(not_in_db)} kommuner are not in the TEOTIL \"regine\" file. Consider updating?:')\n",
    "    print(sman_df[sman_df[\"KOMMUNENR\"].isin(list(not_in_db))])\n",
    "\n",
    "# Get cols of interest for RID_KILDER_SPREDT_VALUES\n",
    "sman_df = sman_df[[\"KOMMUNENR\", \"P_kg\", \"N_kg\"]]\n",
    "\n",
    "# In RESA2.RID_PUNKTKILDER_INPAR_DEF, N is par_id 44 and P par_id 45\n",
    "sman_df.columns = [\"KOMM_NO\", 45, 44]\n",
    "\n",
    "# Melt to \"long\" format\n",
    "sman_df = pd.melt(\n",
    "    sman_df,\n",
    "    id_vars=\"KOMM_NO\",\n",
    "    value_vars=[45, 44],\n",
    "    var_name=\"INP_PAR_ID\",\n",
    "    value_name=\"VALUE\",\n",
    ")\n",
    "\n",
    "# Add column for year\n",
    "sman_df[\"AR\"] = year\n",
    "\n",
    "sman_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_KILDER_SPREDT_VALUES\n",
    "# sman_df.to_sql('rid_kilder_spredt_values', con=engine, schema='resa2',\n",
    "#               if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fish farms\n",
    "\n",
    "An example of the raw data is here:\n",
    "\n",
    " * K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Fiskeoppdrett\\Teotil - 2015 (2) (pr. 09.08.16).xlsx.zip\n",
    "\n",
    "I have made a local copy of the 2016 file here:\n",
    "\n",
    " * C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\\fiske_oppdret_2016_raw.xlsx\n",
    "\n",
    "The data must be added to two tables in RESA2:\n",
    "\n",
    " * First, the site data must be added to `RESA2.RID_KILDER_AQUAKULTUR`. Most of the sites should already be there, but occasionally new sites are added. Any new stations must be be assigned lat/lon co-ordinates and the appropriate \"Regine\" catchment ID. This usually requires geocoding plus co-ordinate conversions and/or a spatial join to determine catchment IDs.\n",
    " \n",
    "    **Note:** The key ID fields in the raw data appear to be `LOKNR` and `LOKNAVN`. <br><br>\n",
    " \n",
    " * Secondly, the chemistry data for each site must be extracted and converted to \"long\" format, then added to `RESA2.RID_KILDER_AQKULT_VALUES`. Parameter IDs etc. are taken from `RESA2.RID_PUNKTKILDER_INPAR_DEF`.\n",
    " \n",
    "### 3.1. Basic data checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year for the data in question\n",
    "year = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw (tidied) data\n",
    "# Fish farms\n",
    "in_xlsx = r\"../../../Data/point_data_%s/fiske_oppdret_%s_raw.xlsx\" % (year, year)\n",
    "fish_df = pd.read_excel(in_xlsx, sheet_name=\"Ark1\")\n",
    "\n",
    "# Drop no data\n",
    "fish_df.dropna(how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any sites are not already in db\n",
    "sql = \"SELECT UNIQUE(NR) \" \"FROM resa2.rid_kilder_aquakultur\"\n",
    "aqua_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "not_in_db = set(fish_df[\"LOKNR\"].values) - set(aqua_df[\"nr\"].values)\n",
    "\n",
    "nidb_df = fish_df[fish_df[\"LOKNR\"].isin(list(not_in_db))][\n",
    "    [\"LOKNR\", \"LOKNAVN\", \"N_DESIMALGRADER_Y\", \"O_DESIMALGRADER_X\"]\n",
    "].drop_duplicates(subset=[\"LOKNR\"])\n",
    "\n",
    "print(\"\\nThe following locations are not in the database:\")\n",
    "print(nidb_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Geocode fish farms and add to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Regine catchment shapefile\n",
    "reg_shp_path = r\"../../../Data/gis/shapefiles/reg_minste_f_wgs84.shp\"\n",
    "\n",
    "# Spatial join\n",
    "if len(nidb_df) > 0:\n",
    "    loc_df = rid.identify_point_in_polygon(\n",
    "        nidb_df,\n",
    "        reg_shp_path,\n",
    "        \"LOKNR\",\n",
    "        \"VASSDRAGNR\",\n",
    "        \"N_DESIMALGRADER_Y\",\n",
    "        \"O_DESIMALGRADER_X\",\n",
    "    )\n",
    "\n",
    "    # Rename cols\n",
    "    loc_df.columns = [\"NR\", \"NAVN\", \"LENGDE\", \"BREDDE\", \"REGINE\"]\n",
    "\n",
    "    print(loc_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_KILDER_AQUAKULTUR\n",
    "# loc_df.to_sql('rid_kilder_aquakultur', con=engine, schema='resa2',\n",
    "#              if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Estimate nutrient inputs\n",
    "\n",
    "The methodology here is a little unclear. The following is my best guess, based on the files located here:\n",
    "\n",
    "K:\\Avdeling\\Vass\\316_Miljøinformatikk\\Prosjekter\\RID\\2016\\Rådata\\Fiskeoppdrett\n",
    "\n",
    "Old workflow:\n",
    "\n",
    " 1. Calculate the fish biomass from the raw data. See the equation in the `Biomasse` column of the spreadsheet *JSE_TEOTIL_2015.xlsx* <br><br>\n",
    " \n",
    " 2. Split the data according to salmon (\"laks\"; species ID 71101) and trout (\"øret\"; species ID 71401), then group by location and month, summing biomass and `FORFORBRUK_KILO` columns (see Fiskeoppdrett_biomasse_2016.accdb) <br><br>\n",
    " \n",
    " 3. Calculate production. This involves combining biomass for the current month with that for the previous month. See the calculations in e.g. *N_P_ørret_2015.xlsx*. <br><br>\n",
    " \n",
    " 4. Calculate NTAP and PTAP. **NB:** I don't know what these quantities are, so I'm just blindly duplicating the Excel calculations in the code below. The functions are therefore not very well explained <br><br>\n",
    " \n",
    " 5. Estimate copper usage at each fish farm by scaling the total annual Cu usage in proportion to P production. For 2018, John Rune has supplied an annual Cu value of **1217 tonnes** (see e-mail received 15.10.2019 at 10.27)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual Cu usage in tonnes\n",
    "an_cu = 1217\n",
    "\n",
    "# Estimate nutrient inputs from fish farns\n",
    "fish_nut = rid.estimate_fish_farm_nutrient_inputs(fish_df, year, an_cu)\n",
    "\n",
    "fish_nut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_KILDER_AQKULT_VALUES\n",
    "# fish_nut.to_sql('rid_kilder_aqkult_values', con=engine, schema='resa2',\n",
    "#                if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Land use\n",
    "\n",
    "An example of the raw data is here:\n",
    "\n",
    " * K:\\Avdeling\\Vass\\316_Miljøinformatikk\\Prosjekter\\RID\\2016\\Rådata\\Jordbruk\\to-niva.2015.xls\n",
    "\n",
    "Note that this file is not really an Excel file and opening it directly creates errors. I have corrected the data format, tidied the column headings and made a local copy of the 2016 data here:\n",
    "\n",
    " * C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\\jordbruk_2016.xlsx\n",
    " \n",
    "This is added to the table `RESA2.RID_AGRI_INPUTS`.\n",
    "\n",
    "**Note:** In recent years, the entry for Oslo (fylke_sone = 3_1) has been missing from the data provided by Bioforsk. This row should be added manually to the Excel file using `omrade = \"osl1\"`. The values should be identical to those for område `ake2`. This works because the land areas in `RID_Fylke-Sone_LU_Areas.xlsx` have been made identical for `osl1` and `ake2` (even though this is not correct), so the inputs in terms of kg/km2 are calculated as being the same for both regions, which is what is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year for the data in question\n",
    "year = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to (tidied) Bioforsk data\n",
    "in_xlsx = r\"../../../Data/point_data_%s/jordbruk_%s.xlsx\" % (year, year)\n",
    "\n",
    "lu_df = pd.read_excel(in_xlsx)\n",
    "\n",
    "# Add year\n",
    "lu_df[\"year\"] = year\n",
    "\n",
    "# Order cols\n",
    "lu_df = lu_df[\n",
    "    [\n",
    "        \"omrade\",\n",
    "        \"year\",\n",
    "        \"n_diff_kg\",\n",
    "        \"n_point_kg\",\n",
    "        \"n_back_kg\",\n",
    "        \"p_diff_kg\",\n",
    "        \"p_point_kg\",\n",
    "        \"p_back_kg\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "lu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to RESA\n",
    "# lu_df.to_sql(name='rid_agri_inputs', con=engine,\n",
    "#             schema='resa2', index=False,\n",
    "#             if_exists='append',\n",
    "#             dtype={'omrade': types.VARCHAR(lu_df['omrade'].str.len().max())})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
