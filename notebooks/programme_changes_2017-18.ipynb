{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import imp\n",
    "import numpy as np\n",
    "import os\n",
    "import nivapy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "sn.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programme changes 2017-18\n",
    "\n",
    "The RID project has applied a fairly consistent methodology for many years, and Tore's original workflow has been used (with minor modifications) for every year up to and including 2015. In 2016, I updated and streamlined the code required to repeat this workflow, as documented [here](https://github.com/JamesSample/rid). However, the programme has been substantially restructured for 2017-2020, which means the workflow I created last year will need to be adapted. This notebook describes the changes and provides some initial modified code. \n",
    "\n",
    "## 1. What has changed?\n",
    "\n",
    "### 1.1. \"Core\" programme (\"grunnprogrammet\")\n",
    "\n",
    "The following is a (slightly modified) extract from an e-mail sent to Hans Fredrik (16.08.2018 at 11.54) when I first discovered changes to the core programme compared to previous years:\n",
    "\n",
    ">In 2016 (and for several years prior to that) we had the following: \n",
    ">\n",
    "> * Monthly sampling for the 11 main rivers <br><br>\n",
    ">\n",
    "> * Quarterly sampling for the 36 bielver <br><br>\n",
    ">\n",
    "> * Estimated values based on long-term measurements (collected prior to 2004) for 108 other rivers\n",
    ">\n",
    ">Each of these categories had its own project in the database, and my code basically applies a different analysis methodology for each one. Comparing the table in the 2017 tilbud PDF to the data in the database, I can see that we now have the following (for 2017-20):\n",
    ">\n",
    "> * We are still sampling the 11 main rivers, as before <br><br>\n",
    ">\n",
    "> * We have stated that we will sample only 8 of the 36 bielver <br><br>\n",
    ">\n",
    "> * We will begin sampling again at one of the old RID-108 rivers (Storelva/Vegårdselva), but this time with monthly resolution (prior to 2017, this site hadn’t been sampled since 2003, and then it had only 1 sample per year)\n",
    ">\n",
    ">In addition, there is at least some data from 2017 in the database for another 7 of the bielver (NTRENAM, AAGENID, TELETOK, VAGEKVI, VAGELYN, VAGEMAN, VAGETOV). This has been collected either as part of the flood sampling or under \"Option 3\" (see below). We need to decide whether to use this data in the loads and trends analyses.\n",
    ">\n",
    ">Some key questions:\n",
    ">\n",
    "> * What do we do with the 28 bielver that are no longer being monitored this year? Are we going to estimate values using the same methodology as we have used previously for the RID 108 rivers, but using all data from 1990 to 2016 (instead of 1990 to 2003)? <br><br>\n",
    ">\n",
    "> * Do we want to incorporate data from the other 7 bielver? They are not they are not part of the core programme, but we do have at least some data in the database for them (monthly in some cases; only one sample per year in others) <br><br>\n",
    ">\n",
    "> * How do we want to estimate trends for Storelva/Vegårdselva? In terms of data, this location has one sample per year for 1990 to 2003 inclusive, then 12 samples from 2017, so it’s a bit unusual\n",
    ">\n",
    ">In terms of the new analysis, we now have different site groupings compared to previous years. Something like this:\n",
    ">\n",
    "> * 11 RID hovedelver <br><br>\n",
    ">\n",
    "> * 8 RID bielver <br><br>\n",
    ">\n",
    "> * 107 “other” rivers not monitored since 2003 <br><br>\n",
    ">\n",
    "> * 28 unmonitored RID bielver, where values now need to be estimated based on long-term data up to 2016. In reality, however, it’s more like 21 sites than 28, because we have 2017 data for 7 of these stations from other components of this project <br><br>\n",
    ">\n",
    "> * 1 “other” river with data prior to 2004 and after 2016, but nothing in between\n",
    ">\n",
    ">The first three of these categories can be treated the same as before, but the last two will require a modified approach.\n",
    "\n",
    "In addition, some new parameters have been included in the analyses for 2017-20: filtered metals, POC, particulate N, etc. **These should not be included in the standard loads or trends calculations**, but a separate analysis of these data may nevertheless be required for the report.\n",
    "\n",
    "**The 20 stations monitored as part of the new core programme are listed in RESA2 under the project `'Elveovervåkningsprogrammet (O 16384)'`**.\n",
    "\n",
    "### 1.2. Option 3 (\"opsjon3\")\n",
    "\n",
    "On top of the basic monitoring, there are some additional stations (several per river, arranged along the stream course) that are monitored as part of this project. A different subset of the 20 main rivers is monitored under \"opsjon3\" each year: roughly 5 rivers per year, for each of the four years in the project.\n",
    "\n",
    "**The new Option 3 sites should not be included in the standard loads or trends work**. For the most part, the Option 3 stations do not overlap with the 155 stations used for estimating loads so, for the analyses of interest here, Option 3 can be largely ignored. However, there are two exceptions: during 2017 Option 3 included SFJESTR (one of the RID-108 sites) and NTRENAM (part of RID-36). These stations were added part way through the sampling programme, so there are no measurements from the first half of the year, but from July to December we have one sample per month for each location. Following discussion with Øyvind, we have decided that **these samples should be excluded from the loads estimation work** (see e-mail received 17.08.2018 at 14.03 for details).\n",
    "\n",
    "A further issue is that the Option 3 data are currently not well organised in the database. To help Liv Bente, the following cleaning is required:\n",
    "\n",
    " * The 2017 \"opsjon3\" data is currently associated with project `'Elveoverv opsj3 2017'` in RESA2. Following discussion on 16.08.2018, we have decided to rename this `'Elveoverv opsj3'` and use it for all Option 3 data for all four years <br><br>\n",
    " \n",
    " * Station co-ordinates for all the 2017 Option 3 rivers need adding to RESA (see e-mail from Liv Bente received 15.08.2018 at 14.33) <br><br>\n",
    " \n",
    " * New stations (plus co-ordinates) for the 2018 Option 3 rivers need adding to the updated `'Elveoverv opsj3'` project (see e-mail from Liv Bente received 15.08.2018 at 14.33)\n",
    " \n",
    "### 1.3. Flood sampling (\"flomprøver\")\n",
    "\n",
    "During October 2017, flood sampling was carried out at 10 locations linked to the Elveovervåkningsprogrammet:\n",
    "\n",
    "| Station code |     Datetime     |\n",
    "|:------------:|:----------------:|\n",
    "| AAGENID      | 25.10.2017 14:50 |\n",
    "| AAGEVEG      | 25.10.2017 14:00 |\n",
    "| TELESKI      | 25.10.2017 11:00 |\n",
    "| TELETOK      | 25.10.2017 12:45 |\n",
    "| VAGEKVI      | 26.10.2017 13:10 |\n",
    "| VAGELYN      | 26.10.2017 17:20 |\n",
    "| VAGEMAN      | 26.10.2017 18:15 |\n",
    "| VAGEOTR      | 26.10.2017 19:10 |\n",
    "| VAGESIR2     | 26.10.2017 14:10 |\n",
    "| VAGETOV      | 25.10.2017 15:30 |\n",
    "\n",
    "Three of these stations (AAGEVEG, TELESKI and VAGEOTR) have also been monitored monthly as part of the core programme in 2017. Note also that VAGESIR2 is one of the Option 3 stations for 2017, and the remaining 6 stations have all been previously monitored for RID, either as part of the bielver or as part of RID-108.\n",
    "\n",
    "Because these samples specifically target flood peaks, it is not a good idea to use them in the loads calculations: to do so would bias the results. **These samples should therefore be omitted from the analysis here**.\n",
    "\n",
    "Liv Bente has created a new project in RESA for the flood sampling called `'Elveoverv_Flomprøver'` and, ideally, the flood samples should be linked to this. However, there is no straightforward way to do this RESA, because water samples are assigned to stations and stations are assigned to projects, so it is difficult to get just some of the water samples associated with a particular station associated with a specific project. As far as I can see, this has been achieved previously in an *ad hoc* way: the tables `'RESA2.SAMPLE_SELECTION_DEFINITIONS'` and `'RESA2.SAMPLE_SELECTIONS'` provide most of the necessary database infrastructure, but neither have had any updates since 2011, so they clearly aren't used consistently.\n",
    "\n",
    "**Need to decide whether to attempt to use this old structure, or to create a temporary solution of my own for the analysis this year**.\n",
    "\n",
    "### 1.4. Summary\n",
    "\n",
    " * For the new core programme, we now have 20 \"main\" rivers that are monitored monthly (except Glomma and Drammenselva, which have 16 samples per year). These 20 sites comprise the original 11 \"main\" rivers, plus 8 of the old \"bielver\", plus one of the old \"RID-108\" rivers. **Loads and trends for these sites should be calculated in the same way as previously for the RID-11 rivers** <br><br>\n",
    "\n",
    " * All the other sites from the old programme (135 in total) are now considered as \"other\"/\"unmonitored\". **Loads for these should be calculated using the method previously applied for RID-108 sites** <br><br>\n",
    " \n",
    " * Additional sampling has been carried out under Option 3. For the analysis presented here these data can be largely ignored, but the **data collected at stations SFJESTR and NTRENAM should be excluded from the loads estimation procedure**\n",
    "\n",
    " * Flood sampling has been carried out at 10 locations. **These samples should be removed from the loads and trends analysis to avoid biasing the results**\n",
    " \n",
    "The table below attempts to summarise the main features of the 2017-20 Elveovervåkningsprogrammet programme relevant to the loads and trends analysis:\n",
    "\n",
    "<img src=\"https://github.com/JamesSample/rid/blob/master/png/change_summary_2017_2020.png?raw=true\" alt=\"Change summary\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "resa2_basic_path = (r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\Upload_Template'\n",
    "                    r'\\useful_resa2_code.py')\n",
    "resa2_basic = imp.load_source('useful_resa2_code', resa2_basic_path)\n",
    "engine, conn = resa2_basic.connect_to_resa2()\n",
    "\n",
    "# Import custom RID functions\n",
    "rid_func_path = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "                 r'\\Python\\rid\\notebooks\\useful_rid_code.py')\n",
    "rid = imp.load_source('useful_rid_code', rid_func_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database tidying\n",
    "\n",
    "### 2.1. Option 3\n",
    "\n",
    "#### 2.1.1. Rename project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change project name from 'Elveoverv opsj3 2017' to 'Elveoverv opsj3'\n",
    "#sql = (\"UPDATE resa2.projects \"\n",
    "#       \"SET project_name = 'Elveoverv opsj3' \"\n",
    "#       \"WHERE project_name = 'Elveoverv opsj3 2017'\")\n",
    "#res = conn.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Add 2017 station co-ordinates\n",
    "\n",
    "Liv Bente has provided an Excel file containing station details for the sites under Option 3 for 2017 and 2018 (see e-mail received 15.08.2018 at 14.33 for details). A tidied version of this files is here:\n",
    "\n",
    "...\\Elveovervakingsprogrammet\\Data\\option_3\\option_3_2017-18_tidied.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read 2017 station data\n",
    "#in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "#           r'\\Data\\option_3\\option_3_2017-18_tidied.xlsx') \n",
    "#df = pd.read_excel(in_xlsx, sheet_name='2017')\n",
    "#\n",
    "## Convert co-ords to degrees\n",
    "#df = nivapy.spatial.utm_to_wgs84_dd(df)\n",
    "#\n",
    "## Loop over sites\n",
    "#for idx, row in df.iterrows():\n",
    "#    # Query db\n",
    "#    sql = (\"SELECT * FROM resa2.stations \"\n",
    "#           \"WHERE station_code = '%s' \" % row['station_code'])\n",
    "#    resa_df = pd.read_sql_query(sql, engine)   \n",
    "#    \n",
    "#    # Make sure site can be uniquely identified\n",
    "#    assert len(resa_df) == 1, 'Wrong number of sites with station_code = %s' % row['station_code']\n",
    "#\n",
    "#    # Update db\n",
    "#    sql = (\"UPDATE resa2.stations \"\n",
    "#           \"SET station_name = '%s', \"\n",
    "#           \"  utme = %.2f, \"\n",
    "#           \"  utmn = %.2f, \"\n",
    "#           \"  zone = %s, \"\n",
    "#           \"  latitude = %.8f, \"\n",
    "#           \"  longitude = %.8f \"\n",
    "#           \"WHERE station_code = '%s'\" % (row['station_name'],\n",
    "#                                          row['utm_east'],\n",
    "#                                          row['utm_north'],\n",
    "#                                          row['utm_zone'],\n",
    "#                                          row['lat'],\n",
    "#                                          row['lon'],\n",
    "#                                          row['station_code']))\n",
    "#    res = conn.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3. Create 2018 stations\n",
    "\n",
    "Liv Bente's Excel files also lists the 36 Option 3 stations for 2018. 7 of these (highlighted yellow in the Excel sheet) are already in the database, so they just need adding to the `'Elveoverv opsj3'` project (see below). The others need to be created as stations first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read 2018 station data\n",
    "#in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "#           r'\\Data\\option_3\\option_3_2017-18_tidied.xlsx') \n",
    "#df = pd.read_excel(in_xlsx, sheet_name='2018')\n",
    "#\n",
    "## Convert co-ords to degrees\n",
    "#df = nivapy.spatial.utm_to_wgs84_dd(df)\n",
    "#\n",
    "## Loop over sites\n",
    "#for idx, row in df.iterrows():\n",
    "#    # Make sure site doesn't already exist\n",
    "#    sql = (\"SELECT * FROM resa2.stations \"\n",
    "#           \"WHERE station_code = '%s' \" % row['station_code'])\n",
    "#    resa_df = pd.read_sql_query(sql, engine)   \n",
    "#    \n",
    "#    if len(resa_df) > 0:\n",
    "#        # Already in db, so skip\n",
    "#        print 'station_code %s already exists. Skipping...' % row['station_code']\n",
    "#    \n",
    "#    else:\n",
    "#        # Create station\n",
    "#        sql = (\"INSERT INTO resa2.stations \"\n",
    "#               \"(station_code, station_name, lake_or_river, latitude, longitude, utme, utmn, zone) \"\n",
    "#               \"VALUES ('%s', '%s', 'R', %.8f, %.8f, %.2f, %.2f, %s)\" % (row['station_code'],\n",
    "#                                                                         row['station_name'],\n",
    "#                                                                         row['lat'],\n",
    "#                                                                         row['lon'],\n",
    "#                                                                         row['utm_east'],\n",
    "#                                                                         row['utm_north'],\n",
    "#                                                                         row['utm_zone']))\n",
    "#        res = conn.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4. Add 2018 stations to Option 3 project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get project ID for Option 3\n",
    "#sql = (\"SELECT project_id FROM resa2.projects \"\n",
    "#       \"WHERE project_name = 'Elveoverv opsj3'\")\n",
    "#prj_id = pd.read_sql_query(sql, engine)['project_id'][0]\n",
    "#\n",
    "## Read 2018 station data\n",
    "#in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "#           r'\\Data\\option_3\\option_3_2017-18_tidied.xlsx') \n",
    "#df = pd.read_excel(in_xlsx, sheet_name='2018')\n",
    "#\n",
    "## Loop over sites\n",
    "#for idx, row in df.iterrows():\n",
    "#    # Get site ID\n",
    "#    sql = (\"SELECT station_id FROM resa2.stations \"\n",
    "#           \"WHERE station_code = '%s' \" % row['station_code'])\n",
    "#    stn_id = pd.read_sql_query(sql, engine)['station_id'][0]\n",
    "#    \n",
    "#    # Check whether this site is already part of this project\n",
    "#    sql = (\"SELECT * FROM resa2.projects_stations \"\n",
    "#           \"WHERE station_id = %s \" \n",
    "#           \"AND project_id = %s\" % (stn_id, prj_id))\n",
    "#    prj_stn_df = pd.read_sql_query(sql, engine)\n",
    "#    \n",
    "#    if len(prj_stn_df) > 0:\n",
    "#        print 'Station %s is already part of this project.' % row['station_code']\n",
    "#    \n",
    "#    else:          \n",
    "#        # Link site to project\n",
    "#        sql = (\"INSERT INTO resa2.projects_stations \"\n",
    "#               \"(station_id, project_id, active) \"\n",
    "#               \"VALUES (%s, %s, 'y')\" % (stn_id, prj_id))\n",
    "#        res = conn.execute(sql)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Flood samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
