{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import mpld3\n",
    "import pandas as pd\n",
    "import imp\n",
    "import numpy as np\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from shutil import copyfile\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "sn.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recalculating OSPAR flow data\n",
    "\n",
    "The discharge data previously submitted in Table 9 of the OSPAR template used the wrong format and needs to be re-entered (see e-mails from Eva received 15/08/2017 at 10.42 and 16/08/2017 at 10.44 for details). Eva has supplied a blank data entry template, which I've copied here:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Recalculate_OSPAR_Flows\\Table 9 template.xlsx\n",
    "\n",
    "For each year from 1990 to the present day, we need a version of this template based on the monitored and modelled flow datasets in the RID database.\n",
    "\n",
    "This notebook develops code for filling-in these templates. With the exception of \"Inner Oslofjord\" and \"Suldalslågen\", which need to be considered separately (see later), the light-yellow rows in the template correspond to 10 of the \"RID_11\" monitoring stations. Data for these stations can be extracted directly. \n",
    "\n",
    "The bright-yellow cells, representing overall discharges to each of the four OSPAR regions, require a more sophisticated approach that combines modelled and monitored datasets. \n",
    "\n",
    "First establish a connection to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "resa2_basic_path = (r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\Upload_Template'\n",
    "                    r'\\useful_resa2_code.py')\n",
    "resa2_basic = imp.load_source('useful_resa2_code', resa2_basic_path)\n",
    "engine, conn = resa2_basic.connect_to_resa2()\n",
    "\n",
    "# Import custom RID functions\n",
    "rid_func_path = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "                 r'\\Python\\rid\\notebooks\\useful_rid_code.py')\n",
    "rid = imp.load_source('useful_rid_code', rid_func_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Discharges from monitored locations\n",
    "\n",
    "The code below extracts summary statistics for 10 of the RID_11 stations from 1990 to 2016 inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_name</th>\n",
       "      <th>ospar_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29615</td>\n",
       "      <td>VESENUM</td>\n",
       "      <td>Numedalslågen</td>\n",
       "      <td>SKAGERAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29821</td>\n",
       "      <td>HOREVOS</td>\n",
       "      <td>Vosso(Bolstadelvi)</td>\n",
       "      <td>NORTH SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29783</td>\n",
       "      <td>ROGEORR</td>\n",
       "      <td>Orreelva</td>\n",
       "      <td>NORTH SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29613</td>\n",
       "      <td>TELESKI</td>\n",
       "      <td>Skienselva</td>\n",
       "      <td>SKAGERAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29614</td>\n",
       "      <td>VAGEOTR</td>\n",
       "      <td>Otra</td>\n",
       "      <td>SKAGERAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29782</td>\n",
       "      <td>NOREVEF</td>\n",
       "      <td>Vefsna</td>\n",
       "      <td>NORWEGIAN SEA2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36225</td>\n",
       "      <td>OSLEALN</td>\n",
       "      <td>Alna</td>\n",
       "      <td>SKAGERAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29617</td>\n",
       "      <td>ØSTEGLO</td>\n",
       "      <td>Glomma ved Sarpsfoss</td>\n",
       "      <td>SKAGERAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29779</td>\n",
       "      <td>FINEALT</td>\n",
       "      <td>Altaelva</td>\n",
       "      <td>LOFOTEN-BARENTS SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29612</td>\n",
       "      <td>BUSEDRA</td>\n",
       "      <td>Drammenselva</td>\n",
       "      <td>SKAGERAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29778</td>\n",
       "      <td>STREORK</td>\n",
       "      <td>Orkla</td>\n",
       "      <td>NORWEGIAN SEA2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29781</td>\n",
       "      <td>ROGESUL</td>\n",
       "      <td>Suldalslågen</td>\n",
       "      <td>NORTH SEA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_id station_code          station_name         ospar_region\n",
       "0        29615      VESENUM         Numedalslågen             SKAGERAK\n",
       "1        29821      HOREVOS    Vosso(Bolstadelvi)            NORTH SEA\n",
       "2        29783      ROGEORR              Orreelva            NORTH SEA\n",
       "3        29613      TELESKI            Skienselva             SKAGERAK\n",
       "4        29614      VAGEOTR                  Otra             SKAGERAK\n",
       "5        29782      NOREVEF                Vefsna       NORWEGIAN SEA2\n",
       "6        36225      OSLEALN                  Alna             SKAGERAK\n",
       "7        29617      ØSTEGLO  Glomma ved Sarpsfoss             SKAGERAK\n",
       "8        29779      FINEALT              Altaelva  LOFOTEN-BARENTS SEA\n",
       "9        29612      BUSEDRA          Drammenselva             SKAGERAK\n",
       "10       29778      STREORK                 Orkla       NORWEGIAN SEA2\n",
       "11       29781      ROGESUL          Suldalslågen            NORTH SEA"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read site data for RID_11 and RID_36\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\RID_Sites_List.xlsx')\n",
    "rid_11_df = pd.read_excel(in_xlsx, sheetname='RID_11')\n",
    "rid_36_df = pd.read_excel(in_xlsx, sheetname='RID_36')\n",
    "\n",
    "# Get just Suldalslågen from rid_36\n",
    "rid_36_df = rid_36_df.query('station_id == 29781')\n",
    "\n",
    "# Combine\n",
    "mon_df = pd.concat([rid_11_df, rid_36_df], axis=0)\n",
    "\n",
    "# Get OSPAR region for stations\n",
    "sql = (\"SELECT station_id, value \"\n",
    "       \"FROM resa2.stations_par_values \"\n",
    "       \"WHERE var_id = 262\")\n",
    "ospar_reg = pd.read_sql_query(sql, engine)\n",
    "ospar_reg.columns = ['station_id', 'ospar_region']\n",
    "\n",
    "# Join OSPAR regions to station data\n",
    "mon_df = pd.merge(mon_df, ospar_reg, \n",
    "                  how='left', on='station_id')\n",
    "\n",
    "# Get cols of interest\n",
    "mon_df = mon_df[['station_id', 'station_code', \n",
    "                 'station_name', 'ospar_region']]\n",
    "\n",
    "mon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_id</th>\n",
       "      <th>year</th>\n",
       "      <th>mean</th>\n",
       "      <th>lta</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>n_yrs</th>\n",
       "      <th>n_sites</th>\n",
       "      <th>stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29615</td>\n",
       "      <td>1990</td>\n",
       "      <td>10119.152564</td>\n",
       "      <td>10311.415628</td>\n",
       "      <td>3412.955689</td>\n",
       "      <td>39299.530691</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29615</td>\n",
       "      <td>1991</td>\n",
       "      <td>7884.893256</td>\n",
       "      <td>10311.415628</td>\n",
       "      <td>1352.807170</td>\n",
       "      <td>30882.317946</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29615</td>\n",
       "      <td>1992</td>\n",
       "      <td>7838.387948</td>\n",
       "      <td>10311.415628</td>\n",
       "      <td>3106.161558</td>\n",
       "      <td>35247.383330</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29615</td>\n",
       "      <td>1993</td>\n",
       "      <td>9867.524888</td>\n",
       "      <td>10311.415628</td>\n",
       "      <td>3256.978716</td>\n",
       "      <td>29220.191819</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29615</td>\n",
       "      <td>1994</td>\n",
       "      <td>10823.288734</td>\n",
       "      <td>10311.415628</td>\n",
       "      <td>3106.161558</td>\n",
       "      <td>54601.346911</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area_id  year          mean           lta          min           max  \\\n",
       "0    29615  1990  10119.152564  10311.415628  3412.955689  39299.530691   \n",
       "1    29615  1991   7884.893256  10311.415628  1352.807170  30882.317946   \n",
       "2    29615  1992   7838.387948  10311.415628  3106.161558  35247.383330   \n",
       "3    29615  1993   9867.524888  10311.415628  3256.978716  29220.191819   \n",
       "4    29615  1994  10823.288734  10311.415628  3106.161558  54601.346911   \n",
       "\n",
       "   n_yrs  n_sites  stat  \n",
       "0     27        1  Mean  \n",
       "1     27        1  Mean  \n",
       "2     27        1  Mean  \n",
       "3     27        1  Mean  \n",
       "4     27        1  Mean  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Container for results\n",
    "df_list = []\n",
    "\n",
    "# Loop over sites\n",
    "for stn_id in mon_df['station_id']:\n",
    "    # Get catch area for chem station\n",
    "    sql = (\"SELECT catchment_area FROM resa2.stations \"\n",
    "           \"WHERE station_id = %s\" % stn_id)\n",
    "    area_df = pd.read_sql_query(sql, engine)    \n",
    "    wc_area = area_df['catchment_area'].iloc[0]\n",
    "    \n",
    "    # Get linked discharge station\n",
    "    sql = (\"SELECT * FROM resa2.default_dis_stations \"\n",
    "           \"WHERE station_id = %s\" % stn_id)\n",
    "    dis_df = pd.read_sql_query(sql, engine)\n",
    "    dis_stn_id = dis_df['dis_station_id'].iloc[0]\n",
    "    \n",
    "    # Get catchment area for discharge station\n",
    "    sql = (\"SELECT area FROM resa2.discharge_stations \"\n",
    "           \"WHERE dis_station_id = %s\" % dis_stn_id)\n",
    "    area_df = pd.read_sql_query(sql, engine)    \n",
    "    dis_area = area_df['area'].iloc[0]\n",
    "\n",
    "    # Get annual summary flow stats for this station\n",
    "    sql = (\"SELECT TO_CHAR(xdate, 'YYYY') as year, \"\n",
    "           \"       AVG(xvalue) as mean, \"\n",
    "           \"       MIN(xvalue) as min, \" \n",
    "           \"       MAX(xvalue) as max \" \n",
    "           \"FROM resa2.discharge_values \"\n",
    "           \"WHERE dis_station_id = %s \"\n",
    "           \"AND xdate >= date '1990-01-01' \"\n",
    "           \"AND xdate <= date '2016-12-31' \"\n",
    "           \"GROUP BY TO_CHAR(xdate, 'YYYY') \"\n",
    "           \"ORDER BY year\" % dis_stn_id)\n",
    "    q_df = pd.read_sql_query(sql, engine) \n",
    "    \n",
    "    # Set index\n",
    "    q_df.index = q_df['year']\n",
    "    del q_df['year']\n",
    "    \n",
    "    # Scale flows by area ratio\n",
    "    q_df = q_df*wc_area/dis_area\n",
    "    \n",
    "    # Convert m3/s to 1000 m3/d\n",
    "    q_df = q_df*60*60*24/1000\n",
    "    \n",
    "    # Reset index\n",
    "    q_df.reset_index(inplace=True)\n",
    "    \n",
    "    # Add LTA and n_yrs\n",
    "    q_df['lta'] = q_df['mean'].mean()\n",
    "    q_df['n_yrs'] = len(q_df)\n",
    "    \n",
    "    # Add ospar region ID, n_sites and 'mean' cols\n",
    "    q_df['area_id'] = stn_id\n",
    "    q_df['stat'] = 'Mean'\n",
    "    q_df['n_sites'] = 1\n",
    "        \n",
    "    # Re-order cols to match template\n",
    "    q_df = q_df[['area_id', 'year', 'mean', 'lta', 'min',\n",
    "                 'max', 'n_yrs', 'n_sites', 'stat']]\n",
    "    \n",
    "    # Add to results\n",
    "    df_list.append(q_df)\n",
    "    \n",
    "# Combine to single df\n",
    "q_mon_df = pd.concat(df_list, axis=0)    \n",
    "\n",
    "q_mon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelled\n",
    "\n",
    "The TEOTIL input file here:\n",
    "\n",
    "K:\\Avdeling\\Vass\\Teotil2\\Norge_Regine\\Regine.txt\n",
    "\n",
    "incorporates data linking \"regine\" catchment IDs to NVE vassdrag numbers. In addition, the table `RESA2.RID_REGINE_DOWN` links each regine ID to an OSPAR region. These tables can be used to link the modelled NVE data to the OSPAR regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_fp</th>\n",
       "      <th>vassdrag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24_90</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24_90</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>24_90</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>24_90</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>24_90</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    area_fp  vassdrag\n",
       "0     24_90        68\n",
       "9     24_90        69\n",
       "88    24_90        70\n",
       "220   24_90        71\n",
       "240   24_90        72"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read cols of interest from Regine.txt\n",
    "in_txt = r'K:\\Avdeling\\Vass\\Teotil2\\Norge_Regine\\Regine.txt'\n",
    "teo_df = pd.read_csv(in_txt, sep=';', comment='!', \n",
    "                     usecols=['Regine', 'VASSOMR'])\n",
    "teo_df.columns = ['regine', 'vassdrag']\n",
    "\n",
    "# Read data from RESA2.RID_REGINE_DOWN\n",
    "sql = (\"SELECT regine, area_fp \"\n",
    "       \"FROM resa2.rid_regine_down\")\n",
    "ospar_reg = pd.read_sql_query(sql, engine) \n",
    "\n",
    "# Join\n",
    "nve_df = pd.merge(ospar_reg, teo_df,\n",
    "                  how='left', on='regine')\n",
    "\n",
    "# Get cols of interest and simplify\n",
    "nve_df = nve_df[['area_fp', 'vassdrag']]\n",
    "nve_df.drop_duplicates(inplace=True)\n",
    "\n",
    "## We already have monitored data for 10 of these vassdrags (see above)\n",
    "## Remove these from consideration to avoid \"double-counting\"\n",
    "## Get discharge station ids\n",
    "#sql = (\"SELECT * FROM resa2.default_dis_stations \"\n",
    "#       \"WHERE station_id IN %s\" % str(tuple(mon_df['station_id'].values)))\n",
    "#dis_df = pd.read_sql_query(sql, engine)\n",
    "#\n",
    "## Get vassdrag numbers for montiored stations\n",
    "#sql = (\"SELECT nve_serienummer FROM resa2.discharge_stations \"\n",
    "#       \"WHERE dis_station_id IN %s\" % str(tuple(dis_df['dis_station_id'].values)))\n",
    "#vass_nr = pd.read_sql_query(sql, engine)['nve_serienummer'].values\n",
    "#vass_nr = [int(i.split('.')[0]) for i in vass_nr]\n",
    "#\n",
    "## Remove these vass_nrs from consideration in the modelled data\n",
    "#nve_df = nve_df[~nve_df['vassdrag'].isin(vass_nr)]\n",
    "\n",
    "nve_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_flow_data(vass, reg):\n",
    "    \"\"\" Function to combine time series for list of Vassdrags\n",
    "        based on the NVE modelled data.\n",
    "    \n",
    "    Args:\n",
    "        vass: List of strings. Vassdrags to combine \n",
    "        reg:  Str. ID for region\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe. Annual summary stats calculated from the \n",
    "        combined series (for 1990 to 2016)\n",
    "    \"\"\"\n",
    "    # Get RESA2 station ID from vassdrag numbers\n",
    "    sql = (\"SELECT dis_station_id \"\n",
    "           \"FROM resa2.discharge_stations \"\n",
    "           \"WHERE nve_serienummer IN %s\" % str(tuple(vass)))\n",
    "    dis_ids = pd.read_sql_query(sql, engine) \n",
    "    \n",
    "    assert len(dis_ids) == len(vass), 'Lengths of \"vass\" and \"dis_ids\" do not match.'\n",
    "    \n",
    "    # Sum flow data for all sites in OSPAR reg to create a single \n",
    "    # aggregated series    \n",
    "    # Get annual summary flow stats for this region\n",
    "    sql = (\"SELECT TO_CHAR(xdate, 'YYYY') as year, \"\n",
    "           \"       AVG(xvalue) as mean, \"\n",
    "           \"       MIN(xvalue) as min, \" \n",
    "           \"       MAX(xvalue) as max \" \n",
    "           \"FROM ( \"\n",
    "           \"  SELECT TRUNC(xdate) AS xdate, \"\n",
    "           \"         SUM(xvalue) AS xvalue \"\n",
    "           \"  FROM resa2.discharge_values \"\n",
    "           \"  WHERE dis_station_id IN %s \"\n",
    "           \"  AND xdate >= DATE '1990-01-01' \"\n",
    "           \"  AND xdate <= DATE '2016-12-31' \"\n",
    "           \"  GROUP BY TRUNC(xdate) \"\n",
    "           \"  ORDER BY TRUNC(xdate)) \"\n",
    "           \"WHERE xdate >= date '1990-01-01' \"\n",
    "           \"AND xdate <= date '2016-12-31' \"\n",
    "           \"GROUP BY TO_CHAR(xdate, 'YYYY') \"\n",
    "           \"ORDER BY year\" % str(tuple(dis_ids['dis_station_id'].values)))\n",
    "    q_df = pd.read_sql_query(sql, engine) \n",
    "\n",
    "    # Set index\n",
    "    q_df.index = q_df['year']\n",
    "    del q_df['year']\n",
    "        \n",
    "    # Convert m3/s to 1000 m3/d\n",
    "    q_df = q_df*60*60*24/1000\n",
    "    \n",
    "    # Reset index\n",
    "    q_df.reset_index(inplace=True)\n",
    "    \n",
    "    # Add LTA and n_yrs\n",
    "    q_df['lta'] = q_df['mean'].mean()\n",
    "    q_df['n_yrs'] = len(q_df)\n",
    "    \n",
    "    # Add ospar region ID, n_sites and 'mean' cols\n",
    "    q_df['area_id'] = reg\n",
    "    q_df['stat'] = 'Mean'\n",
    "    q_df['n_sites'] = len(vass)\n",
    "    \n",
    "    # Re-order cols to match template\n",
    "    q_df = q_df[['area_id', 'year', 'mean', 'lta', 'min',\n",
    "                 'max', 'n_yrs', 'n_sites', 'stat']]\n",
    "    \n",
    "    return q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_id</th>\n",
       "      <th>year</th>\n",
       "      <th>mean</th>\n",
       "      <th>lta</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>n_yrs</th>\n",
       "      <th>n_sites</th>\n",
       "      <th>stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24_90</td>\n",
       "      <td>1990</td>\n",
       "      <td>403261.150362</td>\n",
       "      <td>303877.911598</td>\n",
       "      <td>120253.653043</td>\n",
       "      <td>1.055660e+06</td>\n",
       "      <td>27</td>\n",
       "      <td>67</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24_90</td>\n",
       "      <td>1991</td>\n",
       "      <td>287394.261699</td>\n",
       "      <td>303877.911598</td>\n",
       "      <td>112613.966064</td>\n",
       "      <td>8.306305e+05</td>\n",
       "      <td>27</td>\n",
       "      <td>67</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24_90</td>\n",
       "      <td>1992</td>\n",
       "      <td>367791.005856</td>\n",
       "      <td>303877.911598</td>\n",
       "      <td>110464.140269</td>\n",
       "      <td>1.108435e+06</td>\n",
       "      <td>27</td>\n",
       "      <td>67</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24_90</td>\n",
       "      <td>1993</td>\n",
       "      <td>287751.669048</td>\n",
       "      <td>303877.911598</td>\n",
       "      <td>80757.900806</td>\n",
       "      <td>9.928839e+05</td>\n",
       "      <td>27</td>\n",
       "      <td>67</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24_90</td>\n",
       "      <td>1994</td>\n",
       "      <td>313702.569079</td>\n",
       "      <td>303877.911598</td>\n",
       "      <td>88735.997318</td>\n",
       "      <td>6.832286e+05</td>\n",
       "      <td>27</td>\n",
       "      <td>67</td>\n",
       "      <td>Mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  area_id  year           mean            lta            min           max  \\\n",
       "0   24_90  1990  403261.150362  303877.911598  120253.653043  1.055660e+06   \n",
       "1   24_90  1991  287394.261699  303877.911598  112613.966064  8.306305e+05   \n",
       "2   24_90  1992  367791.005856  303877.911598  110464.140269  1.108435e+06   \n",
       "3   24_90  1993  287751.669048  303877.911598   80757.900806  9.928839e+05   \n",
       "4   24_90  1994  313702.569079  303877.911598   88735.997318  6.832286e+05   \n",
       "\n",
       "   n_yrs  n_sites  stat  \n",
       "0     27       67  Mean  \n",
       "1     27       67  Mean  \n",
       "2     27       67  Mean  \n",
       "3     27       67  Mean  \n",
       "4     27       67  Mean  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Container for results\n",
    "df_list = []\n",
    "\n",
    "# Loop over OSPAR areas\n",
    "for osp_reg in nve_df['area_fp'].unique():\n",
    "    # Get all vassdrags draining to this region\n",
    "    vass = nve_df.query('area_fp == @osp_reg')['vassdrag'].values.astype(str)\n",
    "    \n",
    "    # Get stats\n",
    "    q_df = combine_flow_data(vass, osp_reg)\n",
    "    \n",
    "    # Add to results\n",
    "    df_list.append(q_df)\n",
    "    \n",
    "# Single calculation for the whole of norway\n",
    "vass = nve_df['vassdrag'].values.astype(str)\n",
    "q_df = combine_flow_data(vass, 'all_nor')\n",
    "df_list.append(q_df)\n",
    "    \n",
    "# Combine to single df\n",
    "q_mod_df = pd.concat(df_list, axis=0)    \n",
    "\n",
    "q_mod_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write results to template\n",
    "\n",
    "The code below iterates over the output and writes the results to the Excel template. A new template is produced for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Years of interest\n",
    "st_yr, end_yr = 1990, 2016\n",
    "\n",
    "# Path to template\n",
    "temp_path = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "             r'\\Recalculate_OSPAR_Flows\\Table 9 template.xlsx')\n",
    "\n",
    "# Output folder\n",
    "out_fold = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "            r'\\Recalculate_OSPAR_Flows\\Updated')\n",
    "\n",
    "# Dict mappiong names in template to area IDs in dfs\n",
    "name_dict = {'Orkla':29778,\n",
    "             'Vefsna':29782,\n",
    "             'Norwegian Sea (NO)':'91_170',\n",
    "             'Alta':29779,\n",
    "             'Barents Sea (NO)':'171_247',\n",
    "             'Glomma':29617,\n",
    "             'Drammenselva':29612,\n",
    "             u'Numedalslågen':29615,\n",
    "             'Skienselva':29613,\n",
    "             'Otra':29614,\n",
    "             'Inner Oslofjord':36225, # Assume just Alna for now(?)\n",
    "             'Skagerrak (NO)':'1_23',\n",
    "             'Orreelva':29783,\n",
    "             u'Suldalslågen':29781,\n",
    "             'Vosso':29821,\n",
    "             'North Sea (NO)':'24_90',\n",
    "             'Norway Total':'all_nor'}\n",
    "\n",
    "# Loop over years\n",
    "for year in range(st_yr, end_yr + 1):\n",
    "    # Convert to string\n",
    "    year = str(year)\n",
    "    \n",
    "    # Copy template\n",
    "    out_path = os.path.join(out_fold, 'ospar_table_9_%s.xlsx' % year)\n",
    "    copyfile(temp_path, out_path)\n",
    "    \n",
    "    # Open new file and get sheet\n",
    "    wb = load_workbook(filename=out_path)\n",
    "    ws = wb['9']\n",
    "    \n",
    "    # Set year\n",
    "    ws['B2'] = int(year)\n",
    "    \n",
    "    # Loop over cells\n",
    "    for item in ws['B12':'B28']:\n",
    "        # Get cell properties\n",
    "        cell = item[0]\n",
    "        area = cell.value\n",
    "        row = cell.row\n",
    "        \n",
    "        # Get area ID\n",
    "        ar_id = name_dict[area]\n",
    "        \n",
    "        if ar_id != 999:\n",
    "            # Get data from relevant df\n",
    "            if isinstance(ar_id, int):\n",
    "                # Monitored df\n",
    "                df = q_mon_df.query('(area_id == @ar_id) and '\n",
    "                                    '(year == @year)')\n",
    "            else:\n",
    "                # Modelled df\n",
    "                df = q_mod_df.query('(area_id == @ar_id) and '\n",
    "                                    '(year == @year)')\n",
    "            \n",
    "            assert len(df) == 1\n",
    "            \n",
    "            # Write values\n",
    "            # 1. Mean\n",
    "            ws.cell(column=5, row=row, value=df.iloc[0]['mean'])\n",
    "            \n",
    "            # 2. LTA\n",
    "            ws.cell(column=7, row=row, value=df.iloc[0]['lta'])  \n",
    "            \n",
    "            # 3. Min\n",
    "            ws.cell(column=9, row=row, value=df.iloc[0]['min']) \n",
    "\n",
    "            # 4. Max\n",
    "            ws.cell(column=11, row=row, value=df.iloc[0]['max'])\n",
    "            \n",
    "            # 5. Years\n",
    "            ws.cell(column=13, row=row, value=df.iloc[0]['n_yrs'])\n",
    "            \n",
    "            # 6. N_Sites\n",
    "            ws.cell(column=15, row=row, value=df.iloc[0]['n_sites'])\n",
    "            \n",
    "            # 7. Stat\n",
    "            ws.cell(column=17, row=row, value=df.iloc[0]['stat'])\n",
    "    \n",
    "    # Save\n",
    "    wb.save(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
