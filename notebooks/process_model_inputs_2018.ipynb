{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import nivapy3 as nivapy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geopandas.tools\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import useful_rid_code as rid\n",
    "from shapely.geometry import Point\n",
    "from sqlalchemy import types\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "sn.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process model input datasets (2018-19)\n",
    "\n",
    "Modelling for the RID programme makes use of the following input datasets:\n",
    "\n",
    " * **Avløp** (sewage and other drainage), sub-divided into\n",
    "     * Large treatment works\n",
    "     * Small treatment works\n",
    "     * Other environmental pollutants <br><br>\n",
    "     \n",
    " * **Fiskeoppdret** (Fish farming) <br><br>\n",
    " \n",
    " * **Industri** (industrial point sources) <br><br>\n",
    " \n",
    " * **Jordbruk** (land use and management activities)\n",
    " \n",
    "The raw datasets come from a variety of different sources and must be restructured into a standardised format and added to the RESA2 database. Once in the database, these can can either be used to generate input files for TEOTIL (using either Tore's code or the workflow documented [here](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/prepare_teotil_inputs.ipynb)), or they can be used to run the new [NOPE model](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/nope_model.ipynb). Generating input files for NOPE from the data in RESA2 is very straightforward: simply call `nope.make_rid_input_file()` for the year of interest.\n",
    "\n",
    "This notebook takes the raw data, restructures it, and adds it to RESA2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Username:  ···\n",
      "Password:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "# Connect to db\n",
    "engine = nivapy.da.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Store anlegg, Miljøgifter and Industri\n",
    "\n",
    "These three datasets are all treated similarly, and there is some duplication between the files. Examples of the raw data formats are here:\n",
    "\n",
    " * K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Avløp\\TEOTIL store anlegg 2015 (sendt 18.08.2016).xlsx\n",
    "\n",
    " * K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Avløp\\Miljogifter_NIVA_RID-prosjektet_2015.xlsx\n",
    "\n",
    " * K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Industri\\Teotiluttrekket til NIVA - 2016_v2.xlsx\n",
    "\n",
    "The files for 2017 need to be checked and tidied to match those from 2016, which are here:\n",
    "\n",
    " * C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\n",
    "\n",
    "I have created a new folder named *point_data_2017* for this year's data. See also the information in the e-mail from John Rune received 29/06/2017 at 15.53. \n",
    "\n",
    "**Note:** The raw data files for industry often contain several years of data. For the file in the folder above, I've filtered the values to only include the year of interest.\n",
    "\n",
    "The data in these files must be added to two tables in RESA2:\n",
    "\n",
    " * First, the site data must be added to `RESA2.RID_PUNKTKILDER`. Most of the sites should already be there, but occasionally new sites are added. Any new stations must be be assigned lat/lon co-ordinates and the appropriate \"Regine\" catchment ID. This usually requires geocoding plus co-ordinate conversions and/or a spatial join to determine catchment IDs.\n",
    " \n",
    "    **Note:** Many (>70) of the stations already in the database are missing Regine IDs. Many more (>3000) are missing co-ordinate information. We have previously asked Miljødirektoratet about this, but they have not yet provided the missing data. <br><br>\n",
    " \n",
    " * Secondly, the chemistry data for each site must be extracted and converted to \"long\" format, then added to `RESA2.RID_PUNKTKILDER_INPAR_VALUES`. Parameter IDs etc. are taken from `RESA2.RID_PUNKTKILDER_INPAR_DEF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw (tidied) data\n",
    "# Year of interest\n",
    "year = 2018\n",
    "\n",
    "# Store anlegg\n",
    "in_xlsx = r'../../../Data/point_data_%s/avlop_stor_anlegg_%s_raw.xlsx' % (year, year)\n",
    "stan_df = pd.read_excel(in_xlsx, sheet_name='store_anlegg_%s' % year)\n",
    "\n",
    "# Miljøgifter\n",
    "in_xlsx = r'../../../Data/point_data_%s/avlop_miljogifter_%s_raw.xlsx' % (year, year)\n",
    "milo_df = pd.read_excel(in_xlsx, sheet_name='miljogifter_%s' % year)\n",
    "\n",
    "# Industri\n",
    "in_xlsx = r'../../../Data/point_data_%s/industri_%s_raw.xlsx' % (year, year)\n",
    "ind_df = pd.read_excel(in_xlsx, sheet_name='industry_%s' % year)\n",
    "\n",
    "# Drop blank rows\n",
    "stan_df.dropna(how='all', inplace=True)\n",
    "milo_df.dropna(how='all', inplace=True)\n",
    "ind_df.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Basic data checking\n",
    "\n",
    "All of the \"Store Anlegg\" and \"Miljøgifter\" sites are classified as `RENSEANLEGG` in the `TYPE` column of `RESA2.RID_PUNKTKILDER`; \"Industri\" sites as labelled `INDUSTRI`.\n",
    "\n",
    "Add `TYPE` columns, merge site data from different sources, convert UTM co-ordinates to WGS84 decimal degrees and identify sites not already in the database. Issues identified below (e.g. missing co-ordinates) should be corrected if possible before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following locations are not in the database:\n",
      "Empty DataFrame\n",
      "Columns: [anlegg_nr, anlegg_navn]\n",
      "Index: []\n",
      "\n",
      "The following locations do not have co-ordinates:\n",
      "     anlegg_nr                           anlegg_navn\n",
      "380   0619AL76                 Skrindehaugen H23-H21\n",
      "381   0619AL80        Nystølsameiga, Nordre Øknevatn\n",
      "392   0620AL59                   Krækkja Turisthytte\n",
      "416   0624AL76                Damåsen Pukk, brakkeby\n",
      "486   0716AL38             Helland Nord avløpsanlegg\n",
      "572   0919AL10              Vågdalsfjorden Hyttefelt\n",
      "638   1029AL11                    Syrdal renseanlegg\n",
      "705   1114AL20  Grønabakkane - Stavtjørn renseanlegg\n",
      "832   1146AL35          Tysvær renseanlegg Gismarvik\n",
      "1112  1244AL02                         Store Karlsøy\n",
      "1113  1244AL03                         Haugavikneset\n",
      "1149  1246AL30                             Storanipa\n",
      "1394  1422AL11       Renseanlegg Buhaugane hyttefelt\n",
      "1877  1557AL12                Torvikbukt Torvikneset\n",
      "1878  1557AL13                            Angvik Syd\n",
      "2417  2004AL26                  Bekkeli avløpsanlegg\n",
      "2529  5014AL00                           Beinskardet\n",
      "2609  5032AL00                               Overvik\n",
      "2642  5036AL00                   Mostad avløpsanlegg\n"
     ]
    }
   ],
   "source": [
    "# Add TYPE cols\n",
    "stan_df['TYPE'] = 'RENSEANLEGG'\n",
    "milo_df['TYPE'] = 'RENSEANLEGG'\n",
    "ind_df['TYPE'] = 'INDUSTRI'\n",
    "\n",
    "# Get just stn info from each df\n",
    "stan_loc = stan_df[['ANLEGGSNR', 'ANLEGGSNAVN', 'Kommunenr', \n",
    "                    'TYPE', 'Sone', 'UTM_E', 'UTM_N']]\n",
    "\n",
    "milo_loc = milo_df[['ANLEGGSNR', 'ANLEGGSNAVN', 'KOMMUNE_NR', \n",
    "                    'TYPE', 'SONEBELTE', 'UTMOST', 'UTMNORD']]\n",
    "\n",
    "ind_loc = ind_df[['Anleggsnr', 'Anleggsnavn', 'Komm.nr', 'TYPE', \n",
    "                  'Geografisk Longitude', 'Geografisk Latitude']]\n",
    "\n",
    "\n",
    "# Rename cols\n",
    "stan_loc.columns = ['anlegg_nr', 'anlegg_navn', 'komm_no',\n",
    "                    'TYPE', 'zone', 'east', 'north']\n",
    "milo_loc.columns = ['anlegg_nr', 'anlegg_navn', 'komm_no',\n",
    "                    'TYPE', 'zone', 'east', 'north']\n",
    "ind_loc.columns = ['anlegg_nr', 'anlegg_navn', 'komm_no',\n",
    "                   'TYPE', 'lon', 'lat']\n",
    "\n",
    "# Drop duplicates\n",
    "stan_loc.drop_duplicates(inplace=True)\n",
    "milo_loc.drop_duplicates(inplace=True)\n",
    "ind_loc.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert UTM to lat/lon\n",
    "# \"Industri\" data is already in dd\n",
    "stan_loc = rid.utm_to_wgs84_dd(stan_loc, 'zone', 'east', 'north')\n",
    "milo_loc = rid.utm_to_wgs84_dd(milo_loc, 'zone', 'east', 'north')\n",
    "\n",
    "# Remove UTM data \n",
    "del stan_loc['zone'], stan_loc['east'], stan_loc['north']\n",
    "del milo_loc['zone'], milo_loc['east'], milo_loc['north']\n",
    "\n",
    "# combine into single df\n",
    "loc_df = pd.concat([stan_loc, milo_loc, ind_loc], axis=0, sort=True)\n",
    "\n",
    "# The same site can be in multiple files, so drop duplicates\n",
    "loc_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Kommune nr. should be a 4 char string, not a float\n",
    "fmt = lambda x: '%04d' % x\n",
    "loc_df['komm_no'] = loc_df['komm_no'].apply(fmt)\n",
    "\n",
    "# Check ANLEGG_NR is unique\n",
    "assert loc_df.index.duplicated().all() == False, 'Some \"ANLEGGSNRs\" are duplicated.'\n",
    "\n",
    "# Check if any sites are not already in db\n",
    "sql = ('SELECT UNIQUE(ANLEGG_NR) '\n",
    "       'FROM resa2.rid_punktkilder')\n",
    "annr_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "not_in_db = set(loc_df['anlegg_nr'].values) - set(annr_df['anlegg_nr'].values)\n",
    "\n",
    "print ('\\nThe following locations are not in the database:')\n",
    "print (loc_df[loc_df['anlegg_nr'].isin(list(not_in_db))][['anlegg_nr', 'anlegg_navn']])\n",
    "\n",
    "# Check if any sites are missing co-ords\n",
    "print ('\\nThe following locations do not have co-ordinates:')\n",
    "print (loc_df.query('(lat!=lat) or (lon!=lon)')[['anlegg_nr', 'anlegg_navn']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Identify Regine Vassdragsnummer\n",
    "\n",
    "The shapefile here:\n",
    "\n",
    "K:\\Kart\\Regine_2006\\RegMinsteF.shp\n",
    "\n",
    "shows locations for all the Regine catchments used by TEOTIL (see e-mail from John Rune received 29/06/2017 at 17.26). I've copied this file locally here:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\gis\\shapefiles\\RegMinsteF.shp\n",
    "\n",
    "and re-projected it to WGS84 geographic co-ordinates. The new file is called *reg_minste_f_wgs84.shp*.\n",
    "\n",
    "I have also written a function to perform a spatial join and identify which Regine polygon each point is located in.\n",
    "\n",
    "**Note:** Geopandas is quite fussy about its input data (and also to install). The code below works, but the GDAL/OGR version [here](https://stackoverflow.com/a/13433127/505698) might be more robust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Not all sites have complete co-ordinate information. These rows will be dropped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>anlegg_navn</th>\n",
       "      <th>anlegg_nr</th>\n",
       "      <th>komm_no</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>VASSDRAGNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Prestebakke</td>\n",
       "      <td>0101AL01</td>\n",
       "      <td>0101</td>\n",
       "      <td>59.036768</td>\n",
       "      <td>11.532141</td>\n",
       "      <td>001.1A2B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Bakke</td>\n",
       "      <td>0101AL02</td>\n",
       "      <td>0101</td>\n",
       "      <td>59.015311</td>\n",
       "      <td>11.445723</td>\n",
       "      <td>001.2220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Kornsjø</td>\n",
       "      <td>0101AL06</td>\n",
       "      <td>0101</td>\n",
       "      <td>58.935184</td>\n",
       "      <td>11.668959</td>\n",
       "      <td>001.1J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Remmendalen avløpsanlegg</td>\n",
       "      <td>0101AL07</td>\n",
       "      <td>0101</td>\n",
       "      <td>59.120864</td>\n",
       "      <td>11.360106</td>\n",
       "      <td>001.31Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Kambo avløpsanlegg</td>\n",
       "      <td>0104AL01</td>\n",
       "      <td>0104</td>\n",
       "      <td>59.474488</td>\n",
       "      <td>10.686496</td>\n",
       "      <td>003.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TYPE               anlegg_navn anlegg_nr komm_no        lat  \\\n",
       "0  RENSEANLEGG               Prestebakke  0101AL01    0101  59.036768   \n",
       "1  RENSEANLEGG                     Bakke  0101AL02    0101  59.015311   \n",
       "2  RENSEANLEGG                   Kornsjø  0101AL06    0101  58.935184   \n",
       "3  RENSEANLEGG  Remmendalen avløpsanlegg  0101AL07    0101  59.120864   \n",
       "4  RENSEANLEGG        Kambo avløpsanlegg  0104AL01    0104  59.474488   \n",
       "\n",
       "         lon VASSDRAGNR  \n",
       "0  11.532141   001.1A2B  \n",
       "1  11.445723   001.2220  \n",
       "2  11.668959     001.1J  \n",
       "3  11.360106    001.31Z  \n",
       "4  10.686496     003.20  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to Regine catchment shapefile\n",
    "reg_shp_path = r'../../../Data/gis/shapefiles/reg_minste_f_wgs84.shp'\n",
    "\n",
    "# Spatial join\n",
    "loc_df = rid.identify_point_in_polygon(loc_df, reg_shp_path, \n",
    "                                       'anlegg_nr', 'VASSDRAGNR',\n",
    "                                       'lat', 'lon')\n",
    "\n",
    "loc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Restructuring site data\n",
    "\n",
    "For sites dataframe, rename columns to match RESA2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>ANLEGG_NR</th>\n",
       "      <th>ANLEGG_NAVN</th>\n",
       "      <th>KNO</th>\n",
       "      <th>REGINE</th>\n",
       "      <th>LON_UTL</th>\n",
       "      <th>LAT_UTL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0101AL01</td>\n",
       "      <td>Prestebakke</td>\n",
       "      <td>0101</td>\n",
       "      <td>001.1A2B</td>\n",
       "      <td>11.532141</td>\n",
       "      <td>59.036768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0101AL02</td>\n",
       "      <td>Bakke</td>\n",
       "      <td>0101</td>\n",
       "      <td>001.2220</td>\n",
       "      <td>11.445723</td>\n",
       "      <td>59.015311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0101AL06</td>\n",
       "      <td>Kornsjø</td>\n",
       "      <td>0101</td>\n",
       "      <td>001.1J</td>\n",
       "      <td>11.668959</td>\n",
       "      <td>58.935184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0101AL07</td>\n",
       "      <td>Remmendalen avløpsanlegg</td>\n",
       "      <td>0101</td>\n",
       "      <td>001.31Z</td>\n",
       "      <td>11.360106</td>\n",
       "      <td>59.120864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0104AL01</td>\n",
       "      <td>Kambo avløpsanlegg</td>\n",
       "      <td>0104</td>\n",
       "      <td>003.20</td>\n",
       "      <td>10.686496</td>\n",
       "      <td>59.474488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TYPE ANLEGG_NR               ANLEGG_NAVN   KNO    REGINE    LON_UTL  \\\n",
       "0  RENSEANLEGG  0101AL01               Prestebakke  0101  001.1A2B  11.532141   \n",
       "1  RENSEANLEGG  0101AL02                     Bakke  0101  001.2220  11.445723   \n",
       "2  RENSEANLEGG  0101AL06                   Kornsjø  0101    001.1J  11.668959   \n",
       "3  RENSEANLEGG  0101AL07  Remmendalen avløpsanlegg  0101   001.31Z  11.360106   \n",
       "4  RENSEANLEGG  0104AL01        Kambo avløpsanlegg  0104    003.20  10.686496   \n",
       "\n",
       "     LAT_UTL  \n",
       "0  59.036768  \n",
       "1  59.015311  \n",
       "2  58.935184  \n",
       "3  59.120864  \n",
       "4  59.474488  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename other cols to match RESA2\n",
    "loc_df['ANLEGG_NR'] = loc_df['anlegg_nr']\n",
    "loc_df['ANLEGG_NAVN'] = loc_df['anlegg_navn']\n",
    "loc_df['KNO'] = loc_df['komm_no']\n",
    "loc_df['REGINE'] = loc_df['VASSDRAGNR']\n",
    "loc_df['LON_UTL'] = loc_df['lon']\n",
    "loc_df['LAT_UTL'] = loc_df['lat']\n",
    "\n",
    "del loc_df['anlegg_nr'], loc_df['anlegg_navn'], loc_df['komm_no']\n",
    "del loc_df['VASSDRAGNR'], loc_df['lon'], loc_df['lat']\n",
    "\n",
    "loc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>ANLEGG_NR</th>\n",
       "      <th>ANLEGG_NAVN</th>\n",
       "      <th>KNO</th>\n",
       "      <th>REGINE</th>\n",
       "      <th>LON_UTL</th>\n",
       "      <th>LAT_UTL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TYPE, ANLEGG_NR, ANLEGG_NAVN, KNO, REGINE, LON_UTL, LAT_UTL]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get details for sites not already in db\n",
    "loc_upld = loc_df[loc_df['ANLEGG_NR'].isin(list(not_in_db))]\n",
    "\n",
    "loc_upld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_PUNKTKILDER\n",
    "#loc_upld.to_sql('rid_punktkilder', con=engine, schema='resa2', \n",
    "#                if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Restructuring values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year for the data in question\n",
    "year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Anlegg\n",
    "# Get cols of interest \n",
    "stan_vals = stan_df[['ANLEGGSNR', 'MENGDE_P_UT_kg', 'MENGDE_N_UT_kg']]\n",
    "\n",
    "# In RESA2.RID_PUNKTKILDER_INPAR_DEF, N is par_id 44 and P par_id 45\n",
    "stan_vals.columns = ['ANLEGG_NR', 45, 44]\n",
    "\n",
    "# Melt to \"long\" format\n",
    "stan_vals = pd.melt(stan_vals, id_vars='ANLEGG_NR', value_vars=[45, 44],\n",
    "                    var_name='INP_PAR_ID', value_name='VALUE')\n",
    "\n",
    "# Drop NaN values\n",
    "stan_vals.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as I can tell from exploring the 2015 data in the database, the main columns of interest for Miljøgifter are given in `milo_dict`, below, together with the corresponding parameter IDs from `RESA2.RID_PUNKTKILDER_INPAR_DEF`. This hard-coding is a bit messy, but I can't see any database table providing a nice lookup between these values, so they're included here for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miljøgifter\n",
    "# Get cols of interest \n",
    "milo_dict = {'MILJOGIFTHG2':16, \n",
    "             'MILJOGIFTPAH2':48, \n",
    "             'MILJOGIFTPCB2':30, \n",
    "             'MILJOGIFTCD2':8, \n",
    "             'MILJOGIFTDEHP2':119, \n",
    "             'MILJOGIFTAS2':2,\n",
    "             'MILJOGIFTCR2':10, \n",
    "             'MILJOGIFTPB2':28, \n",
    "             'MILJOGIFTNI2':25,\n",
    "             'MILJOGIFTCU2':15, \n",
    "             'MILJOGIFTZN2':38, \n",
    "             'KONSMENGDTOTP10':45,\n",
    "             'KONSMENGDTOTN10':44, \n",
    "             'KONSMENGDSS10':46,\n",
    "             'ANLEGGSNR':'ANLEGG_NR'} # Make heading match RESA\n",
    "\n",
    "milo_vals = milo_df[milo_dict.keys()]\n",
    "\n",
    "# Get par IDs from dict\n",
    "milo_vals.columns = [milo_dict[i] for i in milo_vals.columns]\n",
    "\n",
    "# Melt to \"long\" format\n",
    "milo_vals = pd.melt(milo_vals, id_vars='ANLEGG_NR',\n",
    "                    var_name='INP_PAR_ID', value_name='VALUE')\n",
    "\n",
    "# Drop NaN values\n",
    "milo_vals.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The industry data is already in \"long\" format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Industri\n",
    "# Get cols of interest\n",
    "ind_vals = ind_df[['Anleggsnr', 'Komp.kode', 'Mengde', 'Enhet']]\n",
    "ind_vals.columns = ['anlegg_nr', 'name', 'value', 'unit']\n",
    "\n",
    "# Get par defs from db\n",
    "# Check if any sites are not already in db\n",
    "sql = ('SELECT * '\n",
    "       'FROM resa2.rid_punktkilder_inpar_def')\n",
    "par_df = pd.read_sql_query(sql, engine)\n",
    "del par_df['descr']\n",
    "\n",
    "# Convert all units to capitals\n",
    "ind_vals['unit'] = ind_vals['unit'].str.capitalize()\n",
    "par_df['unit'] = par_df['unit'].str.capitalize()\n",
    "\n",
    "# Join\n",
    "ind_vals = pd.merge(ind_vals, par_df, how='left',\n",
    "                    on=['name', 'unit'])\n",
    "\n",
    "# Some parameters that are not of interest are not matched\n",
    "# Drop these\n",
    "ind_vals.dropna(how='any', inplace=True)\n",
    "\n",
    "# Get just cols of interest\n",
    "ind_vals = ind_vals[['anlegg_nr', 'in_pid', 'value']]\n",
    "\n",
    "# Rename for db\n",
    "ind_vals.columns = ['ANLEGG_NR', 'INP_PAR_ID', 'VALUE']\n",
    "\n",
    "# Convert col types\n",
    "ind_vals['INP_PAR_ID'] = ind_vals['INP_PAR_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "val_df = pd.concat([stan_vals, milo_vals, ind_vals], axis=0, sort=True)\n",
    "\n",
    "# Add column for year\n",
    "val_df['YEAR'] = year\n",
    "\n",
    "# Explicitly set data types\n",
    "val_df['ANLEGG_NR'] = val_df['ANLEGG_NR'].astype(str)\n",
    "val_df['INP_PAR_ID'] = val_df['INP_PAR_ID'].astype(int)\n",
    "val_df['VALUE'] = val_df['VALUE'].astype(float)\n",
    "val_df['YEAR'] = val_df['YEAR'].astype(int)\n",
    "\n",
    "# Store Anlegg and Miljøgifter contain some duplicated information\n",
    "val_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Average any remaining duplciates (because sometimes the same value is reported with different precision)\n",
    "val_df = val_df.groupby(['ANLEGG_NR', 'INP_PAR_ID', 'YEAR']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop any existing values for this year\n",
    "#sql = (\"DELETE FROM resa2.rid_punktkilder_inpar_values \"\n",
    "#       \"WHERE year = %s\" % year)\n",
    "#res = engine.execute(sql)\n",
    "#\n",
    "## Add to RESA2.RID_PUNKTKILDER_INPAR_VALUES \n",
    "#val_df.to_sql('rid_punktkilder_inpar_values', con=engine, schema='resa2', \n",
    "#              if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Små anlegg (small treatment works)\n",
    "\n",
    "An example of the raw data format is here:\n",
    "\n",
    "K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Avløp\\TEOTIL små anlegg 2015 (sendt 18.08.2016).xlsx\n",
    "\n",
    "I have made a local copy of the 2016 file here:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\\avlop_sma_anlegg_2016_raw.xlsx\n",
    "\n",
    "and deleted unnecessary columns. All of this data can be added directly to `RESA2.RID_KILDER_SPREDT_VALUES`. \n",
    "\n",
    "**Note:** The kommuner ID numbers should be present in \n",
    "\n",
    "    ./NOPE/NOPE_Core_Input_Data/regine_2018_onwards.csv\n",
    "    \n",
    "If these need updating, see `update_regine_kommune.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year for the data in question\n",
    "year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following locations are not in the NOPE \"regine\" file:\n",
      "    KOMMUNENR  P_kg   N_kg\n",
      "213      1245  1720  11468\n",
      "284      1567   319   3476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KOMM_NO</th>\n",
       "      <th>INP_PAR_ID</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>AR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0101</td>\n",
       "      <td>45</td>\n",
       "      <td>649</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0104</td>\n",
       "      <td>45</td>\n",
       "      <td>96</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0105</td>\n",
       "      <td>45</td>\n",
       "      <td>1220</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0106</td>\n",
       "      <td>45</td>\n",
       "      <td>183</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0111</td>\n",
       "      <td>45</td>\n",
       "      <td>23</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  KOMM_NO INP_PAR_ID  VALUE    AR\n",
       "0    0101         45    649  2018\n",
       "1    0104         45     96  2018\n",
       "2    0105         45   1220  2018\n",
       "3    0106         45    183  2018\n",
       "4    0111         45     23  2018"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read raw (tidied) data\n",
    "in_xlsx = r'../../../Data/point_data_%s/avlop_sma_anlegg_%s_raw.xlsx' % (year, year)\n",
    "sman_df = pd.read_excel(in_xlsx, \n",
    "                        sheet_name='sma_anlegg_%s' % year)\n",
    "\n",
    "# Drop blank rows\n",
    "sman_df.dropna(how='all', inplace=True)\n",
    "\n",
    "# Kommune nr. should be a 4 char string, not a float\n",
    "fmt = lambda x: '%04d' % x\n",
    "sman_df['KOMMUNENR'] = sman_df['KOMMUNENR'].apply(fmt)\n",
    "\n",
    "# Check if any kommuner are not already in NOPE\n",
    "reg_csv = r'../../../NOPE/NOPE_Core_Input_Data/regine_2018_onwards.csv'\n",
    "kmnr_df = pd.read_csv(reg_csv, sep=';', encoding='utf-8')\n",
    "kmnr_df['komnr'] = kmnr_df['komnr'].apply(fmt)\n",
    "\n",
    "not_in_db = set(sman_df['KOMMUNENR'].values) - set(kmnr_df['komnr'].values)\n",
    "\n",
    "print ('\\nThe following locations are not in the NOPE \"regine\" file:')\n",
    "print (sman_df[sman_df['KOMMUNENR'].isin(list(not_in_db))])\n",
    "\n",
    "# Get cols of interest for RID_KILDER_SPREDT_VALUES\n",
    "sman_df = sman_df[['KOMMUNENR', 'P_kg', 'N_kg']]\n",
    "\n",
    "# In RESA2.RID_PUNKTKILDER_INPAR_DEF, N is par_id 44 and P par_id 45\n",
    "sman_df.columns = ['KOMM_NO', 45, 44]\n",
    "\n",
    "# Melt to \"long\" format\n",
    "sman_df = pd.melt(sman_df, id_vars='KOMM_NO', value_vars=[45, 44],\n",
    "                  var_name='INP_PAR_ID', value_name='VALUE')\n",
    "\n",
    "# Add column for year\n",
    "sman_df['AR'] = year\n",
    "\n",
    "sman_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_KILDER_SPREDT_VALUES\n",
    "#sman_df.to_sql('rid_kilder_spredt_values', con=engine, schema='resa2', \n",
    "#               if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fish farms\n",
    "\n",
    "An example of the raw data is here:\n",
    "\n",
    " * K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Fiskeoppdrett\\Teotil - 2015 (2) (pr. 09.08.16).xlsx.zip\n",
    "\n",
    "I have made a local copy of the 2016 file here:\n",
    "\n",
    " * C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\\fiske_oppdret_2016_raw.xlsx\n",
    "\n",
    "The data must be added to two tables in RESA2:\n",
    "\n",
    " * First, the site data must be added to `RESA2.RID_KILDER_AQUAKULTUR`. Most of the sites should already be there, but occasionally new sites are added. Any new stations must be be assigned lat/lon co-ordinates and the appropriate \"Regine\" catchment ID. This usually requires geocoding plus co-ordinate conversions and/or a spatial join to determine catchment IDs.\n",
    " \n",
    "    **Note:** The key ID fields in the raw data appear to be `LOKNR` and `LOKNAVN`. <br><br>\n",
    " \n",
    " * Secondly, the chemistry data for each site must be extracted and converted to \"long\" format, then added to `RESA2.RID_KILDER_AQKULT_VALUES`. Parameter IDs etc. are taken from `RESA2.RID_PUNKTKILDER_INPAR_DEF`.\n",
    " \n",
    "### 3.1. Basic data checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year for the data in question\n",
    "year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw (tidied) data\n",
    "# Fish farms\n",
    "in_xlsx = r'../../../Data/point_data_%s/fiske_oppdret_%s_raw.xlsx' % (year, year)\n",
    "fish_df = pd.read_excel(in_xlsx, sheet_name='Ark1')\n",
    "\n",
    "# Drop no data\n",
    "fish_df.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following locations are not in the database:\n",
      "Empty DataFrame\n",
      "Columns: [LOKNR, LOKNAVN, N_DESIMALGRADER_Y, O_DESIMALGRADER_X]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check if any sites are not already in db\n",
    "sql = ('SELECT UNIQUE(NR) '\n",
    "       'FROM resa2.rid_kilder_aquakultur')\n",
    "aqua_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "not_in_db = set(fish_df['LOKNR'].values) - set(aqua_df['nr'].values)\n",
    "\n",
    "nidb_df = fish_df[fish_df['LOKNR'].isin(list(not_in_db))][['LOKNR', 'LOKNAVN', \n",
    "                                                           'N_DESIMALGRADER_Y',\n",
    "                                                           'O_DESIMALGRADER_X']].drop_duplicates(subset=['LOKNR'])\n",
    "\n",
    "print ('\\nThe following locations are not in the database:')\n",
    "print (nidb_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Geocode fish farms and add to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Regine catchment shapefile\n",
    "reg_shp_path = r'../../../Data/gis/shapefiles/reg_minste_f_wgs84.shp'\n",
    "\n",
    "# Spatial join\n",
    "if len(nidb_df) > 0:\n",
    "    loc_df = rid.identify_point_in_polygon(nidb_df, reg_shp_path, \n",
    "                                           'LOKNR', 'VASSDRAGNR',\n",
    "                                           'N_DESIMALGRADER_Y',\n",
    "                                           'O_DESIMALGRADER_X')\n",
    "\n",
    "    # Rename cols\n",
    "    loc_df.columns = ['NR', 'NAVN', 'LENGDE', 'BREDDE', 'REGINE']\n",
    "\n",
    "    loc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_KILDER_AQUAKULTUR\n",
    "#loc_df.to_sql('rid_kilder_aquakultur', con=engine, schema='resa2', \n",
    "#              if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Estimate nutrient inputs\n",
    "\n",
    "The methodology here is a little unclear. The following is my best guess, based on the files located here:\n",
    "\n",
    "K:\\Avdeling\\Vass\\316_Miljøinformatikk\\Prosjekter\\RID\\2016\\Rådata\\Fiskeoppdrett\n",
    "\n",
    "Old workflow:\n",
    "\n",
    " 1. Calculate the fish biomass from the raw data. See the equation in the `Biomasse` column of the spreadsheet *JSE_TEOTIL_2015.xlsx* <br><br>\n",
    " \n",
    " 2. Split the data according to salmon (\"laks\"; species ID 71101) and trout (\"øret\"; species ID 71401), then group by location and month, summing biomass and `FORFORBRUK_KILO` columns (see Fiskeoppdrett_biomasse_2016.accdb) <br><br>\n",
    " \n",
    " 3. Calculate production. This involves combining biomass for the current month with that for the previous month. See the calculations in e.g. *N_P_ørret_2015.xlsx*. <br><br>\n",
    " \n",
    " 4. Calculate NTAP and PTAP. **NB:** I don't know what these quantities are, so I'm just blindly duplicating the Excel calculations in the code below. The functions are therefore not very well explained <br><br>\n",
    " \n",
    " 5. Estimate copper usage at each fish farm by scaling the total annual Cu usage in proportion to P production. For 2018, John Rune has supplied an annual Cu value of **1217 tonnes** (see e-mail received 15.10.2019 at 10.27)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANLEGG_NR</th>\n",
       "      <th>INP_PAR_ID</th>\n",
       "      <th>AR</th>\n",
       "      <th>MANED</th>\n",
       "      <th>ART</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10041</td>\n",
       "      <td>39</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74713.494563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10045</td>\n",
       "      <td>39</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>523.987021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10050</td>\n",
       "      <td>39</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12950.678402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10054</td>\n",
       "      <td>39</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172448.826660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10078</td>\n",
       "      <td>39</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1966.837565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ANLEGG_NR INP_PAR_ID    AR  MANED  ART          VALUE\n",
       "0      10041         39  2018      6  NaN   74713.494563\n",
       "1      10045         39  2018      6  NaN     523.987021\n",
       "2      10050         39  2018      6  NaN   12950.678402\n",
       "3      10054         39  2018      6  NaN  172448.826660\n",
       "4      10078         39  2018      6  NaN    1966.837565"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Annual Cu usage in tonnes\n",
    "an_cu = 1217\n",
    "\n",
    "# Estimate nutrient inputs from fish farns\n",
    "fish_nut = rid.estimate_fish_farm_nutrient_inputs(fish_df, year, an_cu)\n",
    "\n",
    "fish_nut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_KILDER_AQKULT_VALUES\n",
    "#fish_nut.to_sql('rid_kilder_aqkult_values', con=engine, schema='resa2', \n",
    "#                if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Land use\n",
    "\n",
    "An example of the raw data is here:\n",
    "\n",
    " * K:\\Avdeling\\Vass\\316_Miljøinformatikk\\Prosjekter\\RID\\2016\\Rådata\\Jordbruk\\to-niva.2015.xls\n",
    "\n",
    "Note that this file is not really an Excel file and opening it directly creates errors. I have corrected the data format, tidied the column headings and made a local copy of the 2016 data here:\n",
    "\n",
    " * C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\\jordbruk_2016.xlsx\n",
    " \n",
    "This is added to the table `RESA2.RID_AGRI_INPUTS`.\n",
    "\n",
    "**Note:** In recent years, the entry for Oslo (fylke_sone = 3_1) has been missing from the data provided by Bioforsk. This row should be added manually to the Excel file using `omrade = \"osl1\"`. The values should be identical to those for område `ake2`. This works because the land areas in `RID_Fylke-Sone_LU_Areas.xlsx` have been made identical for `osl1` and `ake2` (even though this is not correct), so the inputs in terms of kg/km2 are calculated as being the same for both regions, which is what is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year for the data in question\n",
    "year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>omrade</th>\n",
       "      <th>year</th>\n",
       "      <th>n_diff_kg</th>\n",
       "      <th>n_point_kg</th>\n",
       "      <th>n_back_kg</th>\n",
       "      <th>p_diff_kg</th>\n",
       "      <th>p_point_kg</th>\n",
       "      <th>p_back_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>øst1</td>\n",
       "      <td>2018</td>\n",
       "      <td>717665</td>\n",
       "      <td>8338</td>\n",
       "      <td>157590</td>\n",
       "      <td>41091</td>\n",
       "      <td>674</td>\n",
       "      <td>3563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>øst2</td>\n",
       "      <td>2018</td>\n",
       "      <td>1139830</td>\n",
       "      <td>5451</td>\n",
       "      <td>194922</td>\n",
       "      <td>21855</td>\n",
       "      <td>457</td>\n",
       "      <td>3422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>øst3</td>\n",
       "      <td>2018</td>\n",
       "      <td>214878</td>\n",
       "      <td>1048</td>\n",
       "      <td>39159</td>\n",
       "      <td>5143</td>\n",
       "      <td>90</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ake1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1594487</td>\n",
       "      <td>9164</td>\n",
       "      <td>237631</td>\n",
       "      <td>62668</td>\n",
       "      <td>1470</td>\n",
       "      <td>5554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ake2</td>\n",
       "      <td>2018</td>\n",
       "      <td>719786</td>\n",
       "      <td>1905</td>\n",
       "      <td>117703</td>\n",
       "      <td>21904</td>\n",
       "      <td>245</td>\n",
       "      <td>2221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  omrade  year  n_diff_kg  n_point_kg  n_back_kg  p_diff_kg  p_point_kg  \\\n",
       "0   øst1  2018     717665        8338     157590      41091         674   \n",
       "1   øst2  2018    1139830        5451     194922      21855         457   \n",
       "2   øst3  2018     214878        1048      39159       5143          90   \n",
       "3   ake1  2018    1594487        9164     237631      62668        1470   \n",
       "4   ake2  2018     719786        1905     117703      21904         245   \n",
       "\n",
       "   p_back_kg  \n",
       "0       3563  \n",
       "1       3422  \n",
       "2        759  \n",
       "3       5554  \n",
       "4       2221  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to (tidied) Bioforsk data\n",
    "in_xlsx = r'../../../Data/point_data_%s/jordbruk_%s.xlsx' % (year, year)\n",
    "\n",
    "lu_df = pd.read_excel(in_xlsx)\n",
    "\n",
    "# Add year\n",
    "lu_df['year'] = year\n",
    "\n",
    "# Order cols\n",
    "lu_df = lu_df[['omrade', 'year', 'n_diff_kg', 'n_point_kg', \n",
    "               'n_back_kg', 'p_diff_kg', 'p_point_kg', \n",
    "               'p_back_kg']]\n",
    "\n",
    "lu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to RESA\n",
    "#lu_df.to_sql(name='rid_agri_inputs', con=engine, \n",
    "#             schema='resa2', index=False,\n",
    "#             if_exists='append',\n",
    "#             dtype={'omrade': types.VARCHAR(lu_df['omrade'].str.len().max())})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
