{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import imp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geopandas.tools\n",
    "import pyproj\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from sqlalchemy import types\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "sn.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process model input datasets\n",
    "\n",
    "Modelling for the RID programme makes use of the following input datasets:\n",
    "\n",
    " * **Avløp** (sewage and other drainage), sub-divided into\n",
    "     * Large treatment works\n",
    "     * Small treatment works\n",
    "     * Other environmental pollutants <br><br>\n",
    "     \n",
    " * **Fiskeoppdret** (Fish farming) <br><br>\n",
    " \n",
    " * **Industri** (industrial point sources) <br><br>\n",
    " \n",
    " * **Jordbruk** (land use and management activities)\n",
    " \n",
    "The raw datasets come from a variety of different sources and must be restructured into a standardised format and added to the RESA2 database. Once in the database, these can can either be used to generate input files for TEOTIL (using either Tore's code or the workflow documented [here](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/prepare_teotil_inputs.ipynb)), or they can be used to run the new [NOPE model](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/nope_model.ipynb). Generating input files for NOPE from the data in RESA2 is very straightforward: simply call `nope.make_rid_input_file()` for the year of interest.\n",
    "\n",
    "This notebook takes the raw data, restructures it, and adds it to RESA2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "resa2_basic_path = (r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\Upload_Template'\n",
    "                    r'\\useful_resa2_code.py')\n",
    "\n",
    "resa2_basic = imp.load_source('useful_resa2_code', resa2_basic_path)\n",
    "\n",
    "engine, conn = resa2_basic.connect_to_resa2()\n",
    "\n",
    "# Import custom RID functions\n",
    "rid_func_path = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "                 r'\\Python\\rid\\notebooks\\useful_rid_code.py')\n",
    "\n",
    "rid = imp.load_source('useful_rid_code', rid_func_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Store anlegg, Miljøgifter and Industri\n",
    "\n",
    "These three datasets are all treated similarly, and there is some duplication between the files. Examples of the raw data formats are here:\n",
    "\n",
    " * K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Avløp\\TEOTIL store anlegg 2015 (sendt 18.08.2016).xlsx\n",
    "\n",
    " * K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Avløp\\Miljogifter_NIVA_RID-prosjektet_2015.xlsx\n",
    "\n",
    " * K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Industri\\Teotiluttrekket til NIVA - 2016_v2.xlsx\n",
    "\n",
    "I have made local copies of the 2016 data files here:\n",
    "\n",
    " * C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\n",
    "\n",
    "and tidied all the column headings. See also the information in the e-mail from John Rune received 29/06/2017 at 15.53. \n",
    "\n",
    "**Note:** The raw data files for industry often contain several years of data. For the file in the folder above, I've filtered the values to only include the year of interest.\n",
    "\n",
    "The data in these files must be added to two tables in RESA2:\n",
    "\n",
    " * First, the site data must be added to `RESA2.RID_PUNKTKILDER`. Most of the sites should already be there, but occasionally new sites are added. Any new stations must be be assigned lat/lon co-ordinates and the appropriate \"Regine\" catchment ID. This usually requires geocoding plus co-ordinate conversions and/or a spatial join to determine catchment IDs.\n",
    " \n",
    "    **Note:** Many (>70) of the stations already in the database are missing Regine IDs. Many more (>3000) are missing co-ordinate information. We have previously asked Miljødirektoratet about this, but they have not yet provided the missing data. <br><br>\n",
    " \n",
    " * Secondly, the chemistry data for each site must be extracted and converted to \"long\" format, then added to `RESA2.RID_PUNKTKILDER_INPAR_VALUES`. Parameter IDs etc. are taken from `RESA2.RID_PUNKTKILDER_INPAR_DEF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read raw (tidied) data\n",
    "\n",
    "# Store anlegg\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\point_data_2016\\avlop_stor_anlegg_2016_raw.xlsx')\n",
    "stan_df = pd.read_excel(in_xlsx, sheetname='store_anlegg_2016')\n",
    "\n",
    "# Miljøgifter\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\point_data_2016\\avlop_miljogifter_2016_raw.xlsx')\n",
    "milo_df = pd.read_excel(in_xlsx, sheetname='miljogifter_2016')\n",
    "\n",
    "# Industri\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\point_data_2016\\industri_2016_raw.xlsx')\n",
    "ind_df = pd.read_excel(in_xlsx, sheetname='industry_2016')\n",
    "\n",
    "# Drop blank rows\n",
    "stan_df.dropna(how='all', inplace=True)\n",
    "milo_df.dropna(how='all', inplace=True)\n",
    "ind_df.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Basic data checking\n",
    "\n",
    "All of the \"Store Anlegg\" and \"Miljøgifter\" sites are classified as `RENSEANLEGG` in the `TYPE` column of `RESA2.RID_PUNKTKILDER`; \"Industri\" sites as labelled `INDUSTRI`.\n",
    "\n",
    "Add `TYPE` columns, merge site data from different sources, convert UTM co-ordinates to WGS84 decimal degrees and identify sites not already in the database. Issues identified below (e.g. missing co-ordinates) should be corrected if possible before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following locations are not in the database:\n",
      "Empty DataFrame\n",
      "Columns: [anlegg_nr, anlegg_navn]\n",
      "Index: []\n",
      "\n",
      "The following locations do not have co-ordinates:\n",
      "     anlegg_nr                          anlegg_navn\n",
      "55    0226AL71          MIRA renseanlegg (v/Tangen)\n",
      "136   0430AL03                    Koppang rensepark\n",
      "342   0615AL11        Damtjernhallin 2 avløpsanlegg\n",
      "343   0615AL12  Solheimseter, Sørbølfjell - trinn 1\n",
      "349   0617AL19       Einarset Stølslag Felt H1 + H5\n",
      "353   0617AL90                  Brekko Camping r.a.\n",
      "365   0619AL69                        Øyni menighet\n",
      "377   0621AL37                     Nedre Eggedal RA\n",
      "399   0626AL64                          Tronstad RA\n",
      "410   0631AL32            Borge–Blestua hytteområde\n",
      "413   0633AL21           EKT FJELLGÅRD OG LEIRSKOLE\n",
      "414   0633AL24                IMINGFJELL TURISTHEIM\n",
      "621   1101AL28                          Trosavig RA\n",
      "666   1114AL18                      Stavtjørnknuten\n",
      "768   1141AL43                   Østabøvågen Talgje\n",
      "827   1149AL97                Torvvika avløpsanlegg\n",
      "908   1219AL15          Høvringevika, Ytre Røyksund\n",
      "909   1219AL16                Heio, Mosterhamn aust\n",
      "910   1219AL17                               Innvær\n",
      "1019  1238AL20                  Øystese-Norheimsund\n",
      "1104  1246AL30                            Storanipa\n",
      "1843  1557AL11                      Torvikbukt vest\n",
      "1844  1560AL00                               Årsund\n",
      "1847  1560AL03                             Holmeide\n",
      "1851  1560AL13                     TINGVOLL SENTRUM\n",
      "1972  1638AL33                       Bjørkøybekk RA\n",
      "2333  1851AL04                     LØDINGEN, Tippen\n",
      "2372  1860AL31                                Havet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Data\\WinPython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\util\\decorators.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Add TYPE cols\n",
    "stan_df['TYPE'] = 'RENSEANLEGG'\n",
    "milo_df['TYPE'] = 'RENSEANLEGG'\n",
    "ind_df['TYPE'] = 'INDUSTRI'\n",
    "\n",
    "# Get just stn info from each df\n",
    "stan_loc = stan_df[['ANLEGGSNR', 'ANLEGGSNAVN', 'Kommunenr', \n",
    "                    'TYPE', 'Sone', 'UTM_E', 'UTM_N']]\n",
    "\n",
    "milo_loc = milo_df[['ANLEGGSNR', 'ANLEGGSNAVN', 'KOMMUNE_NR', \n",
    "                    'TYPE', 'SONEBELTE', 'UTMOST', 'UTMNORD']]\n",
    "\n",
    "ind_loc = ind_df[['Anleggsnr', 'Anleggsnavn', 'Komm.nr', 'TYPE', \n",
    "                  'Geografisk Longitude', 'Geografisk Latitude']]\n",
    "\n",
    "\n",
    "# Rename cols\n",
    "stan_loc.columns = ['anlegg_nr', 'anlegg_navn', 'komm_no',\n",
    "                    'TYPE', 'zone', 'east', 'north']\n",
    "milo_loc.columns = ['anlegg_nr', 'anlegg_navn', 'komm_no',\n",
    "                    'TYPE', 'zone', 'east', 'north']\n",
    "ind_loc.columns = ['anlegg_nr', 'anlegg_navn', 'komm_no',\n",
    "                   'TYPE', 'lon', 'lat']\n",
    "\n",
    "# Drop duplicates\n",
    "stan_loc.drop_duplicates(inplace=True)\n",
    "milo_loc.drop_duplicates(inplace=True)\n",
    "ind_loc.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert UTM to lat/lon\n",
    "# \"Industri\" data is already in dd\n",
    "stan_loc = rid.utm_to_wgs84_dd(stan_loc, 'zone', 'east', 'north')\n",
    "milo_loc = rid.utm_to_wgs84_dd(milo_loc, 'zone', 'east', 'north')\n",
    "\n",
    "# Remove UTM data \n",
    "del stan_loc['zone'], stan_loc['east'], stan_loc['north']\n",
    "del milo_loc['zone'], milo_loc['east'], milo_loc['north']\n",
    "\n",
    "# combine into single df\n",
    "loc_df = pd.concat([stan_loc, milo_loc, ind_loc], axis=0)\n",
    "\n",
    "# The same site can be in multiple files, so drop duplicates\n",
    "loc_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Kommune nr. should be a 4 char string, not a float\n",
    "fmt = lambda x: '%04d' % x\n",
    "loc_df['komm_no'] = loc_df['komm_no'].apply(fmt)\n",
    "\n",
    "# Check ANLEGG_NR is unique\n",
    "assert loc_df.index.duplicated().all() == False, 'Some \"ANLEGGSNRs\" are duplicated.'\n",
    "\n",
    "# Check if any sites are not already in db\n",
    "sql = ('SELECT UNIQUE(ANLEGG_NR) '\n",
    "       'FROM resa2.rid_punktkilder')\n",
    "annr_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "not_in_db = set(loc_df['anlegg_nr'].values) - set(annr_df['anlegg_nr'].values)\n",
    "\n",
    "print '\\nThe following locations are not in the database:'\n",
    "print loc_df[loc_df['anlegg_nr'].isin(list(not_in_db))][['anlegg_nr', 'anlegg_navn']]\n",
    "\n",
    "# Check if any sites are missing co-ords\n",
    "print '\\nThe following locations do not have co-ordinates:'\n",
    "print loc_df.query('(lat!=lat) or (lon!=lon)')[['anlegg_nr', 'anlegg_navn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Identify Regine Vassdragsnummer\n",
    "\n",
    "The shapefile here:\n",
    "\n",
    "K:\\Kart\\Regine_2006\\RegMinsteF.shp\n",
    "\n",
    "shows locations for all the Regine catchments used by TEOTIL (see e-mail from John Rune received 29/06/2017 at 17.26). I've copied this file locally here:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\gis\\shapefiles\\RegMinsteF.shp\n",
    "\n",
    "and re-projected it to WGS84 geographic co-ordinates. The new file is called *reg_minste_f_wgs84.shp*.\n",
    "\n",
    "I have also written a function to perform a spatial join and identify which Regine polygon each point is located in.\n",
    "\n",
    "**Note:** Geopandas is quite fussy about its input data (and also to install). The code below works, but the GDAL/OGR version [here](https://stackoverflow.com/a/13433127/505698) might be more robust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Not all sites have complete co-ordinate information. These rows will be dropped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>anlegg_navn</th>\n",
       "      <th>anlegg_nr</th>\n",
       "      <th>komm_no</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>VASSDRAGNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Bakke</td>\n",
       "      <td>0101AL02</td>\n",
       "      <td>0101</td>\n",
       "      <td>59.019598</td>\n",
       "      <td>11.443762</td>\n",
       "      <td>001.2220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Kornsjø</td>\n",
       "      <td>0101AL06</td>\n",
       "      <td>0101</td>\n",
       "      <td>58.935184</td>\n",
       "      <td>11.668959</td>\n",
       "      <td>001.1J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Remmendalen avløpsanlegg</td>\n",
       "      <td>0101AL07</td>\n",
       "      <td>0101</td>\n",
       "      <td>59.120864</td>\n",
       "      <td>11.360106</td>\n",
       "      <td>001.31Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Kambo</td>\n",
       "      <td>0104AL01</td>\n",
       "      <td>0104</td>\n",
       "      <td>59.474488</td>\n",
       "      <td>10.686496</td>\n",
       "      <td>003.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Alvim Renseanlegg</td>\n",
       "      <td>0105AL00</td>\n",
       "      <td>0105</td>\n",
       "      <td>59.273056</td>\n",
       "      <td>11.075773</td>\n",
       "      <td>002.A4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TYPE               anlegg_navn anlegg_nr komm_no        lat  \\\n",
       "0  RENSEANLEGG                     Bakke  0101AL02    0101  59.019598   \n",
       "1  RENSEANLEGG                   Kornsjø  0101AL06    0101  58.935184   \n",
       "2  RENSEANLEGG  Remmendalen avløpsanlegg  0101AL07    0101  59.120864   \n",
       "3  RENSEANLEGG                     Kambo  0104AL01    0104  59.474488   \n",
       "4  RENSEANLEGG         Alvim Renseanlegg  0105AL00    0105  59.273056   \n",
       "\n",
       "         lon VASSDRAGNR  \n",
       "0  11.443762   001.2220  \n",
       "1  11.668959     001.1J  \n",
       "2  11.360106    001.31Z  \n",
       "3  10.686496     003.20  \n",
       "4  11.075773     002.A4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to Regine catchment shapefile\n",
    "reg_shp_path = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "                r'\\Data\\gis\\shapefiles\\reg_minste_f_wgs84.shp')\n",
    "\n",
    "# Spatial join\n",
    "loc_df = rid.identify_point_in_polygon(loc_df, reg_shp_path, \n",
    "                                       'anlegg_nr', 'VASSDRAGNR',\n",
    "                                       'lat', 'lon')\n",
    "\n",
    "loc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Restructuring site data\n",
    "\n",
    "For sites dataframe, rename columns to match RESA2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>ANLEGG_NR</th>\n",
       "      <th>ANLEGG_NAVN</th>\n",
       "      <th>KNO</th>\n",
       "      <th>REGINE</th>\n",
       "      <th>LON_UTL</th>\n",
       "      <th>LAT_UTL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0101AL02</td>\n",
       "      <td>Bakke</td>\n",
       "      <td>0101</td>\n",
       "      <td>001.2220</td>\n",
       "      <td>11.443762</td>\n",
       "      <td>59.019598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0101AL06</td>\n",
       "      <td>Kornsjø</td>\n",
       "      <td>0101</td>\n",
       "      <td>001.1J</td>\n",
       "      <td>11.668959</td>\n",
       "      <td>58.935184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0101AL07</td>\n",
       "      <td>Remmendalen avløpsanlegg</td>\n",
       "      <td>0101</td>\n",
       "      <td>001.31Z</td>\n",
       "      <td>11.360106</td>\n",
       "      <td>59.120864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0104AL01</td>\n",
       "      <td>Kambo</td>\n",
       "      <td>0104</td>\n",
       "      <td>003.20</td>\n",
       "      <td>10.686496</td>\n",
       "      <td>59.474488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0105AL00</td>\n",
       "      <td>Alvim Renseanlegg</td>\n",
       "      <td>0105</td>\n",
       "      <td>002.A4</td>\n",
       "      <td>11.075773</td>\n",
       "      <td>59.273056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TYPE ANLEGG_NR               ANLEGG_NAVN   KNO    REGINE    LON_UTL  \\\n",
       "0  RENSEANLEGG  0101AL02                     Bakke  0101  001.2220  11.443762   \n",
       "1  RENSEANLEGG  0101AL06                   Kornsjø  0101    001.1J  11.668959   \n",
       "2  RENSEANLEGG  0101AL07  Remmendalen avløpsanlegg  0101   001.31Z  11.360106   \n",
       "3  RENSEANLEGG  0104AL01                     Kambo  0104    003.20  10.686496   \n",
       "4  RENSEANLEGG  0105AL00         Alvim Renseanlegg  0105    002.A4  11.075773   \n",
       "\n",
       "     LAT_UTL  \n",
       "0  59.019598  \n",
       "1  58.935184  \n",
       "2  59.120864  \n",
       "3  59.474488  \n",
       "4  59.273056  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename other cols to match RESA2\n",
    "loc_df['ANLEGG_NR'] = loc_df['anlegg_nr']\n",
    "loc_df['ANLEGG_NAVN'] = loc_df['anlegg_navn']\n",
    "loc_df['KNO'] = loc_df['komm_no']\n",
    "loc_df['REGINE'] = loc_df['VASSDRAGNR']\n",
    "loc_df['LON_UTL'] = loc_df['lon']\n",
    "loc_df['LAT_UTL'] = loc_df['lat']\n",
    "\n",
    "del loc_df['anlegg_nr'], loc_df['anlegg_navn'], loc_df['komm_no']\n",
    "del loc_df['VASSDRAGNR'], loc_df['lon'], loc_df['lat']\n",
    "\n",
    "loc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>ANLEGG_NR</th>\n",
       "      <th>ANLEGG_NAVN</th>\n",
       "      <th>KNO</th>\n",
       "      <th>REGINE</th>\n",
       "      <th>LON_UTL</th>\n",
       "      <th>LAT_UTL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TYPE, ANLEGG_NR, ANLEGG_NAVN, KNO, REGINE, LON_UTL, LAT_UTL]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get details for sites not already in db\n",
    "loc_upld = loc_df[loc_df['ANLEGG_NR'].isin(list(not_in_db))]\n",
    "\n",
    "loc_upld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_PUNKTKILDER\n",
    "#loc_upld.to_sql('rid_punktkilder', con=engine, schema='resa2', \n",
    "#                if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Restructuring values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the year for the data in question\n",
    "year = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store Anlegg\n",
    "# Get cols of interest \n",
    "stan_vals = stan_df[['ANLEGGSNR', 'MENGDE_P_UT_kg', 'MENGDE_N_UT_kg']]\n",
    "\n",
    "# In RESA2.RID_PUNKTKILDER_INPAR_DEF, N is par_id 44 and P par_id 45\n",
    "stan_vals.columns = ['ANLEGG_NR', 45, 44]\n",
    "\n",
    "# Melt to \"long\" format\n",
    "stan_vals = pd.melt(stan_vals, id_vars='ANLEGG_NR', value_vars=[45, 44],\n",
    "                    var_name='INP_PAR_ID', value_name='VALUE')\n",
    "\n",
    "# Drop NaN values\n",
    "stan_vals.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as I can tell from exploring the 2015 data in the database, the main columns of interest for Miljøgifter are given in `milo_dict`, below, together with the corresponding parameter IDs from `RESA2.RID_PUNKTKILDER_INPAR_DEF`. This hard-coding is a bit messy, but I can't see any database table providing a nice lookup between these values, so they're included here for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Miljøgifter\n",
    "# Get cols of interest \n",
    "milo_dict = {'MILJOGIFTHG2':16, \n",
    "             'MILJOGIFTPAH2':48, \n",
    "             'MILJOGIFTPCB2':30, \n",
    "             'MILJOGIFTCD2':8, \n",
    "             'MILJOGIFTDEHP2':119, \n",
    "             'MILJOGIFTAS2':2,\n",
    "             'MILJOGIFTCR2':10, \n",
    "             'MILJOGIFTPB2':28, \n",
    "             'MILJOGIFTNI2':25,\n",
    "             'MILJOGIFTCU2':15, \n",
    "             'MILJOGIFTZN2':38, \n",
    "             'KONSMENGDTOTP10':45,\n",
    "             'KONSMENGDTOTN10':44, \n",
    "             'KONSMENGDSS10':46,\n",
    "             'ANLEGGSNR':'ANLEGG_NR'} # Make heading match RESA\n",
    "\n",
    "milo_vals = milo_df[milo_dict.keys()]\n",
    "\n",
    "# Get par IDs from dict\n",
    "milo_vals.columns = [milo_dict[i] for i in milo_vals.columns]\n",
    "\n",
    "# Melt to \"long\" format\n",
    "milo_vals = pd.melt(milo_vals, id_vars='ANLEGG_NR',\n",
    "                    var_name='INP_PAR_ID', value_name='VALUE')\n",
    "\n",
    "# Drop NaN values\n",
    "milo_vals.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The industry data is already in \"long\" format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Data\\WinPython-64bit-2.7.10.3\\python-2.7.10.amd64\\lib\\site-packages\\ipykernel\\__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Industri\n",
    "# Get cols of interest\n",
    "ind_vals = ind_df[['Anleggsnr', 'Komp.kode', 'Mengde', 'Enhet']]\n",
    "ind_vals.columns = ['anlegg_nr', 'name', 'value', 'unit']\n",
    "\n",
    "# Get par defs from db\n",
    "# Check if any sites are not already in db\n",
    "sql = ('SELECT * '\n",
    "       'FROM resa2.rid_punktkilder_inpar_def')\n",
    "par_df = pd.read_sql_query(sql, engine)\n",
    "del par_df['descr']\n",
    "\n",
    "# Convert all units to capitals\n",
    "ind_vals['unit'] = ind_vals['unit'].str.capitalize()\n",
    "par_df['unit'] = par_df['unit'].str.capitalize()\n",
    "\n",
    "# Join\n",
    "ind_vals = pd.merge(ind_vals, par_df, how='left',\n",
    "                    on=['name', 'unit'])\n",
    "\n",
    "# Some parameters that are not of interest are not matched\n",
    "# Drop these\n",
    "ind_vals.dropna(how='any', inplace=True)\n",
    "\n",
    "# Get just cols of interest\n",
    "ind_vals = ind_vals[['anlegg_nr', 'in_pid', 'value']]\n",
    "\n",
    "# Rename for db\n",
    "ind_vals.columns = ['ANLEGG_NR', 'INP_PAR_ID', 'VALUE']\n",
    "\n",
    "# Convert col types\n",
    "ind_vals['INP_PAR_ID'] = ind_vals['INP_PAR_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine\n",
    "val_df = pd.concat([stan_vals, milo_vals, ind_vals], axis=0)\n",
    "\n",
    "# Add column for year\n",
    "val_df['YEAR'] = year\n",
    "\n",
    "# Explicitly set data types\n",
    "val_df['ANLEGG_NR'] = val_df['ANLEGG_NR'].astype(str)\n",
    "val_df['INP_PAR_ID'] = val_df['INP_PAR_ID'].astype(int)\n",
    "val_df['VALUE'] = val_df['VALUE'].astype(float)\n",
    "val_df['YEAR'] = val_df['YEAR'].astype(int)\n",
    "\n",
    "# Store Anlegg and Miljøgifter contain some duplicated information\n",
    "val_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop any existing values for this year\n",
    "#sql = (\"DELETE FROM resa2.rid_punktkilder_inpar_values \"\n",
    "#       \"WHERE year = %s\" % year)\n",
    "#res = conn.execute(sql)\n",
    "\n",
    "# Add to RESA2.RID_PUNKTKILDER_INPAR_VALUES \n",
    "#val_df.to_sql('rid_punktkilder_inpar_values', con=engine, schema='resa2', \n",
    "#              if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Små anlegg (small treatment works)\n",
    "\n",
    "An example of the raw data format is here:\n",
    "\n",
    "K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Avløp\\TEOTIL små anlegg 2015 (sendt 18.08.2016).xlsx\n",
    "\n",
    "I have made a local copy of the 2016 file here:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\\avlop_sma_anlegg_2016_raw.xlsx\n",
    "\n",
    "and deleted unnecessary columns. All of this data can be added directly to `RESA2.RID_KILDER_SPREDT_VALUES`. The kommuner ID numbers and names are in `RESA2.KOMMUNER`, but not all kommune IDs in `RID_KILDER_SPREDT_VALUES` are in `KOMMUNER`. Need to check to see if Tore's code actually uses the `KOMMUNER` table to link kommuners to OSPAR areas. If it does, **need to be careful**, but perhaps it's done directly on kommuner ID?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the year for the data in question\n",
    "year = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following locations are not in the database:\n",
      "    KOMMUNENR   KOMMUNENAVN        P_kg       N_kg\n",
      "259      1505  Kristiansund  1433.17980   9554.532\n",
      "292      1576          Aure  1438.50150   9951.360\n",
      "340      1756       Inderøy  1292.87745   8896.875\n",
      "386      1903       Harstad  2595.41280  17317.206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KOMM_NO</th>\n",
       "      <th>INP_PAR_ID</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>AR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101</td>\n",
       "      <td>45</td>\n",
       "      <td>809.22690</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0104</td>\n",
       "      <td>45</td>\n",
       "      <td>93.03120</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0105</td>\n",
       "      <td>45</td>\n",
       "      <td>1074.29355</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0106</td>\n",
       "      <td>45</td>\n",
       "      <td>395.15265</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0111</td>\n",
       "      <td>45</td>\n",
       "      <td>29.59785</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  KOMM_NO INP_PAR_ID       VALUE    AR\n",
       "0    0101         45   809.22690  2016\n",
       "1    0104         45    93.03120  2016\n",
       "2    0105         45  1074.29355  2016\n",
       "3    0106         45   395.15265  2016\n",
       "4    0111         45    29.59785  2016"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read raw (tidied) data\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\point_data_2016\\avlop_sma_anlegg_2016_raw.xlsx')\n",
    "sman_df = pd.read_excel(in_xlsx, \n",
    "                        sheetname='sma_anlegg_2016')\n",
    "# Drop blank rows\n",
    "sman_df.dropna(how='all', inplace=True)\n",
    "\n",
    "# Kommune nr. should be a 4 char string, not a float\n",
    "fmt = lambda x: '%04d' % x\n",
    "sman_df['KOMMUNENR'] = sman_df['KOMMUNENR'].apply(fmt)\n",
    "\n",
    "# Check if any kommuner are not already in db\n",
    "sql = ('SELECT UNIQUE(kommune_no) '\n",
    "       'FROM resa2.kommuner')\n",
    "kmnr_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "not_in_db = set(sman_df['KOMMUNENR'].values) - set(kmnr_df['kommune_no'].values)\n",
    "\n",
    "print '\\nThe following locations are not in the database:'\n",
    "print sman_df[sman_df['KOMMUNENR'].isin(list(not_in_db))]\n",
    "\n",
    "# Get cols of interest for RID_KILDER_SPREDT_VALUES\n",
    "sman_df = sman_df[['KOMMUNENR', 'P_kg', 'N_kg']]\n",
    "\n",
    "# In RESA2.RID_PUNKTKILDER_INPAR_DEF, N is par_id 44 and P par_id 45\n",
    "sman_df.columns = ['KOMM_NO', 45, 44]\n",
    "\n",
    "# Melt to \"long\" format\n",
    "sman_df = pd.melt(sman_df, id_vars='KOMM_NO', value_vars=[45, 44],\n",
    "                  var_name='INP_PAR_ID', value_name='VALUE')\n",
    "\n",
    "# Add column for year\n",
    "sman_df['AR'] = year\n",
    "\n",
    "sman_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_KILDER_SPREDT_VALUES\n",
    "#sman_df.to_sql('rid_kilder_spredt_values', con=engine, schema='resa2', \n",
    "#               if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fish farms\n",
    "\n",
    "An examples of the raw data is here:\n",
    "\n",
    " * K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Fiskeoppdrett\\Teotil - 2015 (2) (pr. 09.08.16).xlsx.zip\n",
    "\n",
    "I have made a local copy of the 2016 file here:\n",
    "\n",
    " * C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\\fiske_oppdret_2016_raw.xlsx\n",
    "\n",
    "The data must be added to two tables in RESA2:\n",
    "\n",
    " * First, the site data must be added to `RESA2.RID_KILDER_AQUAKULTUR`. Most of the sites should already be there, but occasionally new sites are added. Any new stations must be be assigned lat/lon co-ordinates and the appropriate \"Regine\" catchment ID. This usually requires geocoding plus co-ordinate conversions and/or a spatial join to determine catchment IDs.\n",
    " \n",
    "    **Note:** The key ID fields in the raw data appear to be `LOKNR` and `LOKNAVN`. <br><br>\n",
    " \n",
    " * Secondly, the chemistry data for each site must be extracted and converted to \"long\" format, then added to `RESA2.RID_KILDER_AQKULT_VALUES`. Parameter IDs etc. are taken from `RESA2.RID_PUNKTKILDER_INPAR_DEF`.\n",
    " \n",
    "### 3.1. Basic data checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the year for the data in question\n",
    "year = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read raw (tidied) data\n",
    "# Fish farms\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\point_data_2016\\fiske_oppdret_2016_raw.xlsx')\n",
    "fish_df = pd.read_excel(in_xlsx, sheetname='Ark1')\n",
    "\n",
    "# Drop no data\n",
    "fish_df.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following locations are not in the database:\n",
      "Empty DataFrame\n",
      "Columns: [LOKNR, LOKNAVN, N_DESIMALGRADER_Y, O_DESIMALGRADER_X]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check if any sites are not already in db\n",
    "sql = ('SELECT UNIQUE(NR) '\n",
    "       'FROM resa2.rid_kilder_aquakultur')\n",
    "aqua_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "not_in_db = set(fish_df['LOKNR'].values) - set(aqua_df['nr'].values)\n",
    "\n",
    "nidb_df = fish_df[fish_df['LOKNR'].isin(list(not_in_db))][['LOKNR', 'LOKNAVN', \n",
    "                                                           'N_DESIMALGRADER_Y',\n",
    "                                                           'O_DESIMALGRADER_X']].drop_duplicates(subset=['LOKNR'])\n",
    "\n",
    "print '\\nThe following locations are not in the database:'\n",
    "print nidb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Geocode fish farms and add to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Path to Regine catchment shapefile\n",
    "#reg_shp_path = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "#                r'\\Data\\gis\\shapefiles\\reg_minste_f_wgs84.shp')\n",
    "#\n",
    "## Spatial join\n",
    "#loc_df = rid.identify_point_in_polygon(nidb_df, reg_shp_path, \n",
    "#                                       'LOKNR', 'VASSDRAGNR',\n",
    "#                                       'N_DESIMALGRADER_Y',\n",
    "#                                       'O_DESIMALGRADER_X')\n",
    "#\n",
    "## Rename cols\n",
    "#loc_df.columns = ['NR', 'NAVN', 'LENGDE', 'BREDDE', 'REGINE']\n",
    "#\n",
    "#loc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_KILDER_AQUAKULTUR\n",
    "#loc_df.to_sql('rid_kilder_aquakultur', con=engine, schema='resa2', \n",
    "#              if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Estimate nutrient inputs\n",
    "\n",
    "The methodology here is a little unclear. The following is my best guess, based on the files located here:\n",
    "\n",
    "K:\\Avdeling\\Vass\\316_Miljøinformatikk\\Prosjekter\\RID\\2016\\Rådata\\Fiskeoppdrett\n",
    "\n",
    "Old workflow:\n",
    "\n",
    " 1. Calculate the fish biomass from the raw data. See the equation in the `Biomasse` column of the spreadsheet *JSE_TEOTIL_2015.xlsx* <br><br>\n",
    " \n",
    " 2. Split the data according to salmon (\"laks\"; species ID 71101) and trout (\"øret\"; species ID 71401), then group by location and month, summing biomass and `FORFORBRUK_KILO` columns (see Fiskeoppdrett_biomasse_2016.accdb) <br><br>\n",
    " \n",
    " 3. Calculate production. This involves combining biomass for the current month with that for the previous month. See the calculations in e.g. *N_P_ørret_2015.xlsx*. <br><br>\n",
    " \n",
    " 4. Calculate NTAP and PTAP. **NB:** I don't know what these quantities are, so I'm just blindly duplicating the Excel calculations in the code below. The functions are therefore not very well explained <br><br>\n",
    " \n",
    " 5. Estimate copper usage at each fish farm by scaling the total annual Cu usage in proportion to P production. For 2016, John Rune has supplied an annual Cu value of **1088 tonnes** (see e-mail received 12/09/2017 at 09.49)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANLEGG_NR</th>\n",
       "      <th>INP_PAR_ID</th>\n",
       "      <th>AR</th>\n",
       "      <th>MANED</th>\n",
       "      <th>ART</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10029</td>\n",
       "      <td>39</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10041</td>\n",
       "      <td>39</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157490.099784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10050</td>\n",
       "      <td>39</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.467583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10054</td>\n",
       "      <td>39</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156819.055095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10078</td>\n",
       "      <td>39</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71567.641771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ANLEGG_NR INP_PAR_ID    AR  MANED  ART          VALUE\n",
       "0      10029         39  2016      6  NaN       0.000000\n",
       "1      10041         39  2016      6  NaN  157490.099784\n",
       "2      10050         39  2016      6  NaN     231.467583\n",
       "3      10054         39  2016      6  NaN  156819.055095\n",
       "4      10078         39  2016      6  NaN   71567.641771"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Annual Cu usage in tonnes\n",
    "an_cu = 1088\n",
    "\n",
    "# Estimate nutrient inputs from fish farns\n",
    "fish_nut = rid.estimate_fish_farm_nutrient_inputs(fish_df, year, an_cu)\n",
    "\n",
    "fish_nut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_KILDER_AQKULT_VALUES\n",
    "#fish_nut.to_sql('rid_kilder_aqkult_values', con=engine, schema='resa2', \n",
    "#                if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Land use\n",
    "\n",
    "An example of the raw data is here:\n",
    "\n",
    " * K:\\Avdeling\\Vass\\316_Miljøinformatikk\\Prosjekter\\RID\\2016\\Rådata\\Jordbruk\\to-niva.2015.xls\n",
    "\n",
    "Note that this file is not really an Excel file and opening it directly creates errors. I have corrected the data format, tidied the column headings and made a local copy of the 2016 data here:\n",
    "\n",
    " * C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\\jordbruk_2016.xlsx\n",
    " \n",
    "This is added to the table `RESA2.RID_AGRI_INPUTS`.\n",
    "\n",
    "**Note:** In recent years, the entry for Oslo (fylke_sone = 3_1) has been missing from the data provided by Bioforsk. This row should be added manually to the Excel file using `omrade = \"osl1\"`. The values should be identical to those for område `ake2`. This works because the land areas in `RID_Fylke-Sone_LU_Areas.xlsx` have been made identical for `osl1` and `ake2` (even though this is not correct), so the inputs in terms of kg/km2 are calculated as being the same for both regions, which is what is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to (tidied) Bioforsk data\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\point_data_2016\\jordbruk_2016.xlsx')\n",
    "\n",
    "lu_df = pd.read_excel(in_xlsx)\n",
    "\n",
    "# Add year\n",
    "lu_df['year'] = 2016\n",
    "\n",
    "# Order cols\n",
    "lu_df = lu_df[['omrade', 'year', 'n_diff_kg', 'n_point_kg', \n",
    "               'n_back_kg', 'p_diff_kg', 'p_point_kg', \n",
    "               'p_back_kg']]# Write to RESA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lu_df.to_sql(name='rid_agri_inputs', con=engine, \n",
    "#             schema='resa2', index=False,\n",
    "#             if_exists='append',\n",
    "#             dtype={'omrade': types.VARCHAR(lu_df['omrade'].str.len().max())})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
