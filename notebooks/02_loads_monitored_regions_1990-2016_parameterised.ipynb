{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nivapy3 as nivapy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import useful_rid_code as rid\n",
    "\n",
    "sn.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RID\n",
    "\n",
    "## Data processing for \"monitored rivers\" (parameterised)\n",
    "\n",
    "This notebook is \"parameterised\" for use with Papermill. The cell below has the tag `parameters`, which means the entire notebook can be called from `01_recalculate_ospar_1990-2016_main.ipynb`.\n",
    "\n",
    "**Note:** Some settings in this notebook are specific to the RID programme from 1990 to 2016. Take care for years outside this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is tagged 'parameters' for use with Papermill\n",
    "# https://papermill.readthedocs.io/en/latest/index.html\n",
    "year = 1990\n",
    "user = \"\"\n",
    "pw = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sites\n",
    "in_xlsx = r\"../../../Data/RID_Sites_List_2017-2020.xlsx\"\n",
    "rid_156_df = pd.read_excel(in_xlsx, sheet_name=\"RID_All\")\n",
    "rid_155_df = rid_156_df.query(\"station_id != 38005\")  # Ignore TROEMÃ…L2\n",
    "rid_11_df = rid_155_df.query(\"old_rid_group == 'rid_11'\")\n",
    "rid_47_df = rid_155_df.query(\"old_rid_group != 'rid_108'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Tabulate raw water chemistry and flow\n",
    "\n",
    "### 2.1. Data for year of interest\n",
    "\n",
    "Just for the RID 11 sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Connect to db\n",
    "engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "\n",
    "# Output CSV\n",
    "out_csv = f\"../../../Results/Loads_CSVs/concs_and_flows_rid_11_{year}.csv\"\n",
    "df = rid.write_csv_water_chem(rid_11_df, year, out_csv, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data for all years\n",
    "\n",
    "Not necessary for OSPAR reporting, so commented out below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "# # Connect to db\n",
    "# engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "\n",
    "# # Container for data\n",
    "# df_list = []\n",
    "\n",
    "# # Dummy path for intermediate output (which isn't needed here)\n",
    "# out_csv = r\"../../../Results/Loads_CSVs/cons_and_flows_intermed.csv\"\n",
    "\n",
    "# # Loop over years\n",
    "# for data_yr in range(1990, year + 1):\n",
    "#     # Get data\n",
    "#     df = rid.write_csv_water_chem(rid_155_df, data_yr, out_csv, engine)\n",
    "\n",
    "#     # Add to output\n",
    "#     df_list.append(df)\n",
    "\n",
    "# # Delete intermediate\n",
    "# os.remove(out_csv)\n",
    "\n",
    "# # Combine\n",
    "# df = pd.concat(df_list, axis=0)\n",
    "\n",
    "# # Reorder cols and tidy\n",
    "# st_cols = [\n",
    "#     \"station_id\",\n",
    "#     \"station_code\",\n",
    "#     \"station_name\",\n",
    "#     \"old_rid_group\",\n",
    "#     \"new_rid_group\",\n",
    "#     \"ospar_region\",\n",
    "#     \"sample_date\",\n",
    "#     \"Qs_m3/s\",\n",
    "# ]\n",
    "# par_cols = [i for i in df.columns if i not in st_cols]\n",
    "# par_cols.sort()\n",
    "# df = df[st_cols + par_cols]\n",
    "\n",
    "# # Output CSV\n",
    "# out_csv = f\"../../../Results/Loads_CSVs/concs_and_flows_rid_155_1990-{year}.csv\"\n",
    "# df.to_csv(out_csv, encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estimate observed loads\n",
    "\n",
    "### 3.1. Annual flows\n",
    "\n",
    "First get a dataframe of annual flow volumes to join to the summary output. **NB:** This dataframe isn't actually used in the loads calculations - they are handled separately - it's just for the output CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "\n",
    "# Get flow data\n",
    "q_df = rid.get_flow_volumes(rid_155_df, 1990, year, engine)\n",
    "q_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Loads for all rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Connect to db\n",
    "engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "\n",
    "# Pars of interest\n",
    "par_list = [\n",
    "    \"SPM\",\n",
    "    \"TOC\",\n",
    "    \"PO4-P\",\n",
    "    \"TOTP\",\n",
    "    \"NO3-N\",\n",
    "    \"NH4-N\",\n",
    "    \"TOTN\",\n",
    "    \"SiO2\",\n",
    "    \"Ag\",\n",
    "    \"As\",\n",
    "    \"Pb\",\n",
    "    \"Cd\",\n",
    "    \"Cu\",\n",
    "    \"Zn\",\n",
    "    \"Ni\",\n",
    "    \"Cr\",\n",
    "    \"Hg\",\n",
    "]\n",
    "\n",
    "# Container for results from each site\n",
    "loads_list = []\n",
    "\n",
    "# Loop over sites\n",
    "for stn_id in rid_155_df[\"station_id\"].values:\n",
    "    # Estimate loads at this site\n",
    "    loads_list.append(\n",
    "        rid.estimate_loads(stn_id, par_list, year, engine, infer_missing=True)\n",
    "    )\n",
    "\n",
    "# Concatenate to new df\n",
    "lds_all = pd.concat(loads_list, axis=0)\n",
    "lds_all.index.name = \"station_id\"\n",
    "lds_all.reset_index(inplace=True)\n",
    "\n",
    "# Get flow data for year\n",
    "q_yr = q_df.query(\"year == @year\")\n",
    "\n",
    "# Join\n",
    "lds_all = pd.merge(lds_all, rid_155_df, how=\"left\", on=\"station_id\")\n",
    "lds_all = pd.merge(lds_all, q_yr, how=\"left\", on=\"station_id\")\n",
    "\n",
    "# Reorder cols and tidy\n",
    "st_cols = [\n",
    "    \"station_id\",\n",
    "    \"station_code\",\n",
    "    \"station_name\",\n",
    "    \"old_rid_group\",\n",
    "    \"new_rid_group\",\n",
    "    \"ospar_region\",\n",
    "    \"mean_q_1000m3/day\",\n",
    "]\n",
    "unwant_cols = [\n",
    "    \"nve_vassdrag_nr\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"utm_north\",\n",
    "    \"utm_east\",\n",
    "    \"utm_zone\",\n",
    "    \"station_type\",\n",
    "    \"year\",\n",
    "]\n",
    "par_cols = [i for i in lds_all.columns if i not in (st_cols + unwant_cols)]\n",
    "\n",
    "for col in unwant_cols:\n",
    "    del lds_all[col]\n",
    "\n",
    "lds_all = lds_all[st_cols + par_cols]\n",
    "\n",
    "# Write output\n",
    "out_csv = f\"../../../Results/Loads_CSVs/loads_and_flows_all_sites_{year}.csv\"\n",
    "lds_all.to_csv(out_csv, encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Loads through time\n",
    "\n",
    "The code below is taken from Section 3 of [notebook 3](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/estimate_loads.ipynb).\n",
    "\n",
    "Not necessary for OSPAR reporting, so commented out below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "# # Connect to db\n",
    "# engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "\n",
    "# # Period of interest\n",
    "# st_yr, end_yr = 1990, year\n",
    "\n",
    "# # Container for results\n",
    "# loads_list = []\n",
    "\n",
    "# # Loop over sites\n",
    "# for stn_id in rid_155_df[\"station_id\"].values:\n",
    "#     # Loop over years\n",
    "#     for data_yr in range(st_yr, end_yr + 1):\n",
    "#         print(\"Processing Station ID %s for %s\" % (stn_id, data_yr))\n",
    "\n",
    "#         # Get loads\n",
    "#         l_df = rid.estimate_loads(stn_id, par_list, data_yr, engine, infer_missing=True)\n",
    "\n",
    "#         if l_df is not None:\n",
    "#             # Name and reset index\n",
    "#             l_df.index.name = \"station_id\"\n",
    "#             l_df.reset_index(inplace=True)\n",
    "\n",
    "#             # Add year\n",
    "#             l_df[\"year\"] = data_yr\n",
    "\n",
    "#             # Add to outout\n",
    "#             loads_list.append(l_df)\n",
    "\n",
    "# # Concatenate to new df\n",
    "# lds_ts = pd.concat(loads_list, axis=0)\n",
    "\n",
    "# # Join\n",
    "# lds_q_ts = pd.merge(lds_ts, rid_155_df, how=\"left\", on=\"station_id\")\n",
    "# lds_q_ts = pd.merge(lds_q_ts, q_df, how=\"left\", on=[\"station_id\", \"year\"])\n",
    "\n",
    "# # Reorder cols and tidy\n",
    "# st_cols = [\n",
    "#     \"station_id\",\n",
    "#     \"station_code\",\n",
    "#     \"station_name\",\n",
    "#     \"old_rid_group\",\n",
    "#     \"new_rid_group\",\n",
    "#     \"ospar_region\",\n",
    "#     \"mean_q_1000m3/day\",\n",
    "# ]\n",
    "# unwant_cols = [\n",
    "#     \"nve_vassdrag_nr\",\n",
    "#     \"lat\",\n",
    "#     \"lon\",\n",
    "#     \"utm_north\",\n",
    "#     \"utm_east\",\n",
    "#     \"utm_zone\",\n",
    "#     \"station_type\",\n",
    "# ]\n",
    "# par_cols = [i for i in lds_q_ts.columns if i not in (st_cols + unwant_cols)]\n",
    "\n",
    "# for col in unwant_cols:\n",
    "#     del lds_q_ts[col]\n",
    "\n",
    "# lds_q_ts = lds_q_ts[st_cols + par_cols]\n",
    "\n",
    "# # Save output\n",
    "# out_csv = f\"../../../Results/Loads_CSVs/loads_and_flows_rid_155_{st_yr}-{end_yr}.csv\"\n",
    "# lds_q_ts.to_csv(out_csv, encoding=\"utf-8\", index=False)\n",
    "\n",
    "# # Build multi-index on lds_ts for further processing\n",
    "# lds_ts.set_index([\"station_id\", \"year\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "# # Output folder for plots\n",
    "# out_fold = f\"../../../Results/TS_Plots/RID_Plots_To_{year}\"\n",
    "# if os.path.isdir(out_fold) == False:\n",
    "#     os.mkdir(out_fold)\n",
    "\n",
    "# # Loop over df\n",
    "# for stn_id in rid_11_df[\"station_id\"].values:\n",
    "#     # Get data for this station\n",
    "#     df = lds_ts.loc[stn_id]\n",
    "\n",
    "#     # Separate est and val cols to two dfs\n",
    "#     cols = df.columns\n",
    "#     est_cols = [i for i in cols if i.split(\"_\")[1] == \"Est\"]\n",
    "#     val_cols = [i for i in cols if i.split(\"_\")[1] != \"Est\"]\n",
    "#     val_df = df[val_cols]\n",
    "#     est_df = df[est_cols]\n",
    "\n",
    "#     # Convert to \"long\" format\n",
    "#     val_df.reset_index(inplace=True)\n",
    "#     val_df = pd.melt(val_df, id_vars=\"year\", var_name=\"par_unit\")\n",
    "#     est_df.reset_index(inplace=True)\n",
    "#     est_df = pd.melt(est_df, id_vars=\"year\", var_name=\"par_est\", value_name=\"est\")\n",
    "\n",
    "#     # Get just par for joining\n",
    "#     val_df[\"par\"] = val_df[\"par_unit\"].str.split(\"_\", expand=True)[0]\n",
    "#     est_df[\"par\"] = est_df[\"par_est\"].str.split(\"_\", expand=True)[0]\n",
    "\n",
    "#     # Join\n",
    "#     df = pd.merge(val_df, est_df, how=\"left\", on=[\"year\", \"par\"])\n",
    "\n",
    "#     # Extract cols of interest\n",
    "#     df = df[[\"year\", \"par_unit\", \"value\", \"est\"]]\n",
    "\n",
    "#     # Plot\n",
    "#     g = sn.factorplot(\n",
    "#         x=\"year\",\n",
    "#         y=\"value\",\n",
    "#         hue=\"est\",\n",
    "#         col=\"par_unit\",\n",
    "#         col_wrap=3,\n",
    "#         data=df,\n",
    "#         kind=\"bar\",\n",
    "#         dodge=False,\n",
    "#         sharex=False,\n",
    "#         sharey=False,\n",
    "#         alpha=0.5,\n",
    "#         aspect=2,\n",
    "#         legend=False,\n",
    "#     )\n",
    "\n",
    "#     # Rotate tick labels and tidy\n",
    "#     for ax in g.axes.flatten():\n",
    "#         for tick in ax.get_xticklabels():\n",
    "#             tick.set(rotation=45)\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # Save\n",
    "#     out_path = os.path.join(out_fold, f\"{stn_id}.png\")\n",
    "#     plt.savefig(out_path, dpi=200)\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate output tables for Word\n",
    "\n",
    "Not necessary for OSPAR reporting, so commented out below.\n",
    "\n",
    "### 4.1. Table 1: Raw water chemistry\n",
    "\n",
    "The code below is based on Section 2 of [notebook 5](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/word_data_tables.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "# tab_path = rid.copy_word_template(1, year)\n",
    "# rid.write_word_water_chem_tables(rid_47_df, year, tab_path, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Table 2: Estimated loads at each site\n",
    "\n",
    "The code below is based on Section 3 of [notebook 5](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/word_data_tables.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "# tab_path = rid.copy_word_template(2, year)\n",
    "# loads_csv = f\"../../../Results/Loads_CSVs/loads_and_flows_all_sites_{year}.csv\"\n",
    "# rid.write_word_loads_table(rid_155_df, loads_csv, tab_path, engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
