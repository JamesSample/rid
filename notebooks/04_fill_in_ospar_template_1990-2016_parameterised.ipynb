{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import useful_rid_code as rid\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RID \n",
    "\n",
    "## Fill-in OSPAR reporting template (parameterised)\n",
    "\n",
    "This notebook is \"parameterised\" for use with Papermill. The cell below has the tag `parameters`, which means the entire notebook can be called from `01_recalculate_ospar_1990-2016_main.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is tagged 'parameters' for use with Papermill\n",
    "# https://papermill.readthedocs.io/en/latest/index.html\n",
    "year = 1990\n",
    "user = \"\"\n",
    "pw = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get summary data\n",
    "\n",
    "The notebooks `summary_table_{year}.ipynb` calculate summary values for Table 3. Rather than reading these values from Word, it is easier to repeat the code to summarise the raw data again. This is the data that needs writing to the OSPAR template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Monitored areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "in_csv = f\"../../../Results/Loads_CSVs/loads_and_flows_all_sites_{year}.csv\"\n",
    "mon_df = pd.read_csv(in_csv)\n",
    "del mon_df[\"new_rid_group\"]\n",
    "\n",
    "# Group by OSPAR region\n",
    "mon_df1 = mon_df.groupby([\"ospar_region\", \"old_rid_group\"]).sum()\n",
    "\n",
    "# Totals for Norway\n",
    "mon_df2 = mon_df.groupby(\"old_rid_group\").sum().reset_index()\n",
    "mon_df2[\"ospar_region\"] = \"NORWAY\"\n",
    "mon_df2.set_index([\"ospar_region\", \"old_rid_group\"], inplace=True)\n",
    "\n",
    "# Combine\n",
    "mon_df = pd.concat([mon_df1, mon_df2], axis=0)\n",
    "\n",
    "# Cols of interest\n",
    "cols = [i for i in mon_df.columns if i.split(\"_\")[1] != \"Est\"]\n",
    "mon_df = mon_df[cols]\n",
    "del mon_df[\"station_id\"], mon_df[\"mean_q_1000m3/day\"]\n",
    "\n",
    "# Convert units\n",
    "mon_df[\"Hg_kg\"] = mon_df[\"Hg_kg\"] / 1000.0  # kg to tonnes\n",
    "mon_df[\"NH4-N_tonnes\"] = mon_df[\"NH4-N_tonnes\"] / 1000.0  # tonnes to ktonnes\n",
    "mon_df[\"NO3-N_tonnes\"] = mon_df[\"NO3-N_tonnes\"] / 1000.0  # tonnes to ktonnes\n",
    "mon_df[\"TOTN_tonnes\"] = mon_df[\"TOTN_tonnes\"] / 1000.0  # tonnes to ktonnes\n",
    "mon_df[\"TOTP_tonnes\"] = mon_df[\"TOTP_tonnes\"] / 1000.0  # tonnes to ktonnes\n",
    "mon_df[\"PO4-P_tonnes\"] = mon_df[\"PO4-P_tonnes\"] / 1000.0  # tonnes to ktonnes\n",
    "mon_df[\"SPM_tonnes\"] = mon_df[\"SPM_tonnes\"] / 1000.0  # tonnes to ktonnes\n",
    "\n",
    "# Units are correct, so remove\n",
    "mon_df.columns = [i.split(\"_\")[0] for i in mon_df.columns]\n",
    "\n",
    "mon_df.round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Unmonitored areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "in_csv = f\"../../../Results/Unmon_loads/teotil2_ospar_unmonitored_loads_{year}.csv\"\n",
    "umon_df = pd.read_csv(in_csv, index_col=0)\n",
    "\n",
    "# Rename cols\n",
    "umon_df.columns = [i.replace(\"RENSEANLEGG\", \"sew\") for i in umon_df.columns]\n",
    "umon_df.columns = [i.replace(\"INDUSTRI\", \"ind\") for i in umon_df.columns]\n",
    "umon_df.columns = [i.replace(\"_tonn\", \"\") for i in umon_df.columns]\n",
    "umon_df.columns = [i.replace(\"AQUAKULTUR\", \"fish\") for i in umon_df.columns]\n",
    "\n",
    "# Add missing columns if necessary\n",
    "cols = [\"sew_Hg\", \"sew_S.P.M.\", \"ind_Hg\"]\n",
    "for col in cols:\n",
    "    if col not in umon_df.columns:\n",
    "        umon_df[col] = 0\n",
    "\n",
    "# Convert Hg to kgs\n",
    "umon_df[\"sew_Hg\"] = umon_df[\"sew_Hg\"] * 1000\n",
    "umon_df[\"ind_Hg\"] = umon_df[\"ind_Hg\"] * 1000\n",
    "\n",
    "umon_df.round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Loads for 11 main rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "in_csv = f\"../../../Results/Loads_CSVs/loads_and_flows_all_sites_{year}.csv\"\n",
    "rid11_df = pd.read_csv(in_csv, index_col=0)\n",
    "del rid11_df[\"new_rid_group\"]\n",
    "\n",
    "# Get data for RID11\n",
    "rid11_df = rid11_df.query('old_rid_group == \"rid_11\"')\n",
    "\n",
    "# Tidy\n",
    "del rid11_df[\"station_code\"], rid11_df[\"station_name\"]\n",
    "del rid11_df[\"old_rid_group\"], rid11_df[\"ospar_region\"]\n",
    "del rid11_df[\"mean_q_1000m3/day\"]\n",
    "\n",
    "cols = [i for i in rid11_df.columns if i.split(\"_\")[1] != \"Est\"]\n",
    "rid11_df = rid11_df[cols]\n",
    "\n",
    "# Convert units\n",
    "rid11_df[\"Hg_kg\"] = rid11_df[\"Hg_kg\"] / 1000.0  # kg to tonnes\n",
    "rid11_df[\"NH4-N_tonnes\"] = rid11_df[\"NH4-N_tonnes\"] / 1000.0  # tonnes to ktonnes\n",
    "rid11_df[\"NO3-N_tonnes\"] = rid11_df[\"NO3-N_tonnes\"] / 1000.0  # tonnes to ktonnes\n",
    "rid11_df[\"TOTN_tonnes\"] = rid11_df[\"TOTN_tonnes\"] / 1000.0  # tonnes to ktonnes\n",
    "rid11_df[\"TOTP_tonnes\"] = rid11_df[\"TOTP_tonnes\"] / 1000.0  # tonnes to ktonnes\n",
    "rid11_df[\"PO4-P_tonnes\"] = rid11_df[\"PO4-P_tonnes\"] / 1000.0  # tonnes to ktonnes\n",
    "rid11_df[\"SPM_tonnes\"] = rid11_df[\"SPM_tonnes\"] / 1000.0  # tonnes to ktonnes\n",
    "\n",
    "# Tidy cols\n",
    "rid11_df.columns = [i.split(\"_\")[0] for i in rid11_df.columns]\n",
    "\n",
    "rid11_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fill-in template\n",
    "\n",
    "The template is usually sent each year by Csilla at NIBIO. However, it doesn't seem to change, so old versions can also be used e.g. here:\n",
    "\n",
    "    ../../../Results/OSPAR/Blank_Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of template to update\n",
    "temp_path = rid.copy_ospar_template(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_spreadsheet_point_sources(xlsx, sheet, pars, src, df):\n",
    "    \"\"\"Update the OSPAR template for point source data.\n",
    "\n",
    "    Args:\n",
    "        xslx:  Str. Path to Excel template\n",
    "        sheet: Str. Sheet name to update\n",
    "        pars:  List. Parameter names in template to fill-in\n",
    "        src:   Str. Type of input ('sew', 'ind', 'fish')\n",
    "        df:    Dataframe. Values to fill-in\n",
    "\n",
    "    Returns:\n",
    "        None. The template is updated and saved.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    # Map Excel headings to df cols\n",
    "    par_dict = {\n",
    "        \"SPM\": \"S.P.M.\",\n",
    "        \"TOC\": \"TOC\",\n",
    "        \"PO4-P\": \"po4\",\n",
    "        \"P-Total\": \"p\",\n",
    "        \"NO3-N\": \"no3\",\n",
    "        \"NH4-N\": \"nh4\",\n",
    "        \"N-Total\": \"n\",\n",
    "        \"As\": \"As\",\n",
    "        \"Pb\": \"Pb\",\n",
    "        \"Cd\": \"Cd\",\n",
    "        \"Cu\": \"Cu\",\n",
    "        \"Zn\": \"Zn\",\n",
    "        \"Ni\": \"Ni\",\n",
    "        \"Total Cr\": \"Cr\",\n",
    "        \"Hg\": \"Hg\",\n",
    "    }\n",
    "\n",
    "    # Map template names to df names\n",
    "    names_dict = {\n",
    "        \"Norwegian Sea (NO)\": \"NORWEGIAN SEA2\",\n",
    "        \"Barents Sea (NO)\": \"LOFOTEN-BARENTS SEA\",\n",
    "        \"Skagerrak (NO)\": \"SKAGERAK\",\n",
    "        \"North Sea (NO)\": \"NORTH SEA\",\n",
    "        \"Norway Total\": \"NORWAY\",\n",
    "    }\n",
    "\n",
    "    # Open new file and get sheet\n",
    "    wb = load_workbook(filename=xlsx)\n",
    "    ws = wb[sheet]\n",
    "\n",
    "    # Get row numbers\n",
    "    row_dict = {}\n",
    "    for item in ws[\"B12\" : \"B%s\" % ws.max_row]:\n",
    "        # Get cell properties\n",
    "        cell = item[0]\n",
    "        name = cell.value\n",
    "        row = cell.row\n",
    "        row_dict[name] = row\n",
    "\n",
    "    # Get col numbers\n",
    "    col_dict = {}\n",
    "    for cell in ws[\"E9\":\"AK9\"][0]:\n",
    "        # Get cell properties\n",
    "        par = cell.value\n",
    "        col = cell.column\n",
    "        col_dict[par] = col\n",
    "\n",
    "    # Update spreadsheet\n",
    "    for reg in names_dict.keys():\n",
    "        for par in pars:\n",
    "            # Get value from df\n",
    "            try:\n",
    "                val = df.loc[names_dict[reg], \"%s_%s\" % (src, par_dict[par])]\n",
    "            except KeyError:\n",
    "                val = 0\n",
    "\n",
    "            # Get cell co-ords\n",
    "            row = row_dict[reg] + 2\n",
    "            col = col_dict[par]\n",
    "\n",
    "            # Write value\n",
    "            ws.cell(row=row, column=col).value = val\n",
    "\n",
    "    # Save\n",
    "    wb.save(xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Sheet 5a: Sewage effluents\n",
    "\n",
    "Note these are the values from Table 3 for **unmonitored areas** and not the total sewage inputs for each of the OSPAR areas. This is the same as what Tore reported previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Sewage data\n",
    "cols = [i for i in umon_df.columns if i.split(\"_\")[0] == \"sew\"]\n",
    "sew_df = umon_df[cols].copy()\n",
    "\n",
    "# Convert units\n",
    "sew_df[\"sew_Hg\"] = sew_df[\"sew_Hg\"] / 1000.0  # kg to tonnes\n",
    "sew_df[\"sew_nh4\"] = sew_df[\"sew_nh4\"] / 1000.0  # tonnes to ktonnes\n",
    "sew_df[\"sew_no3\"] = sew_df[\"sew_no3\"] / 1000.0  # tonnes to ktonnes\n",
    "sew_df[\"sew_n\"] = sew_df[\"sew_n\"] / 1000.0  # tonnes to ktonnes\n",
    "sew_df[\"sew_po4\"] = sew_df[\"sew_po4\"] / 1000.0  # tonnes to ktonnes\n",
    "sew_df[\"sew_p\"] = sew_df[\"sew_p\"] / 1000.0  # tonnes to ktonnes\n",
    "sew_df[\"sew_S.P.M.\"] = sew_df[\"sew_S.P.M.\"] / 1000.0  # tonnes to ktonnes\n",
    "\n",
    "sew_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sheet 5a\n",
    "pars = [\n",
    "    \"Ni\",\n",
    "    \"Pb\",\n",
    "    \"NH4-N\",\n",
    "    \"Total Cr\",\n",
    "    \"NO3-N\",\n",
    "    \"Zn\",\n",
    "    \"As\",\n",
    "    \"Cd\",\n",
    "    \"P-Total\",\n",
    "    \"SPM\",\n",
    "    \"PO4-P\",\n",
    "    \"N-Total\",\n",
    "    \"Hg\",\n",
    "    \"Cu\",\n",
    "]\n",
    "\n",
    "update_spreadsheet_point_sources(temp_path, \"5a\", pars, \"sew\", sew_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Sheet 5b: Industrial effluents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get industrial data\n",
    "cols = [i for i in umon_df.columns if i.split(\"_\")[0] == \"ind\"]\n",
    "ind_df = umon_df[cols].copy()\n",
    "\n",
    "# Convert units\n",
    "ind_df[\"ind_Hg\"] = ind_df[\"ind_Hg\"] / 1000.0  # kg to tonnes\n",
    "ind_df[\"ind_nh4\"] = ind_df[\"ind_nh4\"] / 1000.0  # tonnes to ktonnes\n",
    "ind_df[\"ind_no3\"] = ind_df[\"ind_no3\"] / 1000.0  # tonnes to ktonnes\n",
    "ind_df[\"ind_n\"] = ind_df[\"ind_n\"] / 1000.0  # tonnes to ktonnes\n",
    "ind_df[\"ind_po4\"] = ind_df[\"ind_po4\"] / 1000.0  # tonnes to ktonnes\n",
    "ind_df[\"ind_p\"] = ind_df[\"ind_p\"] / 1000.0  # tonnes to ktonnes\n",
    "ind_df[\"ind_S.P.M.\"] = ind_df[\"ind_S.P.M.\"] / 1000.0  # tonnes to ktonnes\n",
    "\n",
    "ind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sheet 5b\n",
    "pars = [\n",
    "    \"Ni\",\n",
    "    \"Pb\",\n",
    "    \"NH4-N\",\n",
    "    \"Total Cr\",\n",
    "    \"NO3-N\",\n",
    "    \"Zn\",\n",
    "    \"As\",\n",
    "    \"Cd\",\n",
    "    \"P-Total\",\n",
    "    \"SPM\",\n",
    "    \"PO4-P\",\n",
    "    \"N-Total\",\n",
    "    \"Hg\",\n",
    "    \"Cu\",\n",
    "    \"TOC\",\n",
    "]\n",
    "\n",
    "update_spreadsheet_point_sources(temp_path, \"5b\", pars, \"ind\", ind_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Sheet 5c: Aquaculture discharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fish data\n",
    "cols = [i for i in umon_df.columns if i.split(\"_\")[0] == \"fish\"]\n",
    "fish_df = umon_df[cols].copy()\n",
    "\n",
    "# Convert units\n",
    "fish_df[\"fish_nh4\"] = fish_df[\"fish_nh4\"] / 1000.0  # tonnes to ktonnes\n",
    "fish_df[\"fish_no3\"] = fish_df[\"fish_no3\"] / 1000.0  # tonnes to ktonnes\n",
    "fish_df[\"fish_n\"] = fish_df[\"fish_n\"] / 1000.0  # tonnes to ktonnes\n",
    "fish_df[\"fish_po4\"] = fish_df[\"fish_po4\"] / 1000.0  # tonnes to ktonnes\n",
    "fish_df[\"fish_p\"] = fish_df[\"fish_p\"] / 1000.0  # tonnes to ktonnes\n",
    "\n",
    "fish_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sheet 5c\n",
    "pars = [\"NH4-N\", \"NO3-N\", \"P-Total\", \"PO4-P\", \"N-Total\", \"Cu\"]\n",
    "\n",
    "update_spreadsheet_point_sources(temp_path, \"5c\", pars, \"fish\", fish_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Sheet 5d: Other discharges\n",
    "\n",
    "This sheet is left blank\n",
    "\n",
    "### 2.5. Sheet 5e: Total direct discharges\n",
    "\n",
    "The sum of sewage, industrial and fish-farm discharges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine sew, ind and fish, then aggregate\n",
    "for df in [sew_df, ind_df, fish_df]:\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns = [i.split(\"_\")[1] for i in df.columns]\n",
    "\n",
    "td_df = pd.concat([sew_df, ind_df, fish_df], axis=0, sort=True)\n",
    "td_df = td_df.groupby(\"region\").sum()\n",
    "\n",
    "td_df.columns = [\"td_\" + i for i in td_df.columns]\n",
    "\n",
    "td_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sheet 5e\n",
    "pars = [\n",
    "    \"Ni\",\n",
    "    \"Pb\",\n",
    "    \"NH4-N\",\n",
    "    \"Total Cr\",\n",
    "    \"NO3-N\",\n",
    "    \"Zn\",\n",
    "    \"As\",\n",
    "    \"Cd\",\n",
    "    \"P-Total\",\n",
    "    \"SPM\",\n",
    "    \"PO4-P\",\n",
    "    \"N-Total\",\n",
    "    \"Hg\",\n",
    "    \"Cu\",\n",
    "    \"TOC\",\n",
    "]\n",
    "\n",
    "update_spreadsheet_point_sources(temp_path, \"5e\", pars, \"td\", td_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Sheet 6a: Monitored rivers\n",
    "\n",
    "**Does \"Inner Oslofjord\" in the template correspond to \"Alna\"?** If so, I can fill-in one additional row in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_df.reset_index(inplace=True)\n",
    "tot_df = mon_df.groupby(\"ospar_region\").sum()\n",
    "trib_df = mon_df[mon_df[\"old_rid_group\"] != \"rid_11\"].groupby(\"ospar_region\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_spreadsheet_monitored_rivers(xlsx, sheet, pars, df_dict):\n",
    "    \"\"\"Update the OSPAR template for monitored rivers.\n",
    "\n",
    "    Args:\n",
    "        xslx:    Str. Path to Excel template\n",
    "        sheet:   Str. Sheet name to update\n",
    "        pars:    List. Parameter names in template to fill-in\n",
    "        df_dict: Dict. {'tot':tot_df, 'trib':trib_df, 'main':rid11_df}\n",
    "                 Values to fill-in\n",
    "\n",
    "    Returns:\n",
    "        None. The template is updated and saved.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    # Map Excel headings to df cols\n",
    "    par_dict = {\n",
    "        \"SPM\": \"SPM\",\n",
    "        \"TOC\": \"TOC\",\n",
    "        \"PO4-P\": \"PO4-P\",\n",
    "        \"P-Total\": \"TOTP\",\n",
    "        \"NO3-N\": \"NO3-N\",\n",
    "        \"NH4-N\": \"NH4-N\",\n",
    "        \"N-Total\": \"TOTN\",\n",
    "        \"As\": \"As\",\n",
    "        \"Pb\": \"Pb\",\n",
    "        \"Cd\": \"Cd\",\n",
    "        \"Cu\": \"Cu\",\n",
    "        \"Zn\": \"Zn\",\n",
    "        \"Ni\": \"Ni\",\n",
    "        \"Total Cr\": \"Cr\",\n",
    "        \"Hg\": \"Hg\",\n",
    "    }\n",
    "\n",
    "    # Map template names to df names and rows\n",
    "    names_dict = {\n",
    "        \"Norwegian Sea (NO)\": (\"NORWEGIAN SEA2\", \"tot\"),\n",
    "        \"Barents Sea (NO)\": (\"LOFOTEN-BARENTS SEA\", \"tot\"),\n",
    "        \"Skagerrak (NO)\": (\"SKAGERAK\", \"tot\"),\n",
    "        \"North Sea (NO)\": (\"NORTH SEA\", \"tot\"),\n",
    "        \"Norway Total\": (\"NORWAY\", \"tot\"),\n",
    "        \"Tributary Rivers - Norwegian Sea\": (\"NORWEGIAN SEA2\", \"trib\"),\n",
    "        \"Tributary Rivers - Barents Sea\": (\"LOFOTEN-BARENTS SEA\", \"trib\"),\n",
    "        \"Tributary Rivers - Skagerak\": (\"SKAGERAK\", \"trib\"),\n",
    "        \"Tributary Rivers - North Sea\": (\"NORTH SEA\", \"trib\"),\n",
    "        \"Orkla\": (29778, \"main\"),\n",
    "        \"Vefsna\": (29782, \"main\"),\n",
    "        \"Alta\": (29779, \"main\"),\n",
    "        \"Glomma\": (29617, \"main\"),\n",
    "        \"Drammenselva\": (29612, \"main\"),\n",
    "        u\"Numedalslågen\": (29615, \"main\"),\n",
    "        \"Skienselva\": (29613, \"main\"),\n",
    "        \"Otra\": (29614, \"main\"),\n",
    "        \"Orreelva\": (29783, \"main\"),\n",
    "        \"Vosso\": (29821, \"main\"),\n",
    "    }\n",
    "\n",
    "    # Open new file and get sheet\n",
    "    wb = load_workbook(filename=xlsx)\n",
    "    ws = wb[sheet]\n",
    "\n",
    "    # Get row numbers\n",
    "    row_dict = {}\n",
    "    for item in ws[\"B12\" : \"B%s\" % ws.max_row]:\n",
    "        # Get cell properties\n",
    "        cell = item[0]\n",
    "        name = cell.value\n",
    "        row = cell.row\n",
    "        row_dict[name] = row\n",
    "\n",
    "    # Get col numbers\n",
    "    col_dict = {}\n",
    "    for cell in ws[\"E9\":\"AK9\"][0]:\n",
    "        # Get cell properties\n",
    "        par = cell.value\n",
    "        col = cell.column\n",
    "        col_dict[par] = col\n",
    "\n",
    "    # Update spreadsheet\n",
    "    for reg in names_dict.keys():\n",
    "        df_idx, df_name = names_dict[reg]\n",
    "\n",
    "        # Get df\n",
    "        df = df_dict[df_name]\n",
    "\n",
    "        for par in pars:\n",
    "            # Get value from df\n",
    "            val = df.loc[df_idx, par_dict[par]]\n",
    "\n",
    "            # Get cell co-ords\n",
    "            row = row_dict[reg] + 2\n",
    "            col = col_dict[par]\n",
    "\n",
    "            # Write value\n",
    "            ws.cell(row=row, column=col).value = val\n",
    "\n",
    "    # Save\n",
    "    wb.save(xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sheet 6a\n",
    "pars = [\n",
    "    \"Ni\",\n",
    "    \"Pb\",\n",
    "    \"NH4-N\",\n",
    "    \"Total Cr\",\n",
    "    \"NO3-N\",\n",
    "    \"Zn\",\n",
    "    \"As\",\n",
    "    \"Cd\",\n",
    "    \"P-Total\",\n",
    "    \"SPM\",\n",
    "    \"PO4-P\",\n",
    "    \"N-Total\",\n",
    "    \"Hg\",\n",
    "    \"Cu\",\n",
    "    \"TOC\",\n",
    "]\n",
    "df_dict = {\"tot\": tot_df, \"main\": rid11_df, \"trib\": trib_df}\n",
    "\n",
    "update_spreadsheet_monitored_rivers(temp_path, \"6a\", pars, df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7. Sheet 6b: Unmonitored areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get diff data\n",
    "cols = [i for i in umon_df.columns if i.split(\"_\")[0] == \"diff\"]\n",
    "diff_df = umon_df[cols].copy()\n",
    "\n",
    "# Convert units\n",
    "diff_df[\"diff_nh4\"] = diff_df[\"diff_nh4\"] / 1000.0  # tonnes to ktonnes\n",
    "diff_df[\"diff_no3\"] = diff_df[\"diff_no3\"] / 1000.0  # tonnes to ktonnes\n",
    "diff_df[\"diff_n\"] = diff_df[\"diff_n\"] / 1000.0  # tonnes to ktonnes\n",
    "diff_df[\"diff_po4\"] = diff_df[\"diff_po4\"] / 1000.0  # tonnes to ktonnes\n",
    "diff_df[\"diff_p\"] = diff_df[\"diff_p\"] / 1000.0  # tonnes to ktonnes\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sheet 6b\n",
    "pars = [\"NH4-N\", \"NO3-N\", \"P-Total\", \"PO4-P\", \"N-Total\"]\n",
    "\n",
    "update_spreadsheet_point_sources(temp_path, \"6b\", pars, \"diff\", diff_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8. Sheet 6c: Total inputs\n",
    "\n",
    "**Note:** See e-mail from Csilla received 07/11/2017 at 13.43. This table should **not** include \"point\" discharges (`td_df`) - it's just the sum of tables 6a and 6b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename cols in diff_df\n",
    "col_map = {\n",
    "    \"diff_n\": \"TOTN\",\n",
    "    \"diff_p\": \"TOTP\",\n",
    "    \"diff_po4\": \"PO4-P\",\n",
    "    \"diff_no3\": \"NO3-N\",\n",
    "    \"diff_nh4\": \"NH4-N\",\n",
    "}\n",
    "diff_df.columns = [col_map[i] for i in diff_df.columns]\n",
    "\n",
    "# Add to total_df\n",
    "for col in diff_df.columns:\n",
    "    tot_df[col] = tot_df[col] + diff_df[col]\n",
    "\n",
    "# Update sheet 6c\n",
    "pars = [\n",
    "    \"Ni\",\n",
    "    \"Pb\",\n",
    "    \"NH4-N\",\n",
    "    \"Total Cr\",\n",
    "    \"NO3-N\",\n",
    "    \"Zn\",\n",
    "    \"As\",\n",
    "    \"Cd\",\n",
    "    \"P-Total\",\n",
    "    \"SPM\",\n",
    "    \"PO4-P\",\n",
    "    \"N-Total\",\n",
    "    \"Hg\",\n",
    "    \"Cu\",\n",
    "    \"TOC\",\n",
    "]\n",
    "\n",
    "df_dict = {\"tot\": tot_df, \"main\": rid11_df, \"trib\": trib_df}\n",
    "\n",
    "update_spreadsheet_monitored_rivers(temp_path, \"6c\", pars, df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two cells are not longer used as I originally misunderstood what table 6c represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardise col names\n",
    "# diff_df.columns = [i.split('_')[1] for i in diff_df.columns]\n",
    "# td_df.columns = [i.split('_')[1] for i in td_df.columns]\n",
    "# td_df.index.name = 'ospar_region'\n",
    "#\n",
    "# col_dict = {'SPM':'S.P.M.',\n",
    "#            'TOTN':'n',\n",
    "#            'NH4-N':'nh4',\n",
    "#            'NO3-N':'no3',\n",
    "#            'TOTP':'p',\n",
    "#            'PO4-P':'po4'}\n",
    "# for col in col_dict.keys():\n",
    "#    new_col = col_dict[col]\n",
    "#    tot_df[new_col] = tot_df[col]\n",
    "#    del tot_df[col]\n",
    "#\n",
    "## Reset index\n",
    "# diff_df.reset_index(inplace=True)\n",
    "# tot_df.reset_index(inplace=True)\n",
    "# td_df.reset_index(inplace=True)\n",
    "#\n",
    "## Concat and aggregate\n",
    "##tot_df = pd.concat([diff_df, td_df, tot_df], axis=0).groupby('ospar_region').sum() # See comment above\n",
    "# tot_df = pd.concat([diff_df, tot_df], axis=0).groupby('ospar_region').sum()\n",
    "#\n",
    "## Rename cols\n",
    "# tot_df.columns = ['tot_'+i for i in tot_df.columns]\n",
    "#\n",
    "# tot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update sheet 6c\n",
    "# pars = ['Ni', 'Pb', 'NH4-N', 'Total Cr', 'NO3-N',\n",
    "#        'Zn', 'As', 'Cd', 'P-Total', 'SPM', 'PO4-P',\n",
    "#        'N-Total', 'Hg', 'Cu', 'TOC']\n",
    "#\n",
    "# update_spreadsheet_point_sources(temp_path, '6c', pars, 'tot', tot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9. Sheet 7: Concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "in_csv = f\"../../../Results/Loads_CSVs/concs_and_flows_rid_11_{year}.csv\"\n",
    "conc_df = pd.read_csv(in_csv, index_col=0, encoding=\"utf-8\")\n",
    "\n",
    "cols = [\n",
    "    \"Hg_ng/l\",\n",
    "    \"NH4-N_µg/l N\",\n",
    "    \"NO3-N_µg/l N\",\n",
    "    \"TOTN_µg/l N\",\n",
    "    \"TOTP_µg/l P\",\n",
    "    \"PO4-P_µg/l P\",\n",
    "    \"TOC_mg C/l\",\n",
    "]\n",
    "for col in cols:\n",
    "    if col not in conc_df.columns:\n",
    "        par = col.split(\"_\")[0]\n",
    "        conc_df[col] = np.nan\n",
    "        conc_df[f\"{par}_flag\"] = np.nan\n",
    "\n",
    "# Convert units\n",
    "conc_df[\"Hg_ng/l\"] = conc_df[\"Hg_ng/l\"] / 1000  # ng to ug\n",
    "conc_df[\"NH4-N_µg/l N\"] = conc_df[\"NH4-N_µg/l N\"] / 1000  # ug to mg\n",
    "conc_df[\"NO3-N_µg/l N\"] = conc_df[\"NO3-N_µg/l N\"] / 1000  # ug to mg\n",
    "conc_df[\"TOTN_µg/l N\"] = conc_df[\"TOTN_µg/l N\"] / 1000  # ug to mg\n",
    "conc_df[\"TOTP_µg/l P\"] = conc_df[\"TOTP_µg/l P\"] / 1000  # ug to mg\n",
    "conc_df[\"PO4-P_µg/l P\"] = conc_df[\"PO4-P_µg/l P\"] / 1000  # ug to mg\n",
    "conc_df[\"TOC_mg C/l\"] = conc_df[\"TOC_mg C/l\"] * 1000  # mg to ug\n",
    "\n",
    "# Get flags\n",
    "cols = [i for i in conc_df.columns if i.split(\"_\")[1] == \"flag\"]\n",
    "lod_df = conc_df[cols]\n",
    "lod_df.columns = [i.split(\"_\")[0] for i in lod_df.columns]\n",
    "\n",
    "# Get vals\n",
    "cols = [\n",
    "    i\n",
    "    for i in conc_df.columns\n",
    "    if ((i.split(\"_\")[0] in lod_df.columns) and (i.split(\"_\")[1] != \"flag\"))\n",
    "]\n",
    "conc_df = conc_df[cols]\n",
    "conc_df.columns = [i.split(\"_\")[0] for i in conc_df.columns]\n",
    "\n",
    "# Rename\n",
    "col_dict = {\n",
    "    \"SPM\": \"S.P.M.\",\n",
    "    \"TOTN\": \"n\",\n",
    "    \"NH4-N\": \"nh4\",\n",
    "    \"NO3-N\": \"no3\",\n",
    "    \"TOTP\": \"p\",\n",
    "    \"PO4-P\": \"po4\",\n",
    "}\n",
    "for col in col_dict.keys():\n",
    "    new_col = col_dict[col]\n",
    "    lod_df[new_col] = lod_df[col]\n",
    "    conc_df[new_col] = conc_df[col]\n",
    "    del conc_df[col], lod_df[col]\n",
    "\n",
    "# Map Excel headings to df cols\n",
    "par_dict = {\n",
    "    \"SPM\": \"S.P.M.\",\n",
    "    \"TOC\": \"TOC\",\n",
    "    \"PO4-P\": \"po4\",\n",
    "    \"P-Total\": \"p\",\n",
    "    \"NO3-N\": \"no3\",\n",
    "    \"NH4-N\": \"nh4\",\n",
    "    \"N-Total\": \"n\",\n",
    "    \"As\": \"As\",\n",
    "    \"Pb\": \"Pb\",\n",
    "    \"Cd\": \"Cd\",\n",
    "    \"Cu\": \"Cu\",\n",
    "    \"Zn\": \"Zn\",\n",
    "    \"Ni\": \"Ni\",\n",
    "    \"Total Cr\": \"Cr\",\n",
    "    \"Hg\": \"Hg\",\n",
    "}\n",
    "\n",
    "# Map names to stns\n",
    "names_dict = {\n",
    "    \"Orkla\": 29778,\n",
    "    \"Vefsna\": 29782,\n",
    "    \"Alta\": 29779,\n",
    "    \"Glomma\": 29617,\n",
    "    \"Drammenselva\": 29612,\n",
    "    \"Numedalslågen\": 29615,\n",
    "    \"Skienselva\": 29613,\n",
    "    \"Otra\": 29614,\n",
    "    \"Orreelva\": 29783,\n",
    "    \"Vosso\": 29821,\n",
    "}\n",
    "\n",
    "# Open new file and get sheet\n",
    "wb = load_workbook(filename=temp_path)\n",
    "ws = wb[\"7\"]\n",
    "\n",
    "# Get row numbers\n",
    "row_dict = {}\n",
    "for item in ws[\"B12\" : \"B%s\" % ws.max_row]:\n",
    "    # Get cell properties\n",
    "    cell = item[0]\n",
    "    name = cell.value\n",
    "    row = cell.row\n",
    "    row_dict[name] = row\n",
    "\n",
    "# Get col numbers\n",
    "col_dict = {}\n",
    "for cell in ws[\"E9\":\"AK9\"][0]:\n",
    "    # Get cell properties\n",
    "    par = cell.value\n",
    "    col = cell.column\n",
    "    col_dict[par] = col\n",
    "\n",
    "pars = [\n",
    "    \"Ni\",\n",
    "    \"Pb\",\n",
    "    \"NH4-N\",\n",
    "    \"Total Cr\",\n",
    "    \"NO3-N\",\n",
    "    \"Zn\",\n",
    "    \"As\",\n",
    "    \"Cd\",\n",
    "    \"P-Total\",\n",
    "    \"SPM\",\n",
    "    \"PO4-P\",\n",
    "    \"N-Total\",\n",
    "    \"Hg\",\n",
    "    \"Cu\",\n",
    "    \"TOC\",\n",
    "]\n",
    "\n",
    "# Update spreadsheet\n",
    "for reg in names_dict.keys():\n",
    "    for par in pars:\n",
    "        if par_dict[par] not in conc_df.columns:\n",
    "            conc_df[par_dict[par]] = np.nan\n",
    "            lod_df[par_dict[par]] = np.nan\n",
    "\n",
    "        # Get values from df\n",
    "        # 1a. Lower average\n",
    "        vals = conc_df.loc[names_dict[reg]].copy()[[par_dict[par]]].values\n",
    "        lods = lod_df.loc[names_dict[reg]].copy()[[par_dict[par]]].fillna(\"0\").values\n",
    "        vals[(lods == \"<\")] = 0\n",
    "        val = np.nanmean(vals)\n",
    "\n",
    "        row = row_dict[reg]\n",
    "        col = col_dict[par]\n",
    "        ws.cell(row=row, column=col).value = val\n",
    "\n",
    "        # 1b. Upper average\n",
    "        val = conc_df.loc[names_dict[reg], par_dict[par]].mean()\n",
    "        row = row_dict[reg]\n",
    "        col = col_dict[par]\n",
    "        ws.cell(row=row, column=col).value = val\n",
    "\n",
    "        # 2. Min\n",
    "        val = conc_df.loc[names_dict[reg], par_dict[par]].min()\n",
    "        row = row_dict[reg] + 2\n",
    "        col = col_dict[par]\n",
    "        ws.cell(row=row, column=col).value = val\n",
    "\n",
    "        # 3. Max\n",
    "        val = conc_df.loc[names_dict[reg], par_dict[par]].max()\n",
    "        row = row_dict[reg] + 3\n",
    "        col = col_dict[par]\n",
    "        ws.cell(row=row, column=col).value = val\n",
    "\n",
    "        # 4. N\n",
    "        n_samp = len(conc_df.loc[names_dict[reg]].copy()[[par_dict[par]]].dropna())\n",
    "        if n_samp == 0:\n",
    "            n_samp = np.nan\n",
    "        row = row_dict[reg] + 5\n",
    "        col = col_dict[par]\n",
    "        ws.cell(row=row, column=col).value = n_samp\n",
    "\n",
    "        # 5. N LOD\n",
    "        n_lod = (~pd.isnull(lod_df.loc[names_dict[reg]].copy()[[par_dict[par]]])).sum()\n",
    "        try:\n",
    "            pct_lod = 100 * float(n_lod) / float(n_samp)\n",
    "            if pct_lod < 30:\n",
    "                val = \"Yes\"\n",
    "            else:\n",
    "                val = \"No\"\n",
    "        except ZeroDivisionError:\n",
    "            val = np.nan\n",
    "\n",
    "        row = row_dict[reg] + 4\n",
    "        col = col_dict[par]\n",
    "        ws.cell(row=row, column=col).value = val\n",
    "\n",
    "        # 6. Std\n",
    "        val = conc_df.loc[names_dict[reg], par_dict[par]].std()\n",
    "        row = row_dict[reg] + 7\n",
    "        col = col_dict[par]\n",
    "        ws.cell(row=row, column=col).value = val\n",
    "\n",
    "# Save\n",
    "wb.save(temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10. Sheet 9: Discharge\n",
    "\n",
    "The notebook [here](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/recalculate_ospar_flows.ipynb) handles the OSPAR flow data. Run this, and then copy the results over to Sheet 9. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
