{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import calendar\n",
    "import configparser\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nivapy3 as nivapy\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# Get API key for HydAPI\n",
    "api_key = nivapy.da.authenticate_nve_hydapi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elveovervåkingsprogrammet - average monthly temperatures\n",
    "\n",
    "**This notebook has not been run for 2023 as the data were already processed by manually Øyvind.**\n",
    "\n",
    "This notebook calculates average monthly temperatures for the 20 main rivers in the 2021-22 monitoring programme. Data come from a variety of sources, so the workflow is a bit messy. See e-mail from Liv Bente received 31.08.2021 at 12.26 for more details. In addition, the spreadsheet here shows which data sources are usually used for which stations:\n",
    "\n",
    "    K:\\Prosjekter\\Ferskvann\\16384 Elveovervåkingsprogrammet\\2019\\4. Data\\6. Vanntemperatur\\Grunnprogrammet\\2018_TempData_Overview_oppdat for 2019_28aug20.xlsx\n",
    "\n",
    "**Note:** In this notebook I have attempted to switch to HydAPI instead of Hydra-II for the temperature data.\n",
    "\n",
    "## 1. Get manual data from RESA2\n",
    "\n",
    "The code below gets all the temperature data from RESA2 and calculates monthly averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "eng = nivapy.da.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Year of interest\n",
    "year = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find project\n",
    "prj_df = nivapy.da.select_resa_projects(eng)\n",
    "prj_df = prj_df[prj_df[\"project_name\"].str.contains(\"lveovervåking\", na=False)]\n",
    "prj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get stations\n",
    "stn_df = nivapy.da.select_resa_project_stations([4551], eng)\n",
    "stn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Not interested in TROEMÅL (it has now been replaced by TROEMÅL2)\n",
    "stn_df = stn_df.query(\"station_id != 29848\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find ID for temp var\n",
    "par_grid = nivapy.da.select_resa_station_parameters(\n",
    "    stn_df, f\"{year}-01-01\", f\"{year}-12-31\", eng\n",
    ")\n",
    "par_grid.query('parameter_name == \"Temp\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get temp data\n",
    "wc_df, dup_df = nivapy.da.select_resa_water_chemistry(\n",
    "    stn_df,\n",
    "    [125],\n",
    "    f\"{year}-01-01\",\n",
    "    f\"{year}-12-31\",\n",
    "    eng,\n",
    ")\n",
    "\n",
    "wc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print number of measurements in year for each site\n",
    "print(wc_df[[\"station_id\", \"Temp_oC\"]].groupby(\"station_id\").count())\n",
    "\n",
    "# Aggregate to monthly\n",
    "wc_df[\"month\"] = wc_df[\"sample_date\"].dt.month\n",
    "agg = wc_df[[\"station_id\", \"month\", \"Temp_oC\"]].groupby([\"station_id\", \"month\"])\n",
    "mon_df = agg.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot monthly means\n",
    "sn.catplot(\n",
    "    x=\"month\",\n",
    "    y=\"Temp_oC\",\n",
    "    data=mon_df,\n",
    "    col=\"station_id\",\n",
    "    col_wrap=4,\n",
    "    kind=\"point\",\n",
    "    height=3,\n",
    ")\n",
    "\n",
    "# Save\n",
    "out_path = f\"/home/jovyan/shared/common/elveovervakingsprogrammet/temperature_data/temp_2022-23/other/temps_manual_{year}.png\"\n",
    "plt.savefig(out_path, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pivot to \"wide\" format\n",
    "man_df = mon_df.pivot(index=\"station_id\", columns=\"month\", values=\"Temp_oC\")\n",
    "\n",
    "man_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Liv Bente's spreadsheet here\n",
    "\n",
    "    K:\\Prosjekter\\Ferskvann\\16384 Elveovervåkingsprogrammet\\2019\\4. Data\\6. Vanntemperatur\\Grunnprogrammet\\2018_TempData_Overview_oppdat for 2019_28aug20.xlsx\n",
    "    \n",
    "we will use the data from RESA for 9 stations. Filter to just these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter to desired stations for RESA\n",
    "resa_list = [29617, 36225, 29612, 29832, 29842, 29822, 29844, 29820, 29819]\n",
    "man_df = man_df.query(\"station_id in @resa_list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TinyTag data\n",
    "\n",
    "TinyTags are deployed in 7 rivers and the sensors are swapped in the middle of the year, so we need to splice together two data files for each location. The TinyTags are often recording even when they're out of the water, so it's important to know the date when each logger was taken in/set out. Liv Bente stores details in Excel files on the Project Portalen [here](https://niva365.sharepoint.com/sites/projects1/4076/SitePages/home.aspx#nav=InvoDocumentsRecent) under the folder\n",
    "\n",
    "    {year}/Data/Vanntemperatur/TinyTag\n",
    "    \n",
    "This files provide a rough guide, but it is often more obvious from the data exactly when changes have taken place.\n",
    "    \n",
    "**Note:** The date format in the text files sometimes changes (e.g from `%d.%m.%Y %H.%M.%S,%f` to `%d.%m.%Y %H:%M:%S,%f`), so it might be necessary to modify the code below. The raw files may also need converting to UTF-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dates from Liv Bente's spreadsheet\n",
    "swap_dates = {\n",
    "    29615: [\"Numedalslagen\", \"2022-06-07 09:30\"],\n",
    "    29613: [\"Skienselva\", \"2022-06-07 11:00\"],\n",
    "    29614: [\"Otra\", \"2022-06-07 10:34\"],\n",
    "    29783: [\"Orreelva\", \"2022-06-07 09:15\"],\n",
    "    29821: [\"Vosso\", \"2022-06-07 12:25\"],\n",
    "    29782: [\"Vefsna\", \"2022-09-02 11:00\"],\n",
    "    29779: [\"Altaelva\", \"2022-09-30 09:32\"],\n",
    "}\n",
    "\n",
    "# Base folder (with tidied file names)\n",
    "data_fold = r\"/home/jovyan/shared/common/elveovervakingsprogrammet/temperature_data\"\n",
    "\n",
    "# Define date and decimal format for the current and previous year\n",
    "curr_dt_fmt = \"%d.%m.%Y %H:%M:%S.%f\"\n",
    "prev_dt_fmt = \"%d.%m.%Y %H:%M:%S.%f\"\n",
    "curr_dec_sep = \".\"\n",
    "prev_dec_sep = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Container for output\n",
    "df_list = []\n",
    "\n",
    "# Setup plot\n",
    "fig, axes = plt.subplots(nrows=7, ncols=1, figsize=(10, 15), sharex=True)\n",
    "\n",
    "# Loop over stations\n",
    "for idx, stn_id in enumerate(swap_dates.keys()):\n",
    "    # Get stn\n",
    "    stn = swap_dates[stn_id][0]\n",
    "    print(stn)\n",
    "\n",
    "    # Get data paths\n",
    "    path_prev_yr = os.path.join(\n",
    "        data_fold,\n",
    "        f\"temp_{year - 1}-{year - 2000}/tiny_tag/{stn}_{year - 1}-{year - 2000}.txt\",\n",
    "    )\n",
    "    path_yr = os.path.join(\n",
    "        data_fold, f\"temp_{year}-{year - 1999}/tiny_tag/{stn}_{year}-{year - 1999}.txt\"\n",
    "    )\n",
    "\n",
    "    # Parse series 1\n",
    "    df_prev_yr = pd.read_csv(\n",
    "        path_prev_yr,\n",
    "        delim_whitespace=True,\n",
    "        skiprows=2,\n",
    "        names=[\"date\", \"time\", \"temp\"],\n",
    "        decimal=prev_dec_sep,\n",
    "    )\n",
    "    df_prev_yr[\"datetime\"] = df_prev_yr[\"date\"] + \" \" + df_prev_yr[\"time\"]\n",
    "    df_prev_yr[\"datetime\"] = pd.to_datetime(df_prev_yr[\"datetime\"], format=prev_dt_fmt)\n",
    "    df_prev_yr.set_index(\"datetime\", inplace=True)\n",
    "    del df_prev_yr[\"date\"], df_prev_yr[\"time\"]\n",
    "\n",
    "    # Parse series 2\n",
    "    df_yr = pd.read_csv(\n",
    "        path_yr,\n",
    "        delim_whitespace=True,\n",
    "        skiprows=2,\n",
    "        names=[\"date\", \"time\", \"temp\"],\n",
    "        decimal=curr_dec_sep,\n",
    "    )\n",
    "    df_yr[\"datetime\"] = df_yr[\"date\"] + \" \" + df_yr[\"time\"]\n",
    "    df_yr[\"datetime\"] = pd.to_datetime(df_yr[\"datetime\"], format=curr_dt_fmt)\n",
    "    df_yr.set_index(\"datetime\", inplace=True)\n",
    "    del df_yr[\"date\"], df_yr[\"time\"]\n",
    "\n",
    "    # Get date logger changed\n",
    "    swap_dt = pd.to_datetime(swap_dates[stn_id][1])\n",
    "    swap_dt_plus1 = swap_dt + pd.DateOffset(\n",
    "        hours=3\n",
    "    )  # Skip 3 hrs to allow time for re-equilibration\n",
    "\n",
    "    # Truncate series 1\n",
    "    df_prev_yr = df_prev_yr.truncate(before=\"%s-01-01 00:00\" % year, after=swap_dt)\n",
    "\n",
    "    # Truncate series 2\n",
    "    df_yr = df_yr.truncate(before=swap_dt_plus1, after=\"%s-12-31 23:59\" % year)\n",
    "\n",
    "    # Combine\n",
    "    df = pd.merge(df_prev_yr, df_yr, how=\"outer\", left_index=True, right_index=True)\n",
    "\n",
    "    # Plot\n",
    "    df.plot(ax=axes[idx], legend=False)\n",
    "    axes[idx].set_title(stn)\n",
    "    axes[idx].set_xlim([datetime.date(year, 1, 1), datetime.date(year, 12, 31)])\n",
    "\n",
    "    # Concat to single series\n",
    "    df = pd.concat([df_prev_yr, df_yr], axis=0, sort=True)\n",
    "\n",
    "    # Monthly avgs.\n",
    "    df = df.resample(\"M\").mean()\n",
    "\n",
    "    # Add to output\n",
    "    df[\"station_id\"] = stn_id\n",
    "    df_list.append(df)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine results\n",
    "df = pd.concat(df_list, axis=0, sort=True)\n",
    "df.columns = [\"station_id\", \"Temp_oC\"]\n",
    "df[\"month\"] = df.index.month\n",
    "df.reset_index(inplace=True)\n",
    "tt_df = df.pivot(index=\"station_id\", columns=\"month\", values=\"Temp_oC\")\n",
    "\n",
    "tt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Other logger data\n",
    "\n",
    "Other temperature data is also available for Målselv and Vegårdselva (= Storelva/Lundevann)\n",
    "\n",
    "### 3.1. Målselva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "in_xlsx = f\"/home/jovyan/shared/common/elveovervakingsprogrammet/temperature_data/temp_{year}-{year - 1999}/other/malselva_{year}.xlsx\"\n",
    "df = pd.read_excel(in_xlsx, sheet_name=\"Temp\")\n",
    "del df[\"StationName\"]\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Resample\n",
    "df = df.resample(\"M\").mean()\n",
    "\n",
    "# Tidy\n",
    "df.columns = [\"Temp_oC\"]\n",
    "df[\"month\"] = df.index.month\n",
    "df.reset_index(inplace=True)\n",
    "del df[\"Date\"]\n",
    "df[\"station_id\"] = 38005\n",
    "\n",
    "mal_df = df.pivot(index=\"station_id\", columns=\"month\", values=\"Temp_oC\")\n",
    "\n",
    "mal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Vegårdselva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "in_xlsx = f\"/home/jovyan/shared/common/elveovervakingsprogrammet/temperature_data/temp_{year}-{year - 1999}/other/vegardselva_{year}.xlsx\"\n",
    "df = pd.read_excel(in_xlsx, sheet_name=\"Temp\")\n",
    "del df[\"StationName\"]\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Resample\n",
    "df = df.resample(\"M\").mean()\n",
    "\n",
    "# Tidy\n",
    "df.columns = [\"Temp_oC\"]\n",
    "df[\"month\"] = df.index.month\n",
    "df.reset_index(inplace=True)\n",
    "del df[\"Date\"]\n",
    "df[\"station_id\"] = 30019\n",
    "\n",
    "veg_df = df.pivot(index=\"station_id\", columns=\"month\", values=\"Temp_oC\")\n",
    "\n",
    "veg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. NVE data\n",
    "\n",
    "In 2019, NVE datasets were only required for Vikedalselva and Orkla.\n",
    "\n",
    "**Note:** For Orkla, we usually use data from 121.62.0, as this site has a long temperature record. However, in 2022 the data from this location are not complete, so for this year I will use data from 121.22.0, which is just downstream. Similarly, data for Vikedalselva (`38.2.0`) are not complete for 2022, but the series from Holmen (`38.1.0`) looks OK and is only about 50 m upstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dict mapping NVE temp codes to RESA IDs\n",
    "stn_id_dict = {\n",
    "    #     \"2.1087.0\": 29617,\n",
    "    #     \"12.298.0\": 29612,\n",
    "    #     \"15.115.0\": 29615,\n",
    "    #     \"16.207.0\": 29613,\n",
    "    #     \"21.79.0\": 29614,\n",
    "    #     \"27.29.0\": 29832,\n",
    "    # \"38.2.0\": 29837,  # Vikedalselva utløp. Use this if possible\n",
    "    \"38.1.0\": 29837,  # Holmen, about 50 m upstream of Vikedalselva utløp. Use this if problems with Vikedalselva utløp\n",
    "    #     \"62.30.0\": 29821,\n",
    "    #     \"84.23.0\": 29842,\n",
    "    # \"121.62.0\": 29778,  # Orkla (with long time series, not good in 2020)\n",
    "    \"121.22.0\": 29778,  # Orkla (with OK data for 2020, but nothing before 2014)\n",
    "    #     \"151.32.0\": 29782,\n",
    "    #     \"246.11.0\": 29819,\n",
    "    # \"212.11.0\": 29779,  # Alta\n",
    "}\n",
    "\n",
    "# Get stations from HydAPI\n",
    "nve_stn_df = nivapy.da.get_nve_hydapi_stations(api_key=api_key)\n",
    "nve_stn_ids = stn_id_dict.keys()\n",
    "nve_stn_df = nve_stn_df.query(\"station_id in @nve_stn_ids\")\n",
    "print(f\"{len(nve_stn_df)} out of {len(nve_stn_ids)} stations found in HydAPI:\")\n",
    "nve_stn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get temperature\n",
    "par_ids = [1003]\n",
    "st_dt = f\"{year}-01-01\"\n",
    "end_dt = f\"{year + 1}-01-01\"\n",
    "nve_df = nivapy.da.query_nve_hydapi(\n",
    "    nve_stn_ids, par_ids, st_dt, end_dt, resolution=1440, api_key=api_key\n",
    ")\n",
    "nve_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check number of records as expected\n",
    "days = 366 if calendar.isleap(year) else 365\n",
    "if len(nve_df) != len(nve_stn_df) * days:\n",
    "    print(\"Number of records is not as expected.\\n\\n\")\n",
    "\n",
    "# Check quality control level\n",
    "print(\"The following series have not completed quality control (i.e. 'quality' < 3;\")\n",
    "print(\"see https://hydapi.nve.no/UserDocumentation/ for details):\\n\")\n",
    "print(nve_df.query(\"quality != 3\")[[\"station_id\", \"station_name\"]].drop_duplicates())\n",
    "\n",
    "# Check for NaN\n",
    "if pd.isna(nve_df[\"value\"]).sum() > 0:\n",
    "    print(\"\\n\\nThe following records contain NaN values:\\n\")\n",
    "    print(\n",
    "        nve_df[pd.isna(nve_df[\"value\"])][\n",
    "            [\"station_id\", \"station_name\"]\n",
    "        ].drop_duplicates()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "sn.relplot(\n",
    "    x=\"datetime\",\n",
    "    y=\"value\",\n",
    "    row=\"station_name\",\n",
    "    data=nve_df,\n",
    "    kind=\"line\",\n",
    "    aspect=3,\n",
    "    height=2,\n",
    "    facet_kws={\"sharey\": True, \"sharex\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resample\n",
    "df_list = []\n",
    "\n",
    "for stn_cd in stn_id_dict.keys():\n",
    "    df = nve_df.query(\"station_id == @stn_cd\").copy()\n",
    "    df = df.set_index(\"datetime\")[[\"value\"]]\n",
    "    df = df.resample(\"M\").mean()\n",
    "\n",
    "    # Convert index to month\n",
    "    df.index = df.index.month\n",
    "    df.index.name = \"month\"\n",
    "\n",
    "    # Change column to site id\n",
    "    df.columns = [\n",
    "        stn_id_dict[stn_cd],\n",
    "    ]\n",
    "\n",
    "    # Transpose and append\n",
    "    df_list.append(df.T)\n",
    "\n",
    "# Combine\n",
    "nve_df = pd.concat(df_list, axis=0, sort=True)\n",
    "nve_df.index.name = \"station_id\"\n",
    "nve_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt all and combine\n",
    "# RESA\n",
    "man_df2 = man_df.reset_index().melt(id_vars=\"station_id\")\n",
    "man_df2[\"source\"] = \"Manual\"\n",
    "\n",
    "# TinyTag\n",
    "tt_df2 = tt_df.reset_index().melt(id_vars=\"station_id\")\n",
    "tt_df2[\"source\"] = \"TinyTag\"\n",
    "\n",
    "# Other\n",
    "mal_df2 = mal_df.reset_index().melt(id_vars=\"station_id\")\n",
    "mal_df2[\"source\"] = \"Other\"\n",
    "\n",
    "veg_df2 = veg_df.reset_index().melt(id_vars=\"station_id\")\n",
    "veg_df2[\"source\"] = \"Other\"\n",
    "\n",
    "# NVE\n",
    "nve_df2 = nve_df.reset_index().melt(id_vars=\"station_id\")\n",
    "nve_df2[\"source\"] = \"NVE\"\n",
    "\n",
    "# Combine\n",
    "df = pd.concat([man_df2, tt_df2, mal_df2, veg_df2, nve_df2], axis=0, sort=True)\n",
    "\n",
    "# Join stn codes\n",
    "df = pd.merge(df, stn_df[[\"station_id\", \"station_code\"]], how=\"left\", on=\"station_id\")\n",
    "del df[\"station_id\"]\n",
    "df.columns = [\"Month\", \"Source\", \"Temperature (C)\", \"Station code\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "sn.catplot(\n",
    "    x=\"Month\",\n",
    "    y=\"Temperature (C)\",\n",
    "    data=df,\n",
    "    # hue='Source',\n",
    "    col=\"Station code\",\n",
    "    col_wrap=4,\n",
    "    height=3,\n",
    "    # linestyles=['--', '--', '--', '--'],\n",
    "    kind=\"point\",\n",
    ")\n",
    "\n",
    "# Save\n",
    "out_path = f\"/home/jovyan/shared/common/elveovervakingsprogrammet/temperature_data/temp_{year}-{year - 1999}/temps_all_sources_{year}.png\"\n",
    "plt.savefig(out_path, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Format for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "df = pd.concat([man_df, tt_df, mal_df, veg_df, nve_df], axis=0, sort=True)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Join station details\n",
    "df = pd.merge(df, stn_df, how=\"left\", on=\"station_id\")\n",
    "\n",
    "# Reorder\n",
    "df = df[\n",
    "    [\"station_id\", \"station_code\", \"station_name\", \"latitude\", \"longitude\", \"altitude\"]\n",
    "    + list(range(1, 13))\n",
    "]\n",
    "del df[\"latitude\"], df[\"longitude\"], df[\"altitude\"]\n",
    "\n",
    "# Round values\n",
    "df = df.round(2)\n",
    "\n",
    "# Save output\n",
    "out_csv = f\"/home/jovyan/shared/common/elveovervakingsprogrammet/temperature_data/temp_{year}-{year - 1999}/monthly_avg_temps_{year}-{year - 1999}.csv\"\n",
    "df.to_csv(out_csv, encoding=\"utf-8\", index=False)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
