{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate RID data tables for Microsoft Word\n",
    "\n",
    "This notebook includes code for creating Word tables in the output format required by the RID project.\n",
    "\n",
    "## 1. Get site data\n",
    "\n",
    "### 1.1. Establish database connection and import RID functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "resa2_basic_path = (r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\Upload_Template'\n",
    "                    r'\\useful_resa2_code.py')\n",
    "\n",
    "resa2_basic = imp.load_source('useful_resa2_code', resa2_basic_path)\n",
    "\n",
    "engine, conn = resa2_basic.connect_to_resa2()\n",
    "\n",
    "# Import custom RID functions\n",
    "rid_func_path = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "                 r'\\Python\\rid\\notebooks\\useful_rid_code.py')\n",
    "\n",
    "rid = imp.load_source('useful_rid_code', rid_func_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Basic site metadata for stations of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Read site data\n",
    "in_xlsx = r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\RID_Sites_List.xlsx'\n",
    "\n",
    "rid_11_df = pd.read_excel(in_xlsx, sheetname='RID_11')\n",
    "rid_36_df = pd.read_excel(in_xlsx, sheetname='RID_36')\n",
    "rid_108_df = pd.read_excel(in_xlsx, sheetname='RID_108')\n",
    "\n",
    "# Drop the 37th site (with no NVE code) from RID_36\n",
    "rid_36_df.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tables of raw water chemistry data\n",
    "\n",
    "The first set of tables displays raw water chemistry values for the 11 main rivers and the 36 tributaries. I've created a template in Word based on Tore's previous output that includes 47 blank tables:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Results\\Word_Tables\\Table_Templates\\rid_water_chem_tables_template.docx\n",
    "\n",
    "**Do not modify this document**. Instead, create a copy of it and use the code below to modify the copy with the desired data.\n",
    "\n",
    "The code below fills in the Word template with data from 2015. The output is available in PDF format [here](https://github.com/JamesSample/rid/blob/master/pdf/TABLE1_2015_JES.pdf) and can be compared to the results in *Table 1a* of the 2015 report (page 148 onwards). \n",
    "\n",
    "**Note:** I haven't yet worried about number formatting (number of decimal places etc.) or conditional formatting of cells (i.e. colour codes). These features can be easily added later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concatenate data for RID_11 and RID_36 sites\n",
    "stn_df = pd.concat([rid_11_df, rid_36_df], axis=0)\n",
    "\n",
    "# Path to *COPIED* template for editing\n",
    "in_docx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Results\\Word_Tables\\2016Analysis_2015Data\\TABLE1_2015_JES.docx')\n",
    "\n",
    "# Write tables for 2015\n",
    "rid.write_word_water_chem_tables(stn_df, 2015, in_docx, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tables of loads at each site\n",
    "\n",
    "The next set of tables shows annual pollutant loads for each of the 155 main sites. A Word template based on Tore's previous output is here:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Results\\Word_Tables\\Table_Templates\\rid_loads_by_river_template.docx\n",
    "\n",
    "**Do not modify this document**. Instead, create a copy of it and use the code below to modify the copy with the desired data.\n",
    "\n",
    "The code below reads the output produced by [loads notebook](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/estimate_loads.ipynb) and fills-in the template with data from 2015. The finished table is available in PDF format [here](https://github.com/JamesSample/rid/blob/master/pdf/TABLE2_2015_JES.pdf) and can be compared to *Table 2a* of the 2015 report (page 186 onwards). \n",
    "\n",
    "**Note:** I have made the following changes to the orginal table from the report (see section 2.2 of [this notebook](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/estimate_loads.ipynb) for details):\n",
    "\n",
    " * The original table included duplicated sites/rows, which have now been removed <br><br>\n",
    " \n",
    " * The original table did not distinguish between two sites named Børselva and two named Oselva. For these four locations, I have added the site code in brackets after the site name to avoid confusion i.e. `Børselva (FINEBØR)` versus `Børselva (STREBØR)` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate data for RID_11, RID_36 and RID_108 sites\n",
    "stn_df = pd.concat([rid_11_df, rid_36_df, rid_108_df], axis=0)\n",
    "\n",
    "# Path to *COPIED* template for editing\n",
    "in_docx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Results\\Word_Tables\\2016Analysis_2015Data\\TABLE2_2015_JES.docx')\n",
    "\n",
    "# Read loads data (from \"loads notebook\")\n",
    "loads_csv = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "             r'\\Results\\Loads_CSVs\\loads_all_sites_2015.csv')\n",
    "\n",
    "# Write tables for 2015\n",
    "rid.write_word_loads_table(stn_df, loads_csv, in_docx, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Annual summary of monitored and modelled loads\n",
    "\n",
    "The third data table combines all the data from the entire project. Before running the code below, it is necessary to have processed all the monitoring data (creating a file like *loads_and_flows_all_sites_2016.csv* - see [this notebook](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/rid_working_2016-17.ipynb)), as well as completing the modelling for unmonitored locations (creating a file like *unmon_loads_2015.csv* - see [this notebook](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/loads_unmonitored_regions.ipynb)). The code below restructures these files and writes the final output to Word.\n",
    "\n",
    "A Word template modified from Tore's previous output is here:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Results\\Word_Tables\\Table_Templates\\rid_loads_overall_summary_template.docx\n",
    "\n",
    "**Do not modify this document**. Instead, create a copy of it and use the code below to modify the copy with the desired data.\n",
    "\n",
    "### 4.1. Summarise monitoring data\n",
    "\n",
    "The code below adds up the monitored loads. Note that because some of the tributary rivers are upstream of others, it is necessary to build the catchment network using NOPE to identify the downstream-most catchments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "nope_path = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "             r'\\Python\\rid\\notebooks\\nope.py')\n",
    "nope = imp.load_source('nope', nope_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read station data\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\RID_Sites_List.xlsx')\n",
    "stn_df = pd.read_excel(in_xlsx, sheetname='RID_All')\n",
    "\n",
    "# Get just cols of interest and drop duplicates \n",
    "# (some sites are in the same regine)\n",
    "stn_df = stn_df.drop_duplicates(subset=['ospar_region', 'nve_vassdrag_nr'])\n",
    "\n",
    "# Get catch IDs with calib data\n",
    "calib_nds = set(stn_df['nve_vassdrag_nr'].values)\n",
    "\n",
    "# Build network\n",
    "in_path = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\NOPE\\NOPE_Annual_Inputs\\nope_input_data_1990.csv')\n",
    "g, nd_list = nope.build_calib_network(in_path, calib_nds)\n",
    "\n",
    "# Get list of downstream nodes\n",
    "ds_nds = []\n",
    "for nd in g:\n",
    "    # If no downstream nodes\n",
    "    if g.out_degree(nd) == 0:\n",
    "        # Node is of interest\n",
    "        ds_nds.append(nd)\n",
    "\n",
    "# Get just the downstream catchments\n",
    "stn_df = stn_df[stn_df['nve_vassdrag_nr'].isin(ds_nds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "in_csv = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "          r'\\Results\\Loads_CSVs\\loads_and_flows_all_sites_2015.csv')\n",
    "mon_df = pd.read_csv(in_csv)\n",
    "\n",
    "# Get just the downstream catchments\n",
    "#mon_df = mon_df[mon_df['station_id'].isin(stn_df['station_id'].values)]\n",
    "\n",
    "# Group by OSPAR region\n",
    "mon_df1 = mon_df.groupby(['ospar_region', 'rid_group']).sum()\n",
    "\n",
    "# Totals for Norway\n",
    "mon_df2 = mon_df.groupby('rid_group').sum().reset_index()\n",
    "mon_df2['ospar_region'] = 'NORWAY'\n",
    "mon_df2.set_index(['ospar_region', 'rid_group'], inplace=True)\n",
    "\n",
    "# Combine\n",
    "mon_df = pd.concat([mon_df1, mon_df2], axis=0)\n",
    "\n",
    "# Cols of interest\n",
    "cols = [i for i in mon_df.columns if i.split('_')[1] != 'Est']\n",
    "mon_df = mon_df[cols]\n",
    "del mon_df['station_id']\n",
    "\n",
    "# Rename cols to match template\n",
    "mon_df['Flow rate_1000m3/day'] = mon_df['mean_q_1000m3/day']\n",
    "del mon_df['mean_q_1000m3/day']\n",
    "\n",
    "# Units are correct, so remove\n",
    "mon_df.columns = [i.split('_')[0] for i in mon_df.columns]\n",
    "\n",
    "mon_df.round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Data for unmonitored areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "in_csv = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "          r'\\Results\\Unmon_loads\\unmon_loads_2015.csv')\n",
    "umon_df = pd.read_csv(in_csv, index_col=0)\n",
    "\n",
    "# Rename cols\n",
    "umon_df.columns = [i.replace('RENSEANLEGG', 'sew') for i in umon_df.columns]\n",
    "umon_df.columns = [i.replace('INDUSTRI', 'ind') for i in umon_df.columns]\n",
    "umon_df.columns = [i.replace('_tonn', '') for i in umon_df.columns]\n",
    "umon_df.columns = [i.replace('AQUAKULTUR', 'fish') for i in umon_df.columns]\n",
    "\n",
    "# Convert Hg to kgs\n",
    "umon_df['sew_Hg'] = umon_df['sew_Hg']*1000\n",
    "umon_df['ind_Hg'] = umon_df['ind_Hg']*1000\n",
    "\n",
    "umon_df.round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Process template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create table 3\n",
    "in_docx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Results\\Word_Tables\\2016Analysis_2015Data\\TABLE3_2015_JES.docx')\n",
    "\n",
    "rid.write_word_overall_table(mon_df, umon_df, in_docx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in [this table](https://github.com/JamesSample/rid/blob/master/pdf/TABLE3_2015_JES.pdf) are very similar to those in Table 3 of the 2015 report (page 202 onwards). Minor differences between my output and that reported in 2015 can be explained as follows:\n",
    "\n",
    " * There are very minor discrepancies between the regine catchments considered as \"monitored\" in my workflow compared to Tore's. I think Tore's code may include some monitored discharges twice, as some monitored catchments appear to upstream of one another. Overall, these differences are negligible <br><br>\n",
    " \n",
    " * My handling of LOD values is different to Tore's. Furthermore, my method for estimating historic concentrations for the RID 108 stations is substantially different - see [this notebook](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/estimate_loads.ipynb) for details.<br><br>\n",
    " \n",
    " * For unmonitored locations, my new model uses a different (an in my opinion improved) method for estimating annual runoff for each regine catchment. The total flows estimated by the new model are therefore slightly different. <br><br>\n",
    " \n",
    " * The new model assumes that \"local\" inputs are added at the upstream boundary of the catchment (and are therefore subject to retention), whereas I think TEOTIL assumes local inputs are added at the catchment outflow (so the retention factor is not applied). Both seem reasonable, but one consequence is that the new model predicts slightly lower loads than the old one.\n",
    " \n",
    "Overall, I'm pretty happy that these results are comparable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
