{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nivapy3 as nivapy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import useful_rid_code as rid\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "sn.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RID \n",
    "\n",
    "## Fill-in OSPAR flows worksheet (parameterised)\n",
    "\n",
    "This notebook is \"parameterised\" for use with Papermill. The cell below has the tag `parameters`, which means the entire notebook can be called from `01_recalculate_ospar_1990-2016_main.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is tagged 'parameters' for use with Papermill\n",
    "# https://papermill.readthedocs.io/en/latest/index.html\n",
    "year = 1990\n",
    "user = \"\"\n",
    "pw = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Discharges from monitored locations\n",
    "\n",
    "The code below extracts summary statistics for 10 of the RID_11 stations from 1990 to 2016 inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "\n",
    "# Read site data for RID_11 and RID_36\n",
    "in_xlsx = r\"../../../Data/RID_Sites_List.xlsx\"\n",
    "rid_11_df = pd.read_excel(in_xlsx, sheet_name=\"RID_11\")\n",
    "rid_36_df = pd.read_excel(in_xlsx, sheet_name=\"RID_36\")\n",
    "\n",
    "# Get just SuldalslÃ¥gen from rid_36\n",
    "rid_36_df = rid_36_df.query(\"station_id == 29781\")\n",
    "\n",
    "# Combine\n",
    "mon_df = pd.concat([rid_11_df, rid_36_df], axis=0)\n",
    "\n",
    "# Get OSPAR region for stations\n",
    "sql = \"SELECT station_id, value FROM resa2.stations_par_values WHERE var_id = 262\"\n",
    "ospar_reg = pd.read_sql_query(sql, engine)\n",
    "ospar_reg.columns = [\"station_id\", \"ospar_region\"]\n",
    "\n",
    "# Join OSPAR regions to station data\n",
    "mon_df = pd.merge(mon_df, ospar_reg, how=\"left\", on=\"station_id\")\n",
    "\n",
    "# Get cols of interest\n",
    "mon_df[\"ospar_region\"] = mon_df[\"ospar_region_x\"]\n",
    "mon_df = mon_df[[\"station_id\", \"station_code\", \"station_name\", \"ospar_region\"]]\n",
    "\n",
    "mon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "\n",
    "# Container for results\n",
    "df_list = []\n",
    "\n",
    "# Loop over sites\n",
    "for stn_id in mon_df[\"station_id\"]:\n",
    "    # Get catch area for chem station\n",
    "    sql = f\"SELECT catchment_area FROM resa2.stations WHERE station_id = {stn_id}\"\n",
    "    area_df = pd.read_sql_query(sql, engine)\n",
    "    wc_area = area_df[\"catchment_area\"].iloc[0]\n",
    "\n",
    "    # Get linked discharge station\n",
    "    sql = f\"SELECT * FROM resa2.default_dis_stations WHERE station_id = {stn_id}\"\n",
    "    dis_df = pd.read_sql_query(sql, engine)\n",
    "    dis_stn_id = dis_df[\"dis_station_id\"].iloc[0]\n",
    "\n",
    "    # Get catchment area for discharge station\n",
    "    sql = (\n",
    "        \"SELECT area FROM resa2.discharge_stations \"\n",
    "        \"WHERE dis_station_id = %s\" % dis_stn_id\n",
    "    )\n",
    "    area_df = pd.read_sql_query(sql, engine)\n",
    "    dis_area = area_df[\"area\"].iloc[0]\n",
    "\n",
    "    # Get annual summary flow stats for this station\n",
    "    sql = (\n",
    "        \"SELECT TO_CHAR(xdate, 'YYYY') as year, \"\n",
    "        \"       AVG(xvalue) as mean, \"\n",
    "        \"       MIN(xvalue) as min, \"\n",
    "        \"       MAX(xvalue) as max \"\n",
    "        \"FROM resa2.discharge_values \"\n",
    "        \"WHERE dis_station_id = %s \"\n",
    "        \"AND xdate >= date '1990-01-01' \"\n",
    "        \"AND xdate <= date '%s-12-31' \"\n",
    "        \"GROUP BY TO_CHAR(xdate, 'YYYY') \"\n",
    "        \"ORDER BY year\" % (dis_stn_id, year)\n",
    "    )\n",
    "    q_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "    # Set index\n",
    "    q_df.index = q_df[\"year\"]\n",
    "    del q_df[\"year\"]\n",
    "\n",
    "    # Scale flows by area ratio\n",
    "    q_df = q_df * wc_area / dis_area\n",
    "\n",
    "    # Convert m3/s to 1000 m3/d\n",
    "    q_df = q_df * 60 * 60 * 24 / 1000\n",
    "\n",
    "    # Reset index\n",
    "    q_df.reset_index(inplace=True)\n",
    "\n",
    "    # Add LTA and n_yrs\n",
    "    q_df[\"lta\"] = q_df[\"mean\"].mean()\n",
    "    q_df[\"n_yrs\"] = len(q_df)\n",
    "\n",
    "    # Add ospar region ID, n_sites and 'mean' cols\n",
    "    q_df[\"area_id\"] = stn_id\n",
    "    q_df[\"stat\"] = \"Mean\"\n",
    "    q_df[\"n_sites\"] = 1\n",
    "\n",
    "    # Re-order cols to match template\n",
    "    q_df = q_df[\n",
    "        [\"area_id\", \"year\", \"mean\", \"lta\", \"min\", \"max\", \"n_yrs\", \"n_sites\", \"stat\"]\n",
    "    ]\n",
    "\n",
    "    # Add to results\n",
    "    df_list.append(q_df)\n",
    "\n",
    "# Combine to single df\n",
    "q_mon_df = pd.concat(df_list, axis=0)\n",
    "\n",
    "q_mon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "\n",
    "# Read cols of interest from Regine.txt\n",
    "in_txt = r\"../../../Recalculate_OSPAR_Flows/Regine.txt\"\n",
    "teo_df = pd.read_csv(in_txt, sep=\";\", comment=\"!\", usecols=[\"Regine\", \"VASSOMR\"])\n",
    "teo_df.columns = [\"regine\", \"vassdrag\"]\n",
    "\n",
    "# Read data from RESA2.RID_REGINE_DOWN\n",
    "sql = \"SELECT regine, area_fp FROM resa2.rid_regine_down\"\n",
    "ospar_reg = pd.read_sql_query(sql, engine)\n",
    "\n",
    "# Join\n",
    "nve_df = pd.merge(ospar_reg, teo_df, how=\"left\", on=\"regine\")\n",
    "\n",
    "# Get cols of interest and simplify\n",
    "nve_df = nve_df[[\"area_fp\", \"vassdrag\"]]\n",
    "nve_df.drop_duplicates(inplace=True)\n",
    "\n",
    "## We already have monitored data for 10 of these vassdrags (see above)\n",
    "## Remove these from consideration to avoid \"double-counting\"\n",
    "## Get discharge station ids\n",
    "# sql = (\"SELECT * FROM resa2.default_dis_stations \"\n",
    "#       \"WHERE station_id IN %s\" % str(tuple(mon_df['station_id'].values)))\n",
    "# dis_df = pd.read_sql_query(sql, engine)\n",
    "#\n",
    "## Get vassdrag numbers for montiored stations\n",
    "# sql = (\"SELECT nve_serienummer FROM resa2.discharge_stations \"\n",
    "#       \"WHERE dis_station_id IN %s\" % str(tuple(dis_df['dis_station_id'].values)))\n",
    "# vass_nr = pd.read_sql_query(sql, engine)['nve_serienummer'].values\n",
    "# vass_nr = [int(i.split('.')[0]) for i in vass_nr]\n",
    "#\n",
    "## Remove these vass_nrs from consideration in the modelled data\n",
    "# nve_df = nve_df[~nve_df['vassdrag'].isin(vass_nr)]\n",
    "\n",
    "nve_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_flow_data(vass, reg):\n",
    "    \"\"\"Function to combine time series for list of Vassdrags\n",
    "        based on the NVE modelled data.\n",
    "\n",
    "    Args:\n",
    "        vass: List of strings. Vassdrags to combine\n",
    "        reg:  Str. ID for region\n",
    "\n",
    "    Returns:\n",
    "        Dataframe. Annual summary stats calculated from the\n",
    "        combined series (for 1990 to 2016)\n",
    "    \"\"\"\n",
    "    # Get RESA2 station ID from vassdrag numbers\n",
    "    sql = (\n",
    "        \"SELECT dis_station_id \"\n",
    "        \"FROM resa2.discharge_stations \"\n",
    "        \"WHERE nve_serienummer IN %s\" % str(tuple(vass))\n",
    "    )\n",
    "    dis_ids = pd.read_sql_query(sql, engine)\n",
    "\n",
    "    assert len(dis_ids) == len(vass), 'Lengths of \"vass\" and \"dis_ids\" do not match.'\n",
    "\n",
    "    # Sum flow data for all sites in OSPAR reg to create a single\n",
    "    # aggregated series\n",
    "    # Get annual summary flow stats for this region\n",
    "    sql = (\n",
    "        \"SELECT TO_CHAR(xdate, 'YYYY') as year, \"\n",
    "        \"       AVG(xvalue) as mean, \"\n",
    "        \"       MIN(xvalue) as min, \"\n",
    "        \"       MAX(xvalue) as max \"\n",
    "        \"FROM ( \"\n",
    "        \"  SELECT TRUNC(xdate) AS xdate, \"\n",
    "        \"         SUM(xvalue) AS xvalue \"\n",
    "        \"  FROM resa2.discharge_values \"\n",
    "        \"  WHERE dis_station_id IN %s \"\n",
    "        \"  AND xdate >= DATE '1990-01-01' \"\n",
    "        \"  AND xdate <= DATE '%s-12-31' \"\n",
    "        \"  GROUP BY TRUNC(xdate) \"\n",
    "        \"  ORDER BY TRUNC(xdate)) \"\n",
    "        \"WHERE xdate >= date '1990-01-01' \"\n",
    "        \"AND xdate <= date '%s-12-31' \"\n",
    "        \"GROUP BY TO_CHAR(xdate, 'YYYY') \"\n",
    "        \"ORDER BY year\" % (str(tuple(dis_ids[\"dis_station_id\"].values)), year, year)\n",
    "    )\n",
    "    q_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "    # Set index\n",
    "    q_df.index = q_df[\"year\"]\n",
    "    del q_df[\"year\"]\n",
    "\n",
    "    # Convert m3/s to 1000 m3/d\n",
    "    q_df = q_df * 60 * 60 * 24 / 1000\n",
    "\n",
    "    # Reset index\n",
    "    q_df.reset_index(inplace=True)\n",
    "\n",
    "    # Add LTA and n_yrs\n",
    "    q_df[\"lta\"] = q_df[\"mean\"].mean()\n",
    "    q_df[\"n_yrs\"] = len(q_df)\n",
    "\n",
    "    # Add ospar region ID, n_sites and 'mean' cols\n",
    "    q_df[\"area_id\"] = reg\n",
    "    q_df[\"stat\"] = \"Mean\"\n",
    "    q_df[\"n_sites\"] = len(vass)\n",
    "\n",
    "    # Re-order cols to match template\n",
    "    q_df = q_df[\n",
    "        [\"area_id\", \"year\", \"mean\", \"lta\", \"min\", \"max\", \"n_yrs\", \"n_sites\", \"stat\"]\n",
    "    ]\n",
    "\n",
    "    return q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "\n",
    "# Container for results\n",
    "df_list = []\n",
    "\n",
    "# Loop over OSPAR areas\n",
    "for osp_reg in nve_df[\"area_fp\"].unique():\n",
    "    # Get all vassdrags draining to this region\n",
    "    vass = nve_df.query(\"area_fp == @osp_reg\")[\"vassdrag\"].values.astype(str)\n",
    "\n",
    "    # Get stats\n",
    "    q_df = combine_flow_data(vass, osp_reg)\n",
    "\n",
    "    # Add to results\n",
    "    df_list.append(q_df)\n",
    "\n",
    "# Single calculation for the whole of norway\n",
    "vass = nve_df[\"vassdrag\"].values.astype(str)\n",
    "q_df = combine_flow_data(vass, \"all_nor\")\n",
    "df_list.append(q_df)\n",
    "\n",
    "# Combine to single df\n",
    "q_mod_df = pd.concat(df_list, axis=0)\n",
    "\n",
    "q_mod_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write results to template\n",
    "\n",
    "The code below iterates over the output and writes the results to the Excel template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to template\n",
    "osp_path = f\"../../../Results/OSPAR/01_OSPAR_Norway_{year}.xlsx\"\n",
    "\n",
    "# Dict mappiong names in template to area IDs in dfs\n",
    "name_dict = {\n",
    "    \"Orkla\": 29778,\n",
    "    \"Vefsna\": 29782,\n",
    "    \"Norwegian Sea (NO)\": \"91_170\",\n",
    "    \"Alta\": 29779,\n",
    "    \"Barents Sea (NO)\": \"171_247\",\n",
    "    \"Glomma\": 29617,\n",
    "    \"Drammenselva\": 29612,\n",
    "    \"NumedalslÃ¥gen\": 29615,\n",
    "    \"Skienselva\": 29613,\n",
    "    \"Otra\": 29614,\n",
    "    \"Inner Oslofjord\": 36225,  # Assume just Alna for now(?)\n",
    "    \"Skagerrak (NO)\": \"1_23\",\n",
    "    \"Orreelva\": 29783,\n",
    "    \"SuldalslÃ¥gen\": 29781,\n",
    "    \"Vosso\": 29821,\n",
    "    \"North Sea (NO)\": \"24_90\",\n",
    "    \"Norway Total\": \"all_nor\",\n",
    "}\n",
    "\n",
    "# Open new file and get sheet\n",
    "wb = load_workbook(filename=osp_path)\n",
    "ws = wb[\"9\"]\n",
    "\n",
    "year = str(year)\n",
    "for item in ws[\"B12\":\"B28\"]:\n",
    "    # Get cell properties\n",
    "    cell = item[0]\n",
    "    area = cell.value\n",
    "    row = cell.row\n",
    "\n",
    "    # Get area ID\n",
    "    ar_id = name_dict[area]\n",
    "\n",
    "    if ar_id != 999:\n",
    "        # Get data from relevant df\n",
    "        if isinstance(ar_id, int):\n",
    "            # Monitored df\n",
    "            df = q_mon_df.query(\"(area_id == @ar_id) and (year == @year)\")\n",
    "        else:\n",
    "            # Modelled df\n",
    "            df = q_mod_df.query(\"(area_id == @ar_id) and (year == @year)\")\n",
    "\n",
    "        assert len(df) == 1\n",
    "\n",
    "        # Write values\n",
    "        # 1. Mean\n",
    "        ws.cell(column=5, row=row, value=df.iloc[0][\"mean\"])\n",
    "\n",
    "        # 2. LTA\n",
    "        ws.cell(column=7, row=row, value=df.iloc[0][\"lta\"])\n",
    "\n",
    "        # 3. Min\n",
    "        ws.cell(column=9, row=row, value=df.iloc[0][\"min\"])\n",
    "\n",
    "        # 4. Max\n",
    "        ws.cell(column=11, row=row, value=df.iloc[0][\"max\"])\n",
    "\n",
    "        # 5. Years\n",
    "        ws.cell(column=13, row=row, value=df.iloc[0][\"n_yrs\"])\n",
    "\n",
    "        # 6. N_Sites\n",
    "        ws.cell(column=15, row=row, value=df.iloc[0][\"n_sites\"])\n",
    "\n",
    "        # 7. Stat\n",
    "        ws.cell(column=17, row=row, value=df.iloc[0][\"stat\"])\n",
    "\n",
    "# Save\n",
    "wb.save(osp_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
