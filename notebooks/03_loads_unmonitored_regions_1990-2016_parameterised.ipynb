{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nivapy3 as nivapy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import teotil2 as teo\n",
    "import useful_rid_code as rid\n",
    "\n",
    "sn.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RID\n",
    "\n",
    "## Estimating loads in unmonitored regions (parameterised)\n",
    "\n",
    "This notebook is \"parameterised\" for use with Papermill. The cell below has the tag `parameters`, which means the entire notebook can be called from `01_recalculate_ospar_1990-2016_main.ipynb`.\n",
    "\n",
    "The [TEOTIL2 model](https://nivanorge.github.io/teotil2/) is used to estimate loads in unmonitored areas. We know the regine ID for each of the 155 stations where water chemistry is measured, and we also know which OSPAR region each monitoring site drains to. We want to use observed data to estimate loads upstream of each monitoring point, and modelled data elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is tagged 'parameters' for use with Papermill\n",
    "# https://papermill.readthedocs.io/en/latest/index.html\n",
    "year = 1990\n",
    "user = \"\"\n",
    "pw = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate model input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of interest\n",
    "par_list = [\"Tot-N\", \"Tot-P\"]\n",
    "\n",
    "# Path to TEOTIL2 \"core\" input data\n",
    "teo_fold = r\"../../../teotil2/data/core_input_data\"\n",
    "\n",
    "# Ouput path for model file\n",
    "ann_input_csv = f\"../../../teotil2/data/norway_annual_input_data/input_data_{year}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "df = teo.io.make_input_file(\n",
    "    year, engine, teo_fold, ann_input_csv, mode=\"nutrients\", par_list=par_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run model\n",
    "g = teo.model.run_model(ann_input_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results as csv\n",
    "res_csv = f\"../../../teotil2/data/norway_annual_output_data/teotil2_results_{year}.csv\"\n",
    "df = teo.model.model_to_dataframe(g, out_path=res_csv)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save version with main catchments only\n",
    "main_list = [\"%03d.\" % i for i in range(1, 316)]\n",
    "df2 = df.query(\"regine in @main_list\")\n",
    "df2.sort_values(\"regine\", inplace=True)\n",
    "\n",
    "# Save\n",
    "main_csv = f\"../../../Results/Unmon_loads/teotil2_results_{year}_main_catchs.csv\"\n",
    "df2.to_csv(main_csv, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore results\n",
    "\n",
    "### 4.1. Total N and P\n",
    "\n",
    "####  4.1.1. Identify areas with monitoring data\n",
    "\n",
    "Where observations are available, we want to use them in preference to the model output. This means identifying all the catchments with observed data and substracting the model results for these locations. This is more complicated than it appears, because a small number of observed catchments are upstream of others, so subtracting all the loads for the 155 monitored catchments involves \"double accounting\", which we want to avoid. The first step is therefore to identify the downstream-most nodes for the monitored areas i.e. for the cases where one catchment is upstream of another, we just want the downstream node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read station data\n",
    "in_xlsx = r\"../../../Data/RID_Sites_List_2017-2020.xlsx\"\n",
    "stn_df = pd.read_excel(in_xlsx, sheet_name=\"RID_All\")\n",
    "stn_df = stn_df.query(\"station_id != 38005\")  # Ignore TROEMÃ…L2\n",
    "\n",
    "# Get just cols of interest and drop duplicates\n",
    "# (some sites are in the same regine)\n",
    "stn_df = stn_df[[\"ospar_region\", \"nve_vassdrag_nr\"]].drop_duplicates()\n",
    "\n",
    "# Get catch IDs with obs data\n",
    "obs_nds = set(stn_df[\"nve_vassdrag_nr\"].values)\n",
    "\n",
    "# Build network from input file\n",
    "g, nd_list = teo.calib.build_calib_network(ann_input_csv, obs_nds)\n",
    "\n",
    "# Get list of downstream nodes\n",
    "ds_nds = []\n",
    "for nd in g:\n",
    "    # If no downstream nodes\n",
    "    if g.out_degree(nd) == 0:\n",
    "        # Node is of interest\n",
    "        ds_nds.append(nd)\n",
    "\n",
    "# Get just the downstream catchments\n",
    "stn_df = stn_df[stn_df[\"nve_vassdrag_nr\"].isin(ds_nds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2. Sum model results for monitored locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read model output\n",
    "teo_df = pd.read_csv(res_csv)\n",
    "\n",
    "# Join accumulated outputs to stns of interest\n",
    "mon_df = pd.merge(\n",
    "    stn_df, teo_df, how=\"left\", left_on=\"nve_vassdrag_nr\", right_on=\"regine\"\n",
    ")\n",
    "\n",
    "# Groupby OSPAR region\n",
    "mon_df = mon_df.groupby(\"ospar_region\").sum()\n",
    "\n",
    "# Get just accum cols\n",
    "cols = [i for i in mon_df.columns if i.split(\"_\")[0] == \"accum\"]\n",
    "mon_df = mon_df[cols]\n",
    "\n",
    "mon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table gives the **modelled** inputs to each OSPAR region from catchments for which we have observed data. We want to subtract these values from the overall modelled inputs to each region and substitute the observed data instead.\n",
    "\n",
    "The trickiest part of this is that the OSPAR regions in the TEOTIL catchment network (files named `regine_{year}.csv`) don't exactly match the relevant OSPAR definitions for this analysis. This is because the \"OSPAR boundaries\" in the model include catchments draining to Sweden (as part of TEOTIL2 Metals - see [here](https://nivanorge.github.io/teotil2/pages/07_1000_lakes.html)), so instead of using them directly we need to aggregate based on vassdragsnummers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3. Group model output according to \"new\" OSPAR regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \"new\" OSPAR regions (ranges are inclusive)\n",
    "os_dict = {\n",
    "    \"SKAGERAK\": (1, 23),\n",
    "    \"NORTH SEA\": (24, 90),\n",
    "    \"NORWEGIAN SEA2\": (91, 170),\n",
    "    \"LOFOTEN-BARENTS SEA\": (171, 247),\n",
    "}\n",
    "\n",
    "# Container for results\n",
    "df_list = []\n",
    "\n",
    "# Loop over model output\n",
    "for reg in os_dict.keys():\n",
    "    min_id, max_id = os_dict[reg]\n",
    "\n",
    "    regs = [\"%03d.\" % i for i in range(min_id, max_id + 1)]\n",
    "\n",
    "    # Get data for this region\n",
    "    df2 = teo_df[teo_df[\"regine\"].isin(regs)]\n",
    "\n",
    "    # Get just accum cols\n",
    "    cols = [i for i in df2.columns if i.split(\"_\")[0] == \"accum\"]\n",
    "    df2 = df2[cols]\n",
    "\n",
    "    # Add region\n",
    "    df2[\"ospar_region\"] = reg\n",
    "\n",
    "    # Add to output\n",
    "    df_list.append(df2)\n",
    "\n",
    "# Build df\n",
    "os_df = pd.concat(df_list, axis=0)\n",
    "\n",
    "# Aggregate\n",
    "os_df = os_df.groupby(\"ospar_region\").sum()\n",
    "\n",
    "os_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate the unmonitored component by simply subtracting the values modelled upstream of monitoring stations from the overall modelled inputs to each OSPAR region.\n",
    "\n",
    "#### 4.1.4. Estimate loads in unmonitored areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc unmonitored loads\n",
    "unmon_df = os_df - mon_df\n",
    "\n",
    "# Write output\n",
    "out_csv = f\"../../../Results/Unmon_loads/teotil2_raw_unmonitored_loads_{year}.csv\"\n",
    "unmon_df.to_csv(out_csv, encoding=\"utf-8\", index_label=\"ospar_region\")\n",
    "\n",
    "unmon_df.round(0).astype(int).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.5. Aggregate values to required quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to match report\n",
    "unmon_df[\"flow\"] = unmon_df[\"accum_q_m3/s\"] * 60 * 60 * 24 / 1000.0  # 1000s m3/day\n",
    "\n",
    "unmon_df[\"sew_n\"] = (\n",
    "    unmon_df[\"accum_ren_tot-n_tonnes\"] + unmon_df[\"accum_spr_tot-n_tonnes\"]\n",
    ")\n",
    "unmon_df[\"sew_p\"] = (\n",
    "    unmon_df[\"accum_ren_tot-p_tonnes\"] + unmon_df[\"accum_spr_tot-p_tonnes\"]\n",
    ")\n",
    "\n",
    "unmon_df[\"ind_n\"] = unmon_df[\"accum_ind_tot-n_tonnes\"]\n",
    "unmon_df[\"ind_p\"] = unmon_df[\"accum_ind_tot-p_tonnes\"]\n",
    "\n",
    "unmon_df[\"fish_n\"] = unmon_df[\"accum_aqu_tot-n_tonnes\"]\n",
    "unmon_df[\"fish_p\"] = unmon_df[\"accum_aqu_tot-p_tonnes\"]\n",
    "\n",
    "unmon_df[\"diff_n\"] = (\n",
    "    unmon_df[\"accum_anth_diff_tot-n_tonnes\"] + unmon_df[\"accum_nat_diff_tot-n_tonnes\"]\n",
    ")\n",
    "unmon_df[\"diff_p\"] = (\n",
    "    unmon_df[\"accum_anth_diff_tot-p_tonnes\"] + unmon_df[\"accum_nat_diff_tot-p_tonnes\"]\n",
    ")\n",
    "\n",
    "new_df = unmon_df[\n",
    "    [\"flow\", \"sew_n\", \"sew_p\", \"ind_n\", \"ind_p\", \"fish_n\", \"fish_p\", \"diff_n\", \"diff_p\"]\n",
    "]\n",
    "\n",
    "# Total for Norway\n",
    "new_df.loc[\"NORWAY\"] = new_df.sum(axis=0)\n",
    "\n",
    "# Reorder rows\n",
    "new_df = new_df.reindex(\n",
    "    [\"NORWAY\", \"LOFOTEN-BARENTS SEA\", \"NORTH SEA\", \"NORWEGIAN SEA2\", \"SKAGERAK\"]\n",
    ")\n",
    "\n",
    "new_df.round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Other N and P species\n",
    "\n",
    "Tore's procedure `RESA2.FIXTEOTILPN` defines simple correction factors for estimating PO4, NO3 and NH4 from total P and N. The table below lists the factors used.\n",
    "\n",
    "|   Source    | Phosphate | Nitrate | Ammonium |\n",
    "|:-----------:|:---------:|:-------:|:--------:|\n",
    "|    Sewage   |     0.600 |   0.050 |    0.750 |\n",
    "|   Industry  |     0.600 |   0.050 |    0.750 |\n",
    "| Aquaculture |     0.690 |   0.110 |    0.800 |\n",
    "|   Diffuse   |     0.246 |   0.625 |    0.055 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of conversion factors\n",
    "con_dict = {\n",
    "    (\"sew\", \"po4\"): (\"p\", 0.6),\n",
    "    (\"ind\", \"po4\"): (\"p\", 0.6),\n",
    "    (\"fish\", \"po4\"): (\"p\", 0.69),\n",
    "    (\"diff\", \"po4\"): (\"p\", 0.246),\n",
    "    (\"sew\", \"no3\"): (\"n\", 0.05),\n",
    "    (\"ind\", \"no3\"): (\"n\", 0.05),\n",
    "    (\"fish\", \"no3\"): (\"n\", 0.11),\n",
    "    (\"diff\", \"no3\"): (\"n\", 0.625),\n",
    "    (\"sew\", \"nh4\"): (\"n\", 0.75),\n",
    "    (\"ind\", \"nh4\"): (\"n\", 0.75),\n",
    "    (\"fish\", \"nh4\"): (\"n\", 0.8),\n",
    "    (\"diff\", \"nh4\"): (\"n\", 0.055),\n",
    "}\n",
    "\n",
    "# Apply factors\n",
    "for src in [\"sew\", \"ind\", \"fish\", \"diff\"]:\n",
    "    for spc in [\"po4\", \"no3\", \"nh4\"]:\n",
    "        el, fac = con_dict[(src, spc)]\n",
    "        new_df[src + \"_\" + spc] = fac * new_df[src + \"_\" + el]\n",
    "\n",
    "new_df.round().astype(int).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Other quantities\n",
    "\n",
    "The model currently only considers N and P, but the project focuses on a wider range of parameters. For now, we simply assume that all measured inputs (`renseanlegg`, `industri` and `akvakultur`) for regines outside of catchments with measured data make it to the sea.\n",
    "\n",
    "We only want data for catchments that are not monitored i.e. for regine IDs **not** in the graph created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "\n",
    "# The sql below uses a horrible (and slow!) hack to get around Oracle's\n",
    "# 1000 item limit on IN clauses. See here for details:\n",
    "# https://stackoverflow.com/a/9084247/505698\n",
    "nd_list_hack = [(1, i) for i in nd_list]\n",
    "\n",
    "sql = (\n",
    "    \"SELECT SUBSTR(a.regine, 1, 3) AS vassdrag, \"\n",
    "    \"  a.type, \"\n",
    "    \"  b.name, \"\n",
    "    \"  b.unit, \"\n",
    "    \"  SUM(c.value * d.factor) as value \"\n",
    "    \"FROM RESA2.RID_PUNKTKILDER a, \"\n",
    "    \"RESA2.RID_PUNKTKILDER_OUTPAR_DEF b, \"\n",
    "    \"RESA2.RID_PUNKTKILDER_INPAR_VALUES c, \"\n",
    "    \"RESA2.RID_PUNKTKILDER_INP_OUTP d \"\n",
    "    \"WHERE a.anlegg_nr = c.anlegg_nr \"\n",
    "    \"AND (1, a.regine) NOT IN %s \"\n",
    "    \"AND d.in_pid = c.inp_par_id \"\n",
    "    \"AND d.out_pid = b.out_pid \"\n",
    "    \"AND c.year = %s \"\n",
    "    \"GROUP BY SUBSTR(a.regine, 1, 3), a.type, b.name, b.unit \"\n",
    "    \"ORDER BY SUBSTR(a.regine, 1, 3), a.type\" % (tuple(nd_list_hack), year)\n",
    ")\n",
    "\n",
    "df = pd.read_sql(sql, engine)\n",
    "\n",
    "# Tidy\n",
    "df[\"par\"] = df[\"type\"] + \"_\" + df[\"name\"] + \"_\" + df[\"unit\"]\n",
    "del df[\"name\"], df[\"unit\"], df[\"type\"]\n",
    "\n",
    "# Pivot\n",
    "df = df.pivot(index=\"vassdrag\", columns=\"par\", values=\"value\")\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    try:\n",
    "        a = int(x)\n",
    "        return a\n",
    "    except:\n",
    "        return -999\n",
    "\n",
    "\n",
    "# Convert vassdrag to numbers\n",
    "df[\"vass\"] = df[\"vassdrag\"].apply(f)\n",
    "\n",
    "# Get just the main catchments\n",
    "df = df.query(\"vass != -999\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    if x in range(1, 24):\n",
    "        return \"SKAGERAK\"\n",
    "    elif x in range(24, 91):\n",
    "        return \"NORTH SEA\"\n",
    "    elif x in range(91, 171):\n",
    "        return \"NORWEGIAN SEA2\"\n",
    "    elif x in range(171, 248):\n",
    "        return \"LOFOTEN-BARENTS SEA\"\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "# Assign main catchments to OSPAR regions\n",
    "df[\"osp_reg\"] = df[\"vass\"].apply(f2)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by OSPAR region\n",
    "df.fillna(0, inplace=True)\n",
    "df = df.groupby(\"osp_reg\").sum()\n",
    "if 0 in df.index:\n",
    "    df.drop(0, inplace=True)\n",
    "\n",
    "# Total for Norway\n",
    "df.loc[\"NORWAY\"] = df.sum(axis=0)\n",
    "\n",
    "# Join to model results\n",
    "df = new_df.join(df)\n",
    "\n",
    "# Get cols of interest\n",
    "umod_cols = [\"S.P.M.\", \"TOC\", \"As\", \"Pb\", \"Cd\", \"Cu\", \"Zn\", \"Ni\", \"Cr\", \"Hg\"]\n",
    "umod_cols = [\n",
    "    \"%s_%s_tonn\" % (i, j) for i in [\"INDUSTRI\", \"RENSEANLEGG\"] for j in umod_cols\n",
    "]\n",
    "cols = list(new_df.columns) + umod_cols\n",
    "cols.remove(\"RENSEANLEGG_TOC_tonn\")\n",
    "cols = [i for i in cols if i in df.columns]\n",
    "df = df[cols]\n",
    "\n",
    "df.round(0).astype(int).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fish farm copper\n",
    "\n",
    "Finally, we need to add in the Cu totals from fish farms. The method is similar to that used above, but simpler because we're only interested in one parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = rid.connect_to_nivabase(user=user, pw=pw)\n",
    "\n",
    "# The sql below uses a horrible (and slow!) hack to get around Oracle's\n",
    "# 1000 item limit on IN clauses. See here for details:\n",
    "# https://stackoverflow.com/a/9084247/505698\n",
    "nd_list_hack = [(1, i) for i in nd_list]\n",
    "\n",
    "sql = (\n",
    "    \"SELECT SUBSTR(regine, 1, 3) AS vassdrag, \"\n",
    "    \"  SUM(value) AS value FROM ( \"\n",
    "    \"    SELECT b.regine, \"\n",
    "    \"           c.name, \"\n",
    "    \"           (a.value*d.factor) AS value \"\n",
    "    \"    FROM resa2.rid_kilder_aqkult_values a, \"\n",
    "    \"    resa2.rid_kilder_aquakultur b, \"\n",
    "    \"    resa2.rid_punktkilder_outpar_def c, \"\n",
    "    \"    resa2.rid_punktkilder_inp_outp d \"\n",
    "    \"    WHERE a.anlegg_nr = b.nr \"\n",
    "    \"    AND (1, b.regine) NOT IN %s \"\n",
    "    \"    AND a.inp_par_id = d.in_pid \"\n",
    "    \"    AND c.out_pid = d.out_pid \"\n",
    "    \"    AND name = 'Cu' \"\n",
    "    \"    AND ar = %s) \"\n",
    "    \"GROUP BY SUBSTR(regine, 1, 3)\" % (tuple(nd_list_hack), year)\n",
    ")\n",
    "\n",
    "aq_df = pd.read_sql(sql, engine)\n",
    "\n",
    "if len(aq_df) > 0:\n",
    "    # Get vassdrag\n",
    "    aq_df[\"vass\"] = aq_df[\"vassdrag\"].apply(f)\n",
    "    aq_df = aq_df.query(\"vass != -999\")\n",
    "\n",
    "    # Calc OSPAR region and group\n",
    "    aq_df[\"osp_reg\"] = aq_df[\"vass\"].apply(f2)\n",
    "    aq_df.fillna(0, inplace=True)\n",
    "    aq_df = aq_df.groupby(\"osp_reg\").sum()\n",
    "    del aq_df[\"vass\"]\n",
    "\n",
    "    # Total for Norway\n",
    "    aq_df.loc[\"NORWAY\"] = aq_df.sum(axis=0)\n",
    "\n",
    "    # Rename\n",
    "    aq_df.columns = [\n",
    "        \"AQUAKULTUR_Cu_tonn\",\n",
    "    ]\n",
    "\n",
    "    # Join model results\n",
    "    df = df.join(aq_df)\n",
    "\n",
    "    df.round(0).astype(int).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write output\n",
    "out_csv = f\"../../../Results/Unmon_loads/teotil2_ospar_unmonitored_loads_{year}.csv\"\n",
    "df.to_csv(out_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data can then be used to create Table 3 in the report - see [this notebook](https://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/summary_table_2017.ipynb) for details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
