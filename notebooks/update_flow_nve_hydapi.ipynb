{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41a8a553-0c0d-4fa4-85d0-bbe9cec0bb19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "import configparser\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nivapy3 as nivapy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sqlalchemy import text\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# Get API key for HydAPI\n",
    "api_key = nivapy.da.authenticate_nve_hydapi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44cb4b69-cb5f-4989-be6f-28ebe0c9d30b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Username:  ········\n",
      "Password:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "# Connect to db\n",
    "eng = nivapy.da.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd0c15-9b36-4049-a528-3afd571cd2a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Update RID flow datasets\n",
    "\n",
    "Each year, updated flow datasets (both modelled and observed) are obtained from NVE and added to RESA2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9890dcba-5d98-4111-b153-97c315529e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Year of interest\n",
    "year = 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14637092-2461-402f-bddd-74e8b97e64ad",
   "metadata": {},
   "source": [
    "## 1. Observed discharge\n",
    "\n",
    "Observed time series are used **only** for the 11 main rivers - all other calculations are based on modelled flows (from HBV). This notebook uses NVE's HydAPI to download data for the relevant stations where possible. Other datasets must be obtained directly from NVE (e-mail Trine Fjeldstad). Note that more than 11 discharge stations are involved, because at some chemistry sampling locations the flow is the sum of several NVE discharge series. Note also the following:\n",
    "\n",
    " * Chemistry station 29613 should ideally use the sum of NVE series 16.133 and 16.153, but the latter is no longer available. We simply assume the input from 16.153 is constant at 10 $m^3/s$ (which is roughly equal to the long-term average) <br><br>\n",
    " \n",
    " * The discharge for chemistry station 29614 is **either** NVE station 21.71 **or** 21.11. 21.11 is usually available first, but can check 21.71 too <br><br> \n",
    " \n",
    " * Discharge data for chemistry stations 29617 (NVE ID 2.605) and 36225 (NVE ID 6.78) are often delayed. Need to contact Trine at NVE early to avoid problems later.\n",
    " \n",
    "**Added 07.09.2023:** The observed data for Alna come from Oslo VAV and are often delayed. Given MDir's new reporting deadline, we have decided to switch to using modelled data from NVE for this site instead. This simply involves changing the default discharge station in RESA for site 36225 from `dis_station_id` 626 (which is the Oslo VAV dataset) to 283 (which is the NVE modellled dataset). See the notebook `compare_alna_discharge.ipynb` and the e-mail from Øyvind received 07.09.2023 for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121b6584-bcdf-40cd-a69a-605745e380e0",
   "metadata": {},
   "source": [
    "### 1.1. Discharge stations\n",
    "\n",
    "The discharge stations associated with 10 of the 11 main water chemistry sampling locations are shown in the dataframe below. Alna now uses modelled data (see above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec357de-b50d-44e5-bb6a-bd99c2a1900c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_code</th>\n",
       "      <th>nve_id</th>\n",
       "      <th>dis_station_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29612</td>\n",
       "      <td>BUSEDRA</td>\n",
       "      <td>12.285.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29613</td>\n",
       "      <td>TELESKI</td>\n",
       "      <td>16.133.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Actually (16.153 + 16.133), but 16.153 no longer monitored. Assume constant at 10 m3/s and add to 16.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29614</td>\n",
       "      <td>VAGEOTR</td>\n",
       "      <td>21.11.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29615</td>\n",
       "      <td>VESENUM</td>\n",
       "      <td>15.61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29617</td>\n",
       "      <td>ØSTEGLO</td>\n",
       "      <td>2.605.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29778</td>\n",
       "      <td>STREORK</td>\n",
       "      <td>121.22.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29779</td>\n",
       "      <td>FINEALT</td>\n",
       "      <td>212.11.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29782</td>\n",
       "      <td>NOREVEF</td>\n",
       "      <td>151.28.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>Used to be 151.5.0, but this is not available via API. 151.28.0 seems identical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29783</td>\n",
       "      <td>ROGEORR</td>\n",
       "      <td>28.7.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29821</td>\n",
       "      <td>HOREVOS</td>\n",
       "      <td>62.5.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id station_code    nve_id  dis_station_id  \\\n",
       "0       29612      BUSEDRA  12.285.0            57.0   \n",
       "1       29613      TELESKI  16.133.0            59.0   \n",
       "2       29614      VAGEOTR   21.11.0           487.0   \n",
       "3       29615      VESENUM   15.61.0            58.0   \n",
       "4       29617      ØSTEGLO   2.605.0            56.0   \n",
       "5       29778      STREORK  121.22.0           348.0   \n",
       "6       29779      FINEALT  212.11.0           386.0   \n",
       "7       29782      NOREVEF  151.28.0           351.0   \n",
       "8       29783      ROGEORR    28.7.0           355.0   \n",
       "9       29821      HOREVOS    62.5.0           546.0   \n",
       "\n",
       "                                                                                                    comment  \n",
       "0                                                                                                       NaN  \n",
       "1  Actually (16.153 + 16.133), but 16.153 no longer monitored. Assume constant at 10 m3/s and add to 16.133  \n",
       "2                                                                                                       NaN  \n",
       "3                                                                                                       NaN  \n",
       "4                                                                                                       NaN  \n",
       "5                                                                                                       NaN  \n",
       "6                                                                                                       NaN  \n",
       "7                           Used to be 151.5.0, but this is not available via API. 151.28.0 seems identical  \n",
       "8                                                                                                       NaN  \n",
       "9                                                                                                       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xl_path = r\"../data/rid_resa_nve_discharge_stations.xlsx\"\n",
    "resa_nve_df = pd.read_excel(xl_path, sheet_name=\"observed_stns\")\n",
    "resa_nve_df.dropna(subset=\"nve_id\", inplace=True)\n",
    "\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(resa_nve_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab4d16-5032-487e-aedd-f4b515fd6b5c",
   "metadata": {},
   "source": [
    "### 1.2. Data from HydAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43b5fe6-ee15-4b4f-b10d-8a36d40ecf25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 out of 10 stations found in HydAPI:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>utmEast_Z33</th>\n",
       "      <th>utmNorth_Z33</th>\n",
       "      <th>masl</th>\n",
       "      <th>riverName</th>\n",
       "      <th>councilNumber</th>\n",
       "      <th>councilName</th>\n",
       "      <th>...</th>\n",
       "      <th>culQ5</th>\n",
       "      <th>culQ10</th>\n",
       "      <th>culQ20</th>\n",
       "      <th>culQ50</th>\n",
       "      <th>culHm</th>\n",
       "      <th>culH5</th>\n",
       "      <th>culH10</th>\n",
       "      <th>culH20</th>\n",
       "      <th>culH50</th>\n",
       "      <th>seriesList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>12.285.0</td>\n",
       "      <td>Døvikfoss</td>\n",
       "      <td>59.88624</td>\n",
       "      <td>9.90977</td>\n",
       "      <td>215291</td>\n",
       "      <td>6649693</td>\n",
       "      <td>19</td>\n",
       "      <td>Drammensvassdraget</td>\n",
       "      <td>3316</td>\n",
       "      <td>Modum</td>\n",
       "      <td>...</td>\n",
       "      <td>1310.0000</td>\n",
       "      <td>1510.0000</td>\n",
       "      <td>1670.0000</td>\n",
       "      <td>2030.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'parameterName': 'Vannføring', 'parameter': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>121.22.0</td>\n",
       "      <td>Syrstad</td>\n",
       "      <td>63.03225</td>\n",
       "      <td>9.72771</td>\n",
       "      <td>233461</td>\n",
       "      <td>7000123</td>\n",
       "      <td>147</td>\n",
       "      <td>Orkla</td>\n",
       "      <td>5059</td>\n",
       "      <td>Orkland</td>\n",
       "      <td>...</td>\n",
       "      <td>448.0000</td>\n",
       "      <td>520.0000</td>\n",
       "      <td>788.0000</td>\n",
       "      <td>1043.0000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>2.8700</td>\n",
       "      <td>3.1600</td>\n",
       "      <td>4.1400</td>\n",
       "      <td>4.9500</td>\n",
       "      <td>[{'parameterName': 'Vannstand', 'parameter': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15.61.0</td>\n",
       "      <td>Holmfoss i Numedalslågen</td>\n",
       "      <td>59.18906</td>\n",
       "      <td>9.99414</td>\n",
       "      <td>214153</td>\n",
       "      <td>6571840</td>\n",
       "      <td>20</td>\n",
       "      <td>Numedalslågen</td>\n",
       "      <td>3909</td>\n",
       "      <td>Larvik</td>\n",
       "      <td>...</td>\n",
       "      <td>557.7559</td>\n",
       "      <td>666.5267</td>\n",
       "      <td>784.6265</td>\n",
       "      <td>960.4094</td>\n",
       "      <td>4.9316</td>\n",
       "      <td>5.3693</td>\n",
       "      <td>5.7934</td>\n",
       "      <td>6.2009</td>\n",
       "      <td>6.7331</td>\n",
       "      <td>[{'parameterName': 'Vannstand', 'parameter': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>151.28.0</td>\n",
       "      <td>Laksfors</td>\n",
       "      <td>65.62155</td>\n",
       "      <td>13.29156</td>\n",
       "      <td>421320</td>\n",
       "      <td>7278797</td>\n",
       "      <td>40</td>\n",
       "      <td>Vefsna</td>\n",
       "      <td>1825</td>\n",
       "      <td>Grane</td>\n",
       "      <td>...</td>\n",
       "      <td>1266.0000</td>\n",
       "      <td>1427.0000</td>\n",
       "      <td>1580.0000</td>\n",
       "      <td>1779.0000</td>\n",
       "      <td>4.7400</td>\n",
       "      <td>5.1500</td>\n",
       "      <td>5.4300</td>\n",
       "      <td>5.6900</td>\n",
       "      <td>5.9900</td>\n",
       "      <td>[{'parameterName': 'Vannstand', 'parameter': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>16.133.0</td>\n",
       "      <td>Skotfoss</td>\n",
       "      <td>59.20771</td>\n",
       "      <td>9.52788</td>\n",
       "      <td>187736</td>\n",
       "      <td>6576005</td>\n",
       "      <td>16</td>\n",
       "      <td>Skiensvassdraget</td>\n",
       "      <td>4003</td>\n",
       "      <td>Skien</td>\n",
       "      <td>...</td>\n",
       "      <td>920.0000</td>\n",
       "      <td>1070.0000</td>\n",
       "      <td>1210.0000</td>\n",
       "      <td>1400.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'parameterName': 'Vannføring', 'parameter': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>2.605.0</td>\n",
       "      <td>Solbergfoss</td>\n",
       "      <td>59.63733</td>\n",
       "      <td>11.15354</td>\n",
       "      <td>283189</td>\n",
       "      <td>6617306</td>\n",
       "      <td>98</td>\n",
       "      <td>Glommavassdraget</td>\n",
       "      <td>3118</td>\n",
       "      <td>Indre Østfold</td>\n",
       "      <td>...</td>\n",
       "      <td>2677.0000</td>\n",
       "      <td>3046.0000</td>\n",
       "      <td>3217.0000</td>\n",
       "      <td>3492.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'parameterName': 'Vannføring', 'parameter': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>21.11.0</td>\n",
       "      <td>Heisel</td>\n",
       "      <td>58.24755</td>\n",
       "      <td>7.95144</td>\n",
       "      <td>86711</td>\n",
       "      <td>6477930</td>\n",
       "      <td>19</td>\n",
       "      <td>Otra</td>\n",
       "      <td>4223</td>\n",
       "      <td>Vennesla</td>\n",
       "      <td>...</td>\n",
       "      <td>731.0178</td>\n",
       "      <td>871.0733</td>\n",
       "      <td>1004.6568</td>\n",
       "      <td>1176.4673</td>\n",
       "      <td>4.9153</td>\n",
       "      <td>5.6985</td>\n",
       "      <td>6.2775</td>\n",
       "      <td>6.7984</td>\n",
       "      <td>7.4321</td>\n",
       "      <td>[{'parameterName': 'Vannstand', 'parameter': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>212.11.0</td>\n",
       "      <td>Kista</td>\n",
       "      <td>69.82630</td>\n",
       "      <td>23.51681</td>\n",
       "      <td>826880</td>\n",
       "      <td>7769359</td>\n",
       "      <td>62</td>\n",
       "      <td>Altavassdraget</td>\n",
       "      <td>5601</td>\n",
       "      <td>Alta</td>\n",
       "      <td>...</td>\n",
       "      <td>888.8162</td>\n",
       "      <td>1014.6972</td>\n",
       "      <td>1119.2831</td>\n",
       "      <td>1234.5527</td>\n",
       "      <td>3.5130</td>\n",
       "      <td>4.0487</td>\n",
       "      <td>4.3299</td>\n",
       "      <td>4.5492</td>\n",
       "      <td>4.7781</td>\n",
       "      <td>[{'parameterName': 'Vannstand', 'parameter': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>28.7.0</td>\n",
       "      <td>Haugland</td>\n",
       "      <td>58.69291</td>\n",
       "      <td>5.64757</td>\n",
       "      <td>-40981</td>\n",
       "      <td>6543711</td>\n",
       "      <td>19</td>\n",
       "      <td>Hååna</td>\n",
       "      <td>1121</td>\n",
       "      <td>Time</td>\n",
       "      <td>...</td>\n",
       "      <td>88.1993</td>\n",
       "      <td>101.5965</td>\n",
       "      <td>114.6455</td>\n",
       "      <td>131.8289</td>\n",
       "      <td>1.7366</td>\n",
       "      <td>1.8855</td>\n",
       "      <td>1.9995</td>\n",
       "      <td>2.1025</td>\n",
       "      <td>2.2285</td>\n",
       "      <td>[{'parameterName': 'Vannstand', 'parameter': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>62.5.0</td>\n",
       "      <td>Bulken (Vangsvatnet)</td>\n",
       "      <td>60.62868</td>\n",
       "      <td>6.29254</td>\n",
       "      <td>24518</td>\n",
       "      <td>6753006</td>\n",
       "      <td>51</td>\n",
       "      <td>Vossovassdraget</td>\n",
       "      <td>4621</td>\n",
       "      <td>Voss</td>\n",
       "      <td>...</td>\n",
       "      <td>470.0000</td>\n",
       "      <td>530.0000</td>\n",
       "      <td>580.0000</td>\n",
       "      <td>660.0000</td>\n",
       "      <td>3.6800</td>\n",
       "      <td>4.2700</td>\n",
       "      <td>4.7700</td>\n",
       "      <td>5.1800</td>\n",
       "      <td>5.8300</td>\n",
       "      <td>[{'parameterName': 'Vannstand', 'parameter': 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     station_id              station_name  latitude  longitude  utmEast_Z33  \\\n",
       "147    12.285.0                 Døvikfoss  59.88624    9.90977       215291   \n",
       "240    121.22.0                   Syrstad  63.03225    9.72771       233461   \n",
       "399     15.61.0  Holmfoss i Numedalslågen  59.18906    9.99414       214153   \n",
       "409    151.28.0                  Laksfors  65.62155   13.29156       421320   \n",
       "480    16.133.0                  Skotfoss  59.20771    9.52788       187736   \n",
       "912     2.605.0               Solbergfoss  59.63733   11.15354       283189   \n",
       "1026    21.11.0                    Heisel  58.24755    7.95144        86711   \n",
       "1068   212.11.0                     Kista  69.82630   23.51681       826880   \n",
       "1237     28.7.0                  Haugland  58.69291    5.64757       -40981   \n",
       "1490     62.5.0      Bulken (Vangsvatnet)  60.62868    6.29254        24518   \n",
       "\n",
       "      utmNorth_Z33  masl           riverName councilNumber    councilName  \\\n",
       "147        6649693    19  Drammensvassdraget          3316          Modum   \n",
       "240        7000123   147               Orkla          5059        Orkland   \n",
       "399        6571840    20       Numedalslågen          3909         Larvik   \n",
       "409        7278797    40              Vefsna          1825          Grane   \n",
       "480        6576005    16    Skiensvassdraget          4003          Skien   \n",
       "912        6617306    98    Glommavassdraget          3118  Indre Østfold   \n",
       "1026       6477930    19                Otra          4223       Vennesla   \n",
       "1068       7769359    62      Altavassdraget          5601           Alta   \n",
       "1237       6543711    19               Hååna          1121           Time   \n",
       "1490       6753006    51     Vossovassdraget          4621           Voss   \n",
       "\n",
       "      ...      culQ5     culQ10     culQ20     culQ50   culHm   culH5  culH10  \\\n",
       "147   ...  1310.0000  1510.0000  1670.0000  2030.0000     NaN     NaN     NaN   \n",
       "240   ...   448.0000   520.0000   788.0000  1043.0000  2.4200  2.8700  3.1600   \n",
       "399   ...   557.7559   666.5267   784.6265   960.4094  4.9316  5.3693  5.7934   \n",
       "409   ...  1266.0000  1427.0000  1580.0000  1779.0000  4.7400  5.1500  5.4300   \n",
       "480   ...   920.0000  1070.0000  1210.0000  1400.0000     NaN     NaN     NaN   \n",
       "912   ...  2677.0000  3046.0000  3217.0000  3492.0000     NaN     NaN     NaN   \n",
       "1026  ...   731.0178   871.0733  1004.6568  1176.4673  4.9153  5.6985  6.2775   \n",
       "1068  ...   888.8162  1014.6972  1119.2831  1234.5527  3.5130  4.0487  4.3299   \n",
       "1237  ...    88.1993   101.5965   114.6455   131.8289  1.7366  1.8855  1.9995   \n",
       "1490  ...   470.0000   530.0000   580.0000   660.0000  3.6800  4.2700  4.7700   \n",
       "\n",
       "      culH20  culH50                                         seriesList  \n",
       "147      NaN     NaN  [{'parameterName': 'Vannføring', 'parameter': ...  \n",
       "240   4.1400  4.9500  [{'parameterName': 'Vannstand', 'parameter': 1...  \n",
       "399   6.2009  6.7331  [{'parameterName': 'Vannstand', 'parameter': 1...  \n",
       "409   5.6900  5.9900  [{'parameterName': 'Vannstand', 'parameter': 1...  \n",
       "480      NaN     NaN  [{'parameterName': 'Vannføring', 'parameter': ...  \n",
       "912      NaN     NaN  [{'parameterName': 'Vannføring', 'parameter': ...  \n",
       "1026  6.7984  7.4321  [{'parameterName': 'Vannstand', 'parameter': 1...  \n",
       "1068  4.5492  4.7781  [{'parameterName': 'Vannstand', 'parameter': 1...  \n",
       "1237  2.1025  2.2285  [{'parameterName': 'Vannstand', 'parameter': 1...  \n",
       "1490  5.1800  5.8300  [{'parameterName': 'Vannstand', 'parameter': 1...  \n",
       "\n",
       "[10 rows x 98 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stations from HydAPI\n",
    "nve_stn_df = nivapy.da.get_nve_hydapi_stations(api_key=api_key)\n",
    "nve_stn_ids = resa_nve_df[\"nve_id\"].values\n",
    "nve_stn_df = nve_stn_df.query(\"station_id in @nve_stn_ids\")\n",
    "print(f\"{len(nve_stn_df)} out of {len(resa_nve_df)} stations found in HydAPI:\")\n",
    "nve_stn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acf0daa3-e3f6-4ab4-bb59-28b68ad22f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>parameter</th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>parameter_name_eng</th>\n",
       "      <th>method</th>\n",
       "      <th>datetime</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>correction</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.5.0</td>\n",
       "      <td>Bulken (Vangsvatnet)</td>\n",
       "      <td>1001</td>\n",
       "      <td>Vannføring</td>\n",
       "      <td>Discharge</td>\n",
       "      <td>Mean</td>\n",
       "      <td>2023-01-01 11:00:00+00:00</td>\n",
       "      <td>29.92872</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.5.0</td>\n",
       "      <td>Bulken (Vangsvatnet)</td>\n",
       "      <td>1001</td>\n",
       "      <td>Vannføring</td>\n",
       "      <td>Discharge</td>\n",
       "      <td>Mean</td>\n",
       "      <td>2023-01-02 11:00:00+00:00</td>\n",
       "      <td>22.99685</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.5.0</td>\n",
       "      <td>Bulken (Vangsvatnet)</td>\n",
       "      <td>1001</td>\n",
       "      <td>Vannføring</td>\n",
       "      <td>Discharge</td>\n",
       "      <td>Mean</td>\n",
       "      <td>2023-01-03 11:00:00+00:00</td>\n",
       "      <td>18.07844</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.5.0</td>\n",
       "      <td>Bulken (Vangsvatnet)</td>\n",
       "      <td>1001</td>\n",
       "      <td>Vannføring</td>\n",
       "      <td>Discharge</td>\n",
       "      <td>Mean</td>\n",
       "      <td>2023-01-04 11:00:00+00:00</td>\n",
       "      <td>15.56040</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.5.0</td>\n",
       "      <td>Bulken (Vangsvatnet)</td>\n",
       "      <td>1001</td>\n",
       "      <td>Vannføring</td>\n",
       "      <td>Discharge</td>\n",
       "      <td>Mean</td>\n",
       "      <td>2023-01-05 11:00:00+00:00</td>\n",
       "      <td>13.64277</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_id          station_name parameter parameter_name  \\\n",
       "0     62.5.0  Bulken (Vangsvatnet)      1001     Vannføring   \n",
       "1     62.5.0  Bulken (Vangsvatnet)      1001     Vannføring   \n",
       "2     62.5.0  Bulken (Vangsvatnet)      1001     Vannføring   \n",
       "3     62.5.0  Bulken (Vangsvatnet)      1001     Vannføring   \n",
       "4     62.5.0  Bulken (Vangsvatnet)      1001     Vannføring   \n",
       "\n",
       "  parameter_name_eng method                  datetime     value  unit  \\\n",
       "0          Discharge   Mean 2023-01-01 11:00:00+00:00  29.92872  m³/s   \n",
       "1          Discharge   Mean 2023-01-02 11:00:00+00:00  22.99685  m³/s   \n",
       "2          Discharge   Mean 2023-01-03 11:00:00+00:00  18.07844  m³/s   \n",
       "3          Discharge   Mean 2023-01-04 11:00:00+00:00  15.56040  m³/s   \n",
       "4          Discharge   Mean 2023-01-05 11:00:00+00:00  13.64277  m³/s   \n",
       "\n",
       "   correction  quality  \n",
       "0           0        3  \n",
       "1           0        3  \n",
       "2           0        3  \n",
       "3           0        3  \n",
       "4           0        3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get discharge\n",
    "par_ids = [1001]\n",
    "st_dt = f\"{year}-01-01\"\n",
    "end_dt = f\"{year + 1}-01-01\"\n",
    "q_df = nivapy.da.query_nve_hydapi(\n",
    "    nve_stn_ids, par_ids, st_dt, end_dt, resolution=1440, api_key=api_key\n",
    ")\n",
    "q_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70714d4d-922b-4fdc-940e-8088ead30e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following series have not completed quality control (i.e. 'quality' < 3;\n",
      "see https://hydapi.nve.no/UserDocumentation/ for details):\n",
      "\n",
      "     station_id station_name\n",
      "730     2.605.0  Solbergfoss\n",
      "2555   16.133.0     Skotfoss\n",
      "3285    21.11.0       Heisel\n",
      "\n",
      "The following series have quality control level 2:\n",
      "\n",
      "     station_id station_name\n",
      "730     2.605.0  Solbergfoss\n",
      "2555   16.133.0     Skotfoss\n",
      "3285    21.11.0       Heisel\n",
      "\n",
      "Data with quality control values < 2 will be dropped.\n"
     ]
    }
   ],
   "source": [
    "# Check number of records as expected\n",
    "days = 366 if calendar.isleap(year) else 365\n",
    "assert len(q_df) == len(nve_stn_df) * days, \"Number of records is not as expected.\"\n",
    "\n",
    "# Check quality control level\n",
    "print(\"The following series have not completed quality control (i.e. 'quality' < 3;\")\n",
    "print(\"see https://hydapi.nve.no/UserDocumentation/ for details):\\n\")\n",
    "print(q_df.query(\"quality != 3\")[[\"station_id\", \"station_name\"]].drop_duplicates())\n",
    "\n",
    "print(\"\\nThe following series have quality control level 2:\\n\")\n",
    "print(q_df.query(\"quality == 2\")[[\"station_id\", \"station_name\"]].drop_duplicates())\n",
    "\n",
    "print(\"\\nData with quality control values < 2 will be dropped.\")\n",
    "\n",
    "# Drop quality < 2\n",
    "# Used to be quality == 3, but some sites now only get to 2\n",
    "# see e-mail from Trine Fjeldstad received 27.08.2024\n",
    "q_df = q_df.query(\"quality >= 2\")\n",
    "\n",
    "# Check for NaN\n",
    "if pd.isna(q_df[\"value\"]).sum() > 0:\n",
    "    print(\"\\n\\nThe following records contain NaN values:\\n\")\n",
    "    print(\n",
    "        q_df[pd.isna(q_df[\"value\"])][[\"station_id\", \"station_name\"]].drop_duplicates()\n",
    "    )\n",
    "\n",
    "# Check for negative\n",
    "if (q_df[\"value\"] < 0).sum() > 0:\n",
    "    print(\"\\n\\nThe following records contain values <0:\\n\")\n",
    "    print(q_df[q_df[\"value\"] < 0][[\"station_id\", \"station_name\"]].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb0be4-3788-4f06-bf38-f5f052c1ec4b",
   "metadata": {},
   "source": [
    "Based on the output above we can **make a data request to NVE**, if necessary. Quality >= 2 should be OK (see e-mail from Trine Fjeldstad received 27.08.2024).\n",
    "\n",
    "The cell below uploads the valid HydAPI data to RESA2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6714dec1-a096-4d09-bf92-8ea6d8eaf276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_hydapi_data_for_resa(resa_nve_df, q_df, eng):\n",
    "    \"\"\"Process discharge time series from HydAPI and prepare them for upload to RESA2.\n",
    "\n",
    "    Args\n",
    "        resa_nve_df: Dataframe of RESA stations with NVE IDs\n",
    "        q_df:        Dataframe of discharge data from HydAPI\n",
    "        eng:         Obj. Active database connection object for RESA2\n",
    "\n",
    "    Returns\n",
    "        Dataframe.\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "\n",
    "    # Loop over Hydra II data\n",
    "    for idx, row in resa_nve_df.iterrows():\n",
    "        nve_id = row[\"nve_id\"]\n",
    "        dis_stn_id = row[\"dis_station_id\"]\n",
    "\n",
    "        # Get flow for station\n",
    "        q_stn_df = q_df.query(\"station_id == @nve_id\").copy()\n",
    "\n",
    "        if len(q_stn_df) == 0:\n",
    "            print(f\"No data for NVE ID {nve_id}.\")\n",
    "\n",
    "        else:\n",
    "            assert len(q_stn_df) == days\n",
    "\n",
    "            # Remove HH:MM:SS part from dates\n",
    "            q_stn_df.set_index(\"datetime\", inplace=True)\n",
    "            q_stn_df = q_stn_df.resample(\"D\").mean(numeric_only=True)\n",
    "            q_stn_df.reset_index(inplace=True)\n",
    "            q_stn_df[\"datetime\"] = q_stn_df[\"datetime\"].dt.date\n",
    "\n",
    "            # Linear interpolation and back-filling of NaN\n",
    "            q_stn_df[\"value\"].interpolate(method=\"linear\", inplace=True)\n",
    "            q_stn_df[\"value\"].fillna(method=\"backfill\", inplace=True)\n",
    "\n",
    "            # Add 10 m3/s to 16.133 (RESA2 discharge station ID 59)\n",
    "            if dis_stn_id == 59:\n",
    "                q_stn_df[\"value\"] = q_stn_df[\"value\"] + 10\n",
    "\n",
    "            # Add other required cols and tidy\n",
    "            q_stn_df[\"dis_station_id\"] = dis_stn_id\n",
    "            q_stn_df[\"xcomment\"] = np.nan\n",
    "            q_stn_df[\"xvalue\"] = q_stn_df[\"value\"]\n",
    "            q_stn_df[\"xdate\"] = q_stn_df[\"datetime\"]\n",
    "\n",
    "            # Reorder cols\n",
    "            q_stn_df = q_stn_df[[\"dis_station_id\", \"xdate\", \"xvalue\", \"xcomment\"]]\n",
    "\n",
    "            # Append to output\n",
    "            df_list.append(q_stn_df)\n",
    "\n",
    "            # Check whether data already exist for this year\n",
    "            sql = (\n",
    "                \"SELECT count(*) FROM resa2.discharge_values \"\n",
    "                \"WHERE dis_station_id = %s \"\n",
    "                \"AND EXTRACT(YEAR FROM xdate) = %s \" % (dis_stn_id, year)\n",
    "            )\n",
    "            cnt_df = pd.read_sql(sql, eng)\n",
    "            cnt = cnt_df.iloc[0, 0]\n",
    "            if cnt > 0:\n",
    "                print(\n",
    "                    \"%s data already exist for NVE \"\n",
    "                    \"station %s (RESA2 ID %s).\" % (cnt, nve_id, dis_stn_id)\n",
    "                )\n",
    "\n",
    "    hydapi_q_df = pd.concat(df_list, axis=0)\n",
    "\n",
    "    return hydapi_q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eadf23d-eecb-4620-b54f-ef0dee0e0bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 data already exist for NVE station 12.285.0 (RESA2 ID 57.0).\n",
      "365 data already exist for NVE station 16.133.0 (RESA2 ID 59.0).\n",
      "365 data already exist for NVE station 21.11.0 (RESA2 ID 487.0).\n",
      "365 data already exist for NVE station 15.61.0 (RESA2 ID 58.0).\n",
      "365 data already exist for NVE station 2.605.0 (RESA2 ID 56.0).\n",
      "365 data already exist for NVE station 121.22.0 (RESA2 ID 348.0).\n",
      "365 data already exist for NVE station 212.11.0 (RESA2 ID 386.0).\n",
      "365 data already exist for NVE station 151.28.0 (RESA2 ID 351.0).\n",
      "365 data already exist for NVE station 28.7.0 (RESA2 ID 355.0).\n",
      "365 data already exist for NVE station 62.5.0 (RESA2 ID 546.0).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dis_station_id</th>\n",
       "      <th>xdate</th>\n",
       "      <th>xvalue</th>\n",
       "      <th>xcomment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>221.6792</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.0</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>254.0417</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.0</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>281.3104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.0</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>297.2083</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>289.2708</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dis_station_id       xdate    xvalue  xcomment\n",
       "0            57.0  2023-01-01  221.6792       NaN\n",
       "1            57.0  2023-01-02  254.0417       NaN\n",
       "2            57.0  2023-01-03  281.3104       NaN\n",
       "3            57.0  2023-01-04  297.2083       NaN\n",
       "4            57.0  2023-01-05  289.2708       NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydapi_q_df = process_hydapi_data_for_resa(resa_nve_df, q_df, eng)\n",
    "hydapi_q_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "064bc2ef-9502-4ae9-a032-848855f78f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add new rows to database\n",
    "# hydapi_q_df.to_sql(\n",
    "#     \"discharge_values\", con=eng, schema=\"resa2\", if_exists=\"append\", index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58122aae-cd89-44cd-9df3-24a2a6aef21c",
   "metadata": {},
   "source": [
    "### 1.3. Data from Trine\n",
    "\n",
    "Once all the missing datasets identified above have been obtained from NVE, the following code can be used to add them to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e7655-959d-4925-9577-6cd03bf2435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing data from Trine\n",
    "tri_fold = f\"/home/jovyan/shared/common/elveovervakingsprogrammet/nve_observed/{year}-{year - 1999}\"\n",
    "\n",
    "days = 366 if calendar.isleap(year) else 365\n",
    "\n",
    "# List to store output\n",
    "df_list = []\n",
    "\n",
    "# Get list of files from Trine to process\n",
    "search_path = os.path.join(tri_fold, \"*.csv\")\n",
    "file_list = glob.glob(search_path)\n",
    "\n",
    "# Loop over files from Trine\n",
    "for file_path in file_list:\n",
    "    # Get RESA station ID\n",
    "    nve_id = os.path.split(file_path)[1].split(\"_\")[0] + \".0\"\n",
    "    dis_stn_id = resa_nve_df.query(\"nve_id == @nve_id\")[\"dis_station_id\"].iloc[0]\n",
    "\n",
    "    # Parse file\n",
    "    q_stn_df = pd.read_csv(\n",
    "        file_path,\n",
    "        skiprows=1,\n",
    "        index_col=0,\n",
    "        parse_dates=True,\n",
    "        header=None,\n",
    "        sep=\";\",\n",
    "        names=[\"xdate\", \"xvalue\"],\n",
    "        na_values=\"-9999\",\n",
    "        encoding=\"cp1252\",\n",
    "    )\n",
    "\n",
    "    # Get just records for year of interest\n",
    "    q_stn_df = q_stn_df.truncate(before=\"%s-01-01\" % year, after=\"%s-12-31\" % (year))\n",
    "\n",
    "    # Remove HH:MM:SS part from dates\n",
    "    q_stn_df = q_stn_df.resample(\"D\").mean(numeric_only=True)\n",
    "    q_stn_df.reset_index(inplace=True)\n",
    "    q_stn_df[\"xdate\"] = q_stn_df[\"xdate\"].dt.date\n",
    "\n",
    "    # Linear interpolation and back-filling of NaN\n",
    "    q_stn_df[\"xvalue\"].interpolate(method=\"linear\", inplace=True)\n",
    "    q_stn_df[\"xvalue\"].fillna(method=\"backfill\", inplace=True)\n",
    "\n",
    "    # Add 10 m3/s to 16.133 (RESA2 ID 59)\n",
    "    if dis_stn_id == 59:\n",
    "        q_stn_df[\"xvalue\"] = q_stn_df[\"xvalue\"] + 10.0\n",
    "\n",
    "    # Add dis_id and tidy\n",
    "    q_stn_df[\"dis_station_id\"] = dis_stn_id\n",
    "    q_stn_df[\"xcomment\"] = np.nan\n",
    "\n",
    "    # Reorder cols\n",
    "    q_stn_df = q_stn_df[[\"dis_station_id\", \"xdate\", \"xvalue\", \"xcomment\"]]\n",
    "\n",
    "    # Append to output\n",
    "    df_list.append(q_stn_df)\n",
    "\n",
    "# Stack data\n",
    "tri_q_df = pd.concat(df_list, axis=0)\n",
    "\n",
    "assert (\n",
    "    len(tri_q_df) == len(file_list) * days\n",
    "), \"Datasets has an unexpected number of records.\"\n",
    "assert tri_q_df[\"xvalue\"].dtypes == np.float64, 'Check for text in \"xvalue\" column.'\n",
    "assert pd.isna(tri_q_df[\"xvalue\"]).sum() == 0, 'Check for NaN in \"xvalue\" column.'\n",
    "\n",
    "tri_q_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5fa7f-ce1b-4d20-b2fa-fe7e0d554a85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sn.relplot(\n",
    "    data=tri_q_df,\n",
    "    x=\"xdate\",\n",
    "    y=\"xvalue\",\n",
    "    row=\"dis_station_id\",\n",
    "    kind=\"line\",\n",
    "    height=3,\n",
    "    aspect=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de5717-b5a2-4ce5-9c17-f0d9fc5c92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add new rows to database\n",
    "# tri_q_df.to_sql(\n",
    "#     \"discharge_values\", con=eng, schema=\"resa2\", if_exists=\"append\", index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac0b50-e37c-4a05-b93e-2d24aa255196",
   "metadata": {},
   "source": [
    "## 2. Modelled discharge\n",
    "\n",
    "Each year, Stein Beldring supplies modelled data from HBV for the period from 1990 to the year of interest. The flow files are named e.g. `hbv_00000001.var`, where the number corresponds to the NVE \"vassdragsområde\". These are listed in *vassomr.pdf* in the above folder, and they're also included in RESA2's `DISCHARGE_STATIONS` table. The vassdragsområde numbers are stored in the `NVE_SERINUMMER` field.\n",
    "\n",
    "Tore has an Access database in e.g.\n",
    "\n",
    "K:\\Avdeling\\Vass\\316_Miljøinformatikk\\Prosjekter\\RID\\Vannføring\\Modellert\\NVE_MODELLERT_2016\\vannføring\n",
    "\n",
    "that first deletes the modelled NVE values for each station from 1990 onwards and then adds the new data, which includes everything from 1990 plus the additional year of data. The code below does the same, and performs some basic checking of the data at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5aab33e-b2ec-4cc9-9e04-44261900c156",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing hbv_00000089.var.\n",
      "Processing hbv_00000099.var.\n",
      "Processing hbv_00000107.var.\n",
      "Processing hbv_00000057.var.\n",
      "Processing hbv_00000219.var.\n",
      "Processing hbv_00000200.var.\n",
      "Processing hbv_00000180.var.\n",
      "Processing hbv_00000203.var.\n",
      "Processing hbv_00000246.var.\n",
      "Processing hbv_00000196.var.\n",
      "Processing hbv_00000094.var.\n",
      "Processing hbv_00000135.var.\n",
      "Processing hbv_00000009.var.\n",
      "Processing hbv_00000016.var.\n",
      "Processing hbv_00000038.var.\n",
      "Processing hbv_00000036.var.\n",
      "Processing hbv_00000082.var.\n",
      "Processing hbv_00000118.var.\n",
      "Processing hbv_00000076.var.\n",
      "Processing hbv_00000061.var.\n",
      "Processing hbv_00000137.var.\n",
      "Processing hbv_00000223.var.\n",
      "Processing hbv_00000220.var.\n",
      "Processing hbv_00000242.var.\n",
      "Processing hbv_00000169.var.\n",
      "Processing hbv_00000013.var.\n",
      "Processing hbv_00000028.var.\n",
      "Processing hbv_00000171.var.\n",
      "Processing hbv_00000097.var.\n",
      "Processing hbv_00000088.var.\n",
      "Processing hbv_00000175.var.\n",
      "Processing hbv_00000027.var.\n",
      "Processing hbv_00000066.var.\n",
      "Processing hbv_00000122.var.\n",
      "Processing hbv_00000215.var.\n",
      "Processing hbv_00000240.var.\n",
      "Processing hbv_00000121.var.\n",
      "Processing hbv_00000216.var.\n",
      "Processing hbv_00000243.var.\n",
      "Processing hbv_00000174.var.\n",
      "Processing hbv_00000069.var.\n",
      "Processing hbv_00000147.var.\n",
      "Processing hbv_00000239.var.\n",
      "Processing hbv_00000183.var.\n",
      "Processing hbv_00000182.var.\n",
      "Processing hbv_00000110.var.\n",
      "Processing hbv_00000210.var.\n",
      "Processing hbv_00000020.var.\n",
      "Processing hbv_00000032.var.\n",
      "Processing hbv_00000064.var.\n",
      "Processing hbv_00000190.var.\n",
      "Processing hbv_00000078.var.\n",
      "Processing hbv_00000178.var.\n",
      "Processing hbv_00000106.var.\n",
      "Processing hbv_00000105.var.\n",
      "Processing hbv_00000218.var.\n",
      "Processing hbv_00000305.var.\n",
      "Processing hbv_00000212.var.\n",
      "Processing hbv_00000159.var.\n",
      "Processing hbv_00000103.var.\n",
      "Processing hbv_00000113.var.\n",
      "Processing hbv_00000188.var.\n",
      "Processing hbv_00000033.var.\n",
      "Processing hbv_00000102.var.\n",
      "Processing hbv_00000222.var.\n",
      "Processing hbv_00000136.var.\n",
      "Processing hbv_00000165.var.\n",
      "Processing hbv_00000229.var.\n",
      "Processing hbv_00000151.var.\n",
      "Processing hbv_00000160.var.\n",
      "Processing hbv_00000235.var.\n",
      "Processing hbv_00000204.var.\n",
      "Processing hbv_00000047.var.\n",
      "Processing hbv_00000021.var.\n",
      "Processing hbv_00000072.var.\n",
      "Processing hbv_00000228.var.\n",
      "Processing hbv_00000226.var.\n",
      "Processing hbv_00000236.var.\n",
      "Processing hbv_00000134.var.\n",
      "Processing hbv_00000087.var.\n",
      "Processing hbv_00000225.var.\n",
      "Processing hbv_00000115.var.\n",
      "Processing hbv_00000198.var.\n",
      "Processing hbv_00000143.var.\n",
      "Processing hbv_00000017.var.\n",
      "Processing hbv_00000024.var.\n",
      "Processing hbv_00000141.var.\n",
      "Processing hbv_00000306.var.\n",
      "Processing hbv_00000034.var.\n",
      "Processing hbv_00000039.var.\n",
      "Processing hbv_00000181.var.\n",
      "Processing hbv_00000054.var.\n",
      "Processing hbv_00000111.var.\n",
      "Processing hbv_00000085.var.\n",
      "Processing hbv_00000187.var.\n",
      "Processing hbv_00000146.var.\n",
      "Processing hbv_00000231.var.\n",
      "Processing hbv_00000130.var.\n",
      "Processing hbv_00000075.var.\n",
      "Processing hbv_00000150.var.\n",
      "Processing hbv_00000156.var.\n",
      "Processing hbv_00000059.var.\n",
      "Processing hbv_00000154.var.\n",
      "Processing hbv_00000008.var.\n",
      "Processing hbv_00000022.var.\n",
      "Processing hbv_00000138.var.\n",
      "Processing hbv_00000176.var.\n",
      "Processing hbv_00000195.var.\n",
      "Processing hbv_00000010.var.\n",
      "Processing hbv_00000139.var.\n",
      "Processing hbv_00000002.var.\n",
      "Processing hbv_00000074.var.\n",
      "Processing hbv_00000193.var.\n",
      "Processing hbv_00000128.var.\n",
      "Processing hbv_00000232.var.\n",
      "Processing hbv_00000207.var.\n",
      "Processing hbv_00000205.var.\n",
      "Processing hbv_00000307.var.\n",
      "Processing hbv_00000108.var.\n",
      "Processing hbv_00000245.var.\n",
      "Processing hbv_00000308.var.\n",
      "Processing hbv_00000157.var.\n",
      "Processing hbv_00000123.var.\n",
      "Processing hbv_00000058.var.\n",
      "Processing hbv_00000012.var.\n",
      "Processing hbv_00000312.var.\n",
      "Processing hbv_00000112.var.\n",
      "Processing hbv_00000217.var.\n",
      "Processing hbv_00000227.var.\n",
      "Processing hbv_00000068.var.\n",
      "Processing hbv_00000084.var.\n",
      "Processing hbv_00000177.var.\n",
      "Processing hbv_00000167.var.\n",
      "Processing hbv_00000023.var.\n",
      "Processing hbv_00000194.var.\n",
      "Processing hbv_00000025.var.\n",
      "Processing hbv_00000241.var.\n",
      "Processing hbv_00000100.var.\n",
      "Processing hbv_00000142.var.\n",
      "Processing hbv_00000247.var.\n",
      "Processing hbv_00000046.var.\n",
      "Processing hbv_00000116.var.\n",
      "Processing hbv_00000162.var.\n",
      "Processing hbv_00000149.var.\n",
      "Processing hbv_00000230.var.\n",
      "Processing hbv_00000070.var.\n",
      "Processing hbv_00000311.var.\n",
      "Processing hbv_00000132.var.\n",
      "Processing hbv_00000152.var.\n",
      "Processing hbv_00000301.var.\n",
      "Processing hbv_00000096.var.\n",
      "Processing hbv_00000065.var.\n",
      "Processing hbv_00000211.var.\n",
      "Processing hbv_00000037.var.\n",
      "Processing hbv_00000129.var.\n",
      "Processing hbv_00000080.var.\n",
      "Processing hbv_00000313.var.\n",
      "Processing hbv_00000086.var.\n",
      "Processing hbv_00000053.var.\n",
      "Processing hbv_00000011.var.\n",
      "Processing hbv_00000045.var.\n",
      "Processing hbv_00000014.var.\n",
      "Processing hbv_00000304.var.\n",
      "Processing hbv_00000133.var.\n",
      "Processing hbv_00000098.var.\n",
      "Processing hbv_00000209.var.\n",
      "Processing hbv_00000148.var.\n",
      "Processing hbv_00000185.var.\n",
      "Processing hbv_00000237.var.\n",
      "Processing hbv_00000192.var.\n",
      "Processing hbv_00000026.var.\n",
      "Processing hbv_00000056.var.\n",
      "Processing hbv_00000213.var.\n",
      "Processing hbv_00000060.var.\n",
      "Processing hbv_00000310.var.\n",
      "Processing hbv_00000208.var.\n",
      "Processing hbv_00000173.var.\n",
      "Processing hbv_00000067.var.\n",
      "Processing hbv_00000101.var.\n",
      "Processing hbv_00000161.var.\n",
      "Processing hbv_00000206.var.\n",
      "Processing hbv_00000003.var.\n",
      "Processing hbv_00000189.var.\n",
      "Processing hbv_00000120.var.\n",
      "Processing hbv_00000302.var.\n",
      "Processing hbv_00000081.var.\n",
      "Processing hbv_00000029.var.\n",
      "Processing hbv_00000117.var.\n",
      "Processing hbv_00000172.var.\n",
      "Processing hbv_00000214.var.\n",
      "Processing hbv_00000233.var.\n",
      "Processing hbv_00000184.var.\n",
      "Processing hbv_00000030.var.\n",
      "Processing hbv_00000124.var.\n",
      "Processing hbv_00000077.var.\n",
      "Processing hbv_00000221.var.\n",
      "Processing hbv_00000125.var.\n",
      "Processing hbv_00000201.var.\n",
      "Processing hbv_00000234.var.\n",
      "Processing hbv_00000063.var.\n",
      "Processing hbv_00000314.var.\n",
      "Processing hbv_00000042.var.\n",
      "Processing hbv_00000007.var.\n",
      "Processing hbv_00000048.var.\n",
      "Processing hbv_00000186.var.\n",
      "Processing hbv_00000051.var.\n",
      "Processing hbv_00000140.var.\n",
      "Processing hbv_00000043.var.\n",
      "Processing hbv_00000055.var.\n",
      "Processing hbv_00000095.var.\n",
      "Processing hbv_00000006.var.\n",
      "Processing hbv_00000052.var.\n",
      "Processing hbv_00000126.var.\n",
      "Processing hbv_00000199.var.\n",
      "Processing hbv_00000155.var.\n",
      "Processing hbv_00000303.var.\n",
      "Processing hbv_00000191.var.\n",
      "Processing hbv_00000035.var.\n",
      "Processing hbv_00000040.var.\n",
      "Processing hbv_00000315.var.\n",
      "Processing hbv_00000238.var.\n",
      "Processing hbv_00000179.var.\n",
      "Processing hbv_00000158.var.\n",
      "Processing hbv_00000109.var.\n",
      "Processing hbv_00000197.var.\n",
      "Processing hbv_00000091.var.\n",
      "Processing hbv_00000153.var.\n",
      "Processing hbv_00000093.var.\n",
      "Processing hbv_00000062.var.\n",
      "Processing hbv_00000015.var.\n",
      "Processing hbv_00000170.var.\n",
      "Processing hbv_00000079.var.\n",
      "Processing hbv_00000202.var.\n",
      "Processing hbv_00000164.var.\n",
      "Processing hbv_00000224.var.\n",
      "Processing hbv_00000168.var.\n",
      "Processing hbv_00000071.var.\n",
      "Processing hbv_00000049.var.\n",
      "Processing hbv_00000092.var.\n",
      "Processing hbv_00000114.var.\n",
      "Processing hbv_00000144.var.\n",
      "Processing hbv_00000166.var.\n",
      "Processing hbv_00000019.var.\n",
      "Processing hbv_00000119.var.\n",
      "Processing hbv_00000104.var.\n",
      "Processing hbv_00000044.var.\n",
      "Processing hbv_00000073.var.\n",
      "Processing hbv_00000041.var.\n",
      "Processing hbv_00000090.var.\n",
      "Processing hbv_00000083.var.\n",
      "Processing hbv_00000145.var.\n",
      "Processing hbv_00000244.var.\n",
      "Processing hbv_00000031.var.\n",
      "Processing hbv_00000163.var.\n",
      "Processing hbv_00000004.var.\n",
      "Processing hbv_00000005.var.\n",
      "Processing hbv_00000018.var.\n",
      "Processing hbv_00000127.var.\n",
      "Processing hbv_00000001.var.\n",
      "Processing hbv_00000050.var.\n",
      "Processing hbv_00000131.var.\n"
     ]
    }
   ],
   "source": [
    "# Folder containing modelled data\n",
    "data_fold = f\"/home/jovyan/shared/common/elveovervakingsprogrammet/nve_hbv_modelled/nve_rid_{year}\"\n",
    "\n",
    "# Get a list of files to process (only interested in flow here)\n",
    "search_path = os.path.join(data_fold, \"hbv_*.var\")\n",
    "file_list = glob.glob(search_path)\n",
    "\n",
    "# Get number of days between 1990 and year of interest\n",
    "days_new = len(pd.date_range(start=\"1990-01-01\", end=\"%s-12-31\" % year, freq=\"D\"))\n",
    "\n",
    "# Get number of days between 1990 and year before\n",
    "days_old = len(pd.date_range(start=\"1990-01-01\", end=\"%s-12-31\" % (year - 1), freq=\"D\"))\n",
    "\n",
    "# Loop over files\n",
    "for file_path in file_list:\n",
    "    # Get name and reg. nr.\n",
    "    name = os.path.split(file_path)[1]\n",
    "    reg_nr = int(name.split(\"_\")[1][:-4])\n",
    "    print(f\"Processing {name}.\")\n",
    "\n",
    "    # Get RESA2 station ID\n",
    "    sql = (\n",
    "        \"SELECT dis_station_id FROM resa2.discharge_stations \"\n",
    "        \"WHERE nve_serienummer = '%s'\" % reg_nr\n",
    "    )\n",
    "    dis_id = pd.read_sql_query(sql, eng).iloc[0, 0]\n",
    "\n",
    "    # Check number of post-1990 records already in db\n",
    "    # (should equal days_old)\n",
    "    sql = (\n",
    "        \"SELECT COUNT(*) FROM resa2.discharge_values \"\n",
    "        \"WHERE dis_station_id = %s \"\n",
    "        \"AND xdate >= DATE '1990-01-01'\" % dis_id\n",
    "    )\n",
    "    cnt_old = pd.read_sql_query(sql, eng).iloc[0, 0]\n",
    "    assert cnt_old == days_old, \"Unexpected number of records already in database.\"\n",
    "\n",
    "    # Read new data\n",
    "    df = pd.read_csv(\n",
    "        file_path, delim_whitespace=True, header=None, names=[\"XDATE\", \"XVALUE\"]\n",
    "    )\n",
    "\n",
    "    # Convert dates\n",
    "    df[\"XDATE\"] = pd.to_datetime(df[\"XDATE\"], format=\"%Y%m%d/1200\")\n",
    "\n",
    "    # Check st, end and length\n",
    "    assert df[\"XDATE\"].iloc[0] == pd.Timestamp(\n",
    "        \"1990-01-01\"\n",
    "    ), \"New series does not start on 01/01/1990.\"\n",
    "    assert df[\"XDATE\"].iloc[-1] == pd.Timestamp(\"%s-12-31\" % year), (\n",
    "        \"New series does not end on 31/12/%s.\" % year\n",
    "    )\n",
    "    assert len(df) == days_new, \"Unexpected length for new series.\"\n",
    "\n",
    "    # Add station ID to df\n",
    "    df[\"DIS_STATION_ID\"] = dis_id\n",
    "\n",
    "    # Drop existing rows post-1990 for this site\n",
    "    sql = text(\n",
    "        \"DELETE FROM resa2.discharge_values \"\n",
    "        \"WHERE dis_station_id = :dis_station_id \"\n",
    "        \"AND xdate >= DATE '1990-01-01'\"\n",
    "    )\n",
    "    with eng.connect() as connection:\n",
    "        res = connection.execute(sql, {\"dis_station_id\": int(dis_id)})\n",
    "        connection.commit()\n",
    "\n",
    "    # Add new rows\n",
    "    df.to_sql(\n",
    "        \"discharge_values\", con=eng, schema=\"resa2\", if_exists=\"append\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2237c0b-fa7c-41ac-9e7e-ade1cd59cd1f",
   "metadata": {},
   "source": [
    "## 3. Upload of data that has not finished quality control\n",
    "\n",
    "**Added 12.10.2022**\n",
    "\n",
    "**The code below should not be used unless necessary**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e8b0c-841f-4f81-b0fe-60f087f395f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nve_stn_ids = [\"2.605.0\", \"16.133.0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ea920-98e4-4d10-86a7-baa4d1acf72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get discharge\n",
    "par_ids = [1001]\n",
    "st_dt = f\"{year}-01-01\"\n",
    "end_dt = f\"{year + 1}-01-01\"\n",
    "q_df = nivapy.da.query_nve_hydapi(\n",
    "    nve_stn_ids, par_ids, st_dt, end_dt, resolution=1440, api_key=api_key\n",
    ")\n",
    "q_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f38c3-62a4-4875-a974-251fc5745259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot raw\n",
    "q_df2 = q_df[[\"datetime\", \"value\", \"station_name\"]]\n",
    "q_df2.set_index([\"datetime\", \"station_name\"], inplace=True)\n",
    "q_df2 = q_df2.unstack(\"station_name\")\n",
    "\n",
    "# Plot\n",
    "q_df2.plot(subplots=True, sharex=True, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d401f87-7051-4a17-a39a-801c51258775",
   "metadata": {},
   "source": [
    "The code below uses the function defined above to process data from HydAPI. The only difference is that this time I'm using it with data that hasn't finished QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2780d967-493f-41a8-977b-8488cd00f913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hydapi_q_df = process_hydapi_data_for_resa(resa_nve_df, q_df, eng)\n",
    "hydapi_q_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2717c45-0508-4403-96ce-1452990dc87d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot processed\n",
    "q_df2 = hydapi_q_df[[\"xdate\", \"xvalue\", \"dis_station_id\"]]\n",
    "q_df2.set_index([\"xdate\", \"dis_station_id\"], inplace=True)\n",
    "q_df2 = q_df2.unstack(\"dis_station_id\")\n",
    "\n",
    "# Plot\n",
    "q_df2.plot(subplots=True, sharex=True, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39158f-2c43-4f4b-b2c3-f4cb79cf206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add new rows to database\n",
    "# hydapi_q_df.to_sql(\n",
    "#     \"discharge_values\", con=eng, schema=\"resa2\", if_exists=\"append\", index=False\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
