{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import imp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geopandas.tools\n",
    "import pyproj\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from sqlalchemy import types\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "sn.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process model input datasets (2017-18)\n",
    "\n",
    "Modelling for the RID programme makes use of the following input datasets:\n",
    "\n",
    " * **Avløp** (sewage and other drainage), sub-divided into\n",
    "     * Large treatment works\n",
    "     * Small treatment works\n",
    "     * Other environmental pollutants <br><br>\n",
    "     \n",
    " * **Fiskeoppdret** (Fish farming) <br><br>\n",
    " \n",
    " * **Industri** (industrial point sources) <br><br>\n",
    " \n",
    " * **Jordbruk** (land use and management activities)\n",
    " \n",
    "The raw datasets come from a variety of different sources and must be restructured into a standardised format and added to the RESA2 database. Once in the database, these can can either be used to generate input files for TEOTIL (using either Tore's code or the workflow documented [here](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/prepare_teotil_inputs.ipynb)), or they can be used to run the new [NOPE model](http://nbviewer.jupyter.org/github/JamesSample/rid/blob/master/notebooks/nope_model.ipynb). Generating input files for NOPE from the data in RESA2 is very straightforward: simply call `nope.make_rid_input_file()` for the year of interest.\n",
    "\n",
    "This notebook takes the raw data, restructures it, and adds it to RESA2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "resa2_basic_path = (r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\Upload_Template'\n",
    "                    r'\\useful_resa2_code.py')\n",
    "\n",
    "resa2_basic = imp.load_source('useful_resa2_code', resa2_basic_path)\n",
    "\n",
    "engine, conn = resa2_basic.connect_to_resa2()\n",
    "\n",
    "# Import custom RID functions\n",
    "rid_func_path = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "                 r'\\Python\\rid\\notebooks\\useful_rid_code.py')\n",
    "\n",
    "rid = imp.load_source('useful_rid_code', rid_func_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Store anlegg, Miljøgifter and Industri\n",
    "\n",
    "These three datasets are all treated similarly, and there is some duplication between the files. Examples of the raw data formats are here:\n",
    "\n",
    " * K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Avløp\\TEOTIL store anlegg 2015 (sendt 18.08.2016).xlsx\n",
    "\n",
    " * K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Avløp\\Miljogifter_NIVA_RID-prosjektet_2015.xlsx\n",
    "\n",
    " * K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Industri\\Teotiluttrekket til NIVA - 2016_v2.xlsx\n",
    "\n",
    "The files for 2017 need to be checked and tidied to match those from 2016, which are here:\n",
    "\n",
    " * C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\n",
    "\n",
    "I have created a new folder named *point_data_2017* for this year's data. See also the information in the e-mail from John Rune received 29/06/2017 at 15.53. \n",
    "\n",
    "**Note:** The raw data files for industry often contain several years of data. For the file in the folder above, I've filtered the values to only include the year of interest.\n",
    "\n",
    "The data in these files must be added to two tables in RESA2:\n",
    "\n",
    " * First, the site data must be added to `RESA2.RID_PUNKTKILDER`. Most of the sites should already be there, but occasionally new sites are added. Any new stations must be be assigned lat/lon co-ordinates and the appropriate \"Regine\" catchment ID. This usually requires geocoding plus co-ordinate conversions and/or a spatial join to determine catchment IDs.\n",
    " \n",
    "    **Note:** Many (>70) of the stations already in the database are missing Regine IDs. Many more (>3000) are missing co-ordinate information. We have previously asked Miljødirektoratet about this, but they have not yet provided the missing data. <br><br>\n",
    " \n",
    " * Secondly, the chemistry data for each site must be extracted and converted to \"long\" format, then added to `RESA2.RID_PUNKTKILDER_INPAR_VALUES`. Parameter IDs etc. are taken from `RESA2.RID_PUNKTKILDER_INPAR_DEF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw (tidied) data\n",
    "# Year of interest\n",
    "year = 2017\n",
    "\n",
    "# Store anlegg\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\point_data_%s\\avlop_stor_anlegg_%s_raw.xlsx' % (year, year))\n",
    "stan_df = pd.read_excel(in_xlsx, sheet_name='store_anlegg_%s' % year)\n",
    "\n",
    "# Miljøgifter\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\point_data_%s\\avlop_miljogifter_%s_raw.xlsx' % (year, year))\n",
    "milo_df = pd.read_excel(in_xlsx, sheet_name='miljogifter_%s' % year)\n",
    "\n",
    "# Industri\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\point_data_%s\\industri_%s_raw.xlsx' % (year, year))\n",
    "ind_df = pd.read_excel(in_xlsx, sheet_name='industry_%s' % year)\n",
    "\n",
    "# Drop blank rows\n",
    "stan_df.dropna(how='all', inplace=True)\n",
    "milo_df.dropna(how='all', inplace=True)\n",
    "ind_df.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Basic data checking\n",
    "\n",
    "All of the \"Store Anlegg\" and \"Miljøgifter\" sites are classified as `RENSEANLEGG` in the `TYPE` column of `RESA2.RID_PUNKTKILDER`; \"Industri\" sites as labelled `INDUSTRI`.\n",
    "\n",
    "Add `TYPE` columns, merge site data from different sources, convert UTM co-ordinates to WGS84 decimal degrees and identify sites not already in the database. Issues identified below (e.g. missing co-ordinates) should be corrected if possible before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Data\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Data\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Data\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following locations are not in the database:\n",
      "Empty DataFrame\n",
      "Columns: [anlegg_nr, anlegg_navn]\n",
      "Index: []\n",
      "\n",
      "The following locations do not have co-ordinates:\n",
      "     anlegg_nr                           anlegg_navn\n",
      "68    0235AL63                       Onsrud rekkehus\n",
      "112   0420AL55                 Vestmarka renseanlegg\n",
      "327   0605AL36                         RA Nes i Ådal\n",
      "353   0617AL21                         Nystølfjellet\n",
      "359   0618AL01                           Bergastølen\n",
      "364   0618AL24                   Hemsedal Golf Alpin\n",
      "371   0619AL63                Sameiet Hesthovdstølen\n",
      "374   0619AL70     Trollberget hyttefelt, Skjervheim\n",
      "375   0619AL71              Liagardane utleigehytter\n",
      "376   0619AL76                 Skrindehaugen H23-H21\n",
      "377   0619AL80        Nystølsameiga, Nordre Øknevatn\n",
      "378   0619AL81                  Torpomoen kurssenter\n",
      "379   0619AL83                              Venehaug\n",
      "391   0621AL37                      Nedre Eggedal RA\n",
      "403   0623AL11                      Gulsrud Leirsted\n",
      "409   0624AL76                Damåsen Pukk, brakkeby\n",
      "421   0628AL67                   Solbergstøa Camping\n",
      "422   0628AL70               Knatvoldstranda Camping\n",
      "423   0628AL71                     Rødtangen Camping\n",
      "424   0628AL72                 Steinerskolen i Hurum\n",
      "428   0631AL21                BLÅBERG FJELLSTUE R.A.\n",
      "431   0631AL32             Borge–Blestua hytteområde\n",
      "434   0632AL54    Søre Risteigen infiltrasjonsanlegg\n",
      "436   0633AL21            EKT FJELLGÅRD OG LEIRSKOLE\n",
      "582   0938AL61                Reiårsvatn 2 hyttefelt\n",
      "604   1002AL17                   Lian vest hyttefelt\n",
      "696   1114AL20  Grønabakkane - Stavtjørn renseanlegg\n",
      "955   1221AL23                         Skjersholmane\n",
      "956   1221AL25                           Grunnavågen\n",
      "998   1224AL34                          Korsneset RA\n",
      "999   1224AL35       Kvednavik hytteområde, Fjelberg\n",
      "1000  1224AL36                             Årsnes SA\n",
      "1001  1224AL37                          Sandvikjo SA\n",
      "1033  1233AL05                               Myrulla\n",
      "1034  1233AL07                   Hotell og Apartment\n",
      "1141  1246AL30                             Storanipa\n",
      "1236  1253AL22                        Haus silanlegg\n",
      "1361  1417AL13                       Vik Fjellandsby\n",
      "1939  1612AL42          Vitsøsætra avløpsrenseanlegg\n",
      "2160  1755AL01                    Husby avløpsanlegg\n",
      "2161  1755AL02                   Leknes avløpsanlegg\n",
      "2383  1859AL02                           Nusfjord AS\n",
      "2404  1860AL32                                 Neset\n",
      "2574  1931AL32                     Lunde renseanlegg\n",
      "0     0101AL01                           Prestebakke\n"
     ]
    }
   ],
   "source": [
    "# Add TYPE cols\n",
    "stan_df['TYPE'] = 'RENSEANLEGG'\n",
    "milo_df['TYPE'] = 'RENSEANLEGG'\n",
    "ind_df['TYPE'] = 'INDUSTRI'\n",
    "\n",
    "# Get just stn info from each df\n",
    "stan_loc = stan_df[['ANLEGGSNR', 'ANLEGGSNAVN', 'Kommunenr', \n",
    "                    'TYPE', 'Sone', 'UTM_E', 'UTM_N']]\n",
    "\n",
    "milo_loc = milo_df[['ANLEGGSNR', 'ANLEGGSNAVN', 'KOMMUNE_NR', \n",
    "                    'TYPE', 'SONEBELTE', 'UTMOST', 'UTMNORD']]\n",
    "\n",
    "ind_loc = ind_df[['Anleggsnr', 'Anleggsnavn', 'Komm.nr', 'TYPE', \n",
    "                  'Geografisk Longitude', 'Geografisk Latitude']]\n",
    "\n",
    "\n",
    "# Rename cols\n",
    "stan_loc.columns = ['anlegg_nr', 'anlegg_navn', 'komm_no',\n",
    "                    'TYPE', 'zone', 'east', 'north']\n",
    "milo_loc.columns = ['anlegg_nr', 'anlegg_navn', 'komm_no',\n",
    "                    'TYPE', 'zone', 'east', 'north']\n",
    "ind_loc.columns = ['anlegg_nr', 'anlegg_navn', 'komm_no',\n",
    "                   'TYPE', 'lon', 'lat']\n",
    "\n",
    "# Drop duplicates\n",
    "stan_loc.drop_duplicates(inplace=True)\n",
    "milo_loc.drop_duplicates(inplace=True)\n",
    "ind_loc.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert UTM to lat/lon\n",
    "# \"Industri\" data is already in dd\n",
    "stan_loc = rid.utm_to_wgs84_dd(stan_loc, 'zone', 'east', 'north')\n",
    "milo_loc = rid.utm_to_wgs84_dd(milo_loc, 'zone', 'east', 'north')\n",
    "\n",
    "# Remove UTM data \n",
    "del stan_loc['zone'], stan_loc['east'], stan_loc['north']\n",
    "del milo_loc['zone'], milo_loc['east'], milo_loc['north']\n",
    "\n",
    "# combine into single df\n",
    "loc_df = pd.concat([stan_loc, milo_loc, ind_loc], axis=0, sort=True)\n",
    "\n",
    "# The same site can be in multiple files, so drop duplicates\n",
    "loc_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Kommune nr. should be a 4 char string, not a float\n",
    "fmt = lambda x: '%04d' % x\n",
    "loc_df['komm_no'] = loc_df['komm_no'].apply(fmt)\n",
    "\n",
    "# Check ANLEGG_NR is unique\n",
    "assert loc_df.index.duplicated().all() == False, 'Some \"ANLEGGSNRs\" are duplicated.'\n",
    "\n",
    "# Check if any sites are not already in db\n",
    "sql = ('SELECT UNIQUE(ANLEGG_NR) '\n",
    "       'FROM resa2.rid_punktkilder')\n",
    "annr_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "not_in_db = set(loc_df['anlegg_nr'].values) - set(annr_df['anlegg_nr'].values)\n",
    "\n",
    "print '\\nThe following locations are not in the database:'\n",
    "print loc_df[loc_df['anlegg_nr'].isin(list(not_in_db))][['anlegg_nr', 'anlegg_navn']]\n",
    "\n",
    "# Check if any sites are missing co-ords\n",
    "print '\\nThe following locations do not have co-ordinates:'\n",
    "print loc_df.query('(lat!=lat) or (lon!=lon)')[['anlegg_nr', 'anlegg_navn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Identify Regine Vassdragsnummer\n",
    "\n",
    "The shapefile here:\n",
    "\n",
    "K:\\Kart\\Regine_2006\\RegMinsteF.shp\n",
    "\n",
    "shows locations for all the Regine catchments used by TEOTIL (see e-mail from John Rune received 29/06/2017 at 17.26). I've copied this file locally here:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\gis\\shapefiles\\RegMinsteF.shp\n",
    "\n",
    "and re-projected it to WGS84 geographic co-ordinates. The new file is called *reg_minste_f_wgs84.shp*.\n",
    "\n",
    "I have also written a function to perform a spatial join and identify which Regine polygon each point is located in.\n",
    "\n",
    "**Note:** Geopandas is quite fussy about its input data (and also to install). The code below works, but the GDAL/OGR version [here](https://stackoverflow.com/a/13433127/505698) might be more robust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Not all sites have complete co-ordinate information. These rows will be dropped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>anlegg_navn</th>\n",
       "      <th>anlegg_nr</th>\n",
       "      <th>komm_no</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>VASSDRAGNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Prestebakke</td>\n",
       "      <td>0101AL01</td>\n",
       "      <td>0101</td>\n",
       "      <td>58.993978</td>\n",
       "      <td>11.533224</td>\n",
       "      <td>001.1A2B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Bakke</td>\n",
       "      <td>0101AL02</td>\n",
       "      <td>0101</td>\n",
       "      <td>59.015311</td>\n",
       "      <td>11.445723</td>\n",
       "      <td>001.2220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Kornsjø</td>\n",
       "      <td>0101AL06</td>\n",
       "      <td>0101</td>\n",
       "      <td>58.935184</td>\n",
       "      <td>11.668959</td>\n",
       "      <td>001.1J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Remmendalen avløpsanlegg</td>\n",
       "      <td>0101AL07</td>\n",
       "      <td>0101</td>\n",
       "      <td>59.120864</td>\n",
       "      <td>11.360106</td>\n",
       "      <td>001.31Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>Kambo avløpsanlegg</td>\n",
       "      <td>0104AL01</td>\n",
       "      <td>0104</td>\n",
       "      <td>59.474488</td>\n",
       "      <td>10.686496</td>\n",
       "      <td>003.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TYPE               anlegg_navn anlegg_nr komm_no        lat  \\\n",
       "0  RENSEANLEGG               Prestebakke  0101AL01    0101  58.993978   \n",
       "1  RENSEANLEGG                     Bakke  0101AL02    0101  59.015311   \n",
       "2  RENSEANLEGG                   Kornsjø  0101AL06    0101  58.935184   \n",
       "3  RENSEANLEGG  Remmendalen avløpsanlegg  0101AL07    0101  59.120864   \n",
       "4  RENSEANLEGG        Kambo avløpsanlegg  0104AL01    0104  59.474488   \n",
       "\n",
       "         lon VASSDRAGNR  \n",
       "0  11.533224   001.1A2B  \n",
       "1  11.445723   001.2220  \n",
       "2  11.668959     001.1J  \n",
       "3  11.360106    001.31Z  \n",
       "4  10.686496     003.20  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to Regine catchment shapefile\n",
    "reg_shp_path = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "                r'\\Data\\gis\\shapefiles\\reg_minste_f_wgs84.shp')\n",
    "\n",
    "# Spatial join\n",
    "loc_df = rid.identify_point_in_polygon(loc_df, reg_shp_path, \n",
    "                                       'anlegg_nr', 'VASSDRAGNR',\n",
    "                                       'lat', 'lon')\n",
    "\n",
    "loc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Restructuring site data\n",
    "\n",
    "For sites dataframe, rename columns to match RESA2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>ANLEGG_NR</th>\n",
       "      <th>ANLEGG_NAVN</th>\n",
       "      <th>KNO</th>\n",
       "      <th>REGINE</th>\n",
       "      <th>LON_UTL</th>\n",
       "      <th>LAT_UTL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0101AL01</td>\n",
       "      <td>Prestebakke</td>\n",
       "      <td>0101</td>\n",
       "      <td>001.1A2B</td>\n",
       "      <td>11.533224</td>\n",
       "      <td>58.993978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0101AL02</td>\n",
       "      <td>Bakke</td>\n",
       "      <td>0101</td>\n",
       "      <td>001.2220</td>\n",
       "      <td>11.445723</td>\n",
       "      <td>59.015311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0101AL06</td>\n",
       "      <td>Kornsjø</td>\n",
       "      <td>0101</td>\n",
       "      <td>001.1J</td>\n",
       "      <td>11.668959</td>\n",
       "      <td>58.935184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0101AL07</td>\n",
       "      <td>Remmendalen avløpsanlegg</td>\n",
       "      <td>0101</td>\n",
       "      <td>001.31Z</td>\n",
       "      <td>11.360106</td>\n",
       "      <td>59.120864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RENSEANLEGG</td>\n",
       "      <td>0104AL01</td>\n",
       "      <td>Kambo avløpsanlegg</td>\n",
       "      <td>0104</td>\n",
       "      <td>003.20</td>\n",
       "      <td>10.686496</td>\n",
       "      <td>59.474488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TYPE ANLEGG_NR               ANLEGG_NAVN   KNO    REGINE    LON_UTL  \\\n",
       "0  RENSEANLEGG  0101AL01               Prestebakke  0101  001.1A2B  11.533224   \n",
       "1  RENSEANLEGG  0101AL02                     Bakke  0101  001.2220  11.445723   \n",
       "2  RENSEANLEGG  0101AL06                   Kornsjø  0101    001.1J  11.668959   \n",
       "3  RENSEANLEGG  0101AL07  Remmendalen avløpsanlegg  0101   001.31Z  11.360106   \n",
       "4  RENSEANLEGG  0104AL01        Kambo avløpsanlegg  0104    003.20  10.686496   \n",
       "\n",
       "     LAT_UTL  \n",
       "0  58.993978  \n",
       "1  59.015311  \n",
       "2  58.935184  \n",
       "3  59.120864  \n",
       "4  59.474488  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename other cols to match RESA2\n",
    "loc_df['ANLEGG_NR'] = loc_df['anlegg_nr']\n",
    "loc_df['ANLEGG_NAVN'] = loc_df['anlegg_navn']\n",
    "loc_df['KNO'] = loc_df['komm_no']\n",
    "loc_df['REGINE'] = loc_df['VASSDRAGNR']\n",
    "loc_df['LON_UTL'] = loc_df['lon']\n",
    "loc_df['LAT_UTL'] = loc_df['lat']\n",
    "\n",
    "del loc_df['anlegg_nr'], loc_df['anlegg_navn'], loc_df['komm_no']\n",
    "del loc_df['VASSDRAGNR'], loc_df['lon'], loc_df['lat']\n",
    "\n",
    "loc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>ANLEGG_NR</th>\n",
       "      <th>ANLEGG_NAVN</th>\n",
       "      <th>KNO</th>\n",
       "      <th>REGINE</th>\n",
       "      <th>LON_UTL</th>\n",
       "      <th>LAT_UTL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TYPE, ANLEGG_NR, ANLEGG_NAVN, KNO, REGINE, LON_UTL, LAT_UTL]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get details for sites not already in db\n",
    "loc_upld = loc_df[loc_df['ANLEGG_NR'].isin(list(not_in_db))]\n",
    "\n",
    "loc_upld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_PUNKTKILDER\n",
    "#loc_upld.to_sql('rid_punktkilder', con=engine, schema='resa2', \n",
    "#                if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Restructuring values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year for the data in question\n",
    "year = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Anlegg\n",
    "# Get cols of interest \n",
    "stan_vals = stan_df[['ANLEGGSNR', 'MENGDE_P_UT_kg', 'MENGDE_N_UT_kg']]\n",
    "\n",
    "# In RESA2.RID_PUNKTKILDER_INPAR_DEF, N is par_id 44 and P par_id 45\n",
    "stan_vals.columns = ['ANLEGG_NR', 45, 44]\n",
    "\n",
    "# Melt to \"long\" format\n",
    "stan_vals = pd.melt(stan_vals, id_vars='ANLEGG_NR', value_vars=[45, 44],\n",
    "                    var_name='INP_PAR_ID', value_name='VALUE')\n",
    "\n",
    "# Drop NaN values\n",
    "stan_vals.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as I can tell from exploring the 2015 data in the database, the main columns of interest for Miljøgifter are given in `milo_dict`, below, together with the corresponding parameter IDs from `RESA2.RID_PUNKTKILDER_INPAR_DEF`. This hard-coding is a bit messy, but I can't see any database table providing a nice lookup between these values, so they're included here for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miljøgifter\n",
    "# Get cols of interest \n",
    "milo_dict = {'MILJOGIFTHG2':16, \n",
    "             'MILJOGIFTPAH2':48, \n",
    "             'MILJOGIFTPCB2':30, \n",
    "             'MILJOGIFTCD2':8, \n",
    "             'MILJOGIFTDEHP2':119, \n",
    "             'MILJOGIFTAS2':2,\n",
    "             'MILJOGIFTCR2':10, \n",
    "             'MILJOGIFTPB2':28, \n",
    "             'MILJOGIFTNI2':25,\n",
    "             'MILJOGIFTCU2':15, \n",
    "             'MILJOGIFTZN2':38, \n",
    "             'KONSMENGDTOTP10':45,\n",
    "             'KONSMENGDTOTN10':44, \n",
    "             'KONSMENGDSS10':46,\n",
    "             'ANLEGGSNR':'ANLEGG_NR'} # Make heading match RESA\n",
    "\n",
    "milo_vals = milo_df[milo_dict.keys()]\n",
    "\n",
    "# Get par IDs from dict\n",
    "milo_vals.columns = [milo_dict[i] for i in milo_vals.columns]\n",
    "\n",
    "# Melt to \"long\" format\n",
    "milo_vals = pd.melt(milo_vals, id_vars='ANLEGG_NR',\n",
    "                    var_name='INP_PAR_ID', value_name='VALUE')\n",
    "\n",
    "# Drop NaN values\n",
    "milo_vals.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The industry data is already in \"long\" format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Data\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Industri\n",
    "# Get cols of interest\n",
    "ind_vals = ind_df[['Anleggsnr', 'Komp.kode', 'Mengde', 'Enhet']]\n",
    "ind_vals.columns = ['anlegg_nr', 'name', 'value', 'unit']\n",
    "\n",
    "# Get par defs from db\n",
    "# Check if any sites are not already in db\n",
    "sql = ('SELECT * '\n",
    "       'FROM resa2.rid_punktkilder_inpar_def')\n",
    "par_df = pd.read_sql_query(sql, engine)\n",
    "del par_df['descr']\n",
    "\n",
    "# Convert all units to capitals\n",
    "ind_vals['unit'] = ind_vals['unit'].str.capitalize()\n",
    "par_df['unit'] = par_df['unit'].str.capitalize()\n",
    "\n",
    "# Join\n",
    "ind_vals = pd.merge(ind_vals, par_df, how='left',\n",
    "                    on=['name', 'unit'])\n",
    "\n",
    "# Some parameters that are not of interest are not matched\n",
    "# Drop these\n",
    "ind_vals.dropna(how='any', inplace=True)\n",
    "\n",
    "# Get just cols of interest\n",
    "ind_vals = ind_vals[['anlegg_nr', 'in_pid', 'value']]\n",
    "\n",
    "# Rename for db\n",
    "ind_vals.columns = ['ANLEGG_NR', 'INP_PAR_ID', 'VALUE']\n",
    "\n",
    "# Convert col types\n",
    "ind_vals['INP_PAR_ID'] = ind_vals['INP_PAR_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "val_df = pd.concat([stan_vals, milo_vals, ind_vals], axis=0, sort=True)\n",
    "\n",
    "# Add column for year\n",
    "val_df['YEAR'] = year\n",
    "\n",
    "# Explicitly set data types\n",
    "val_df['ANLEGG_NR'] = val_df['ANLEGG_NR'].astype(str)\n",
    "val_df['INP_PAR_ID'] = val_df['INP_PAR_ID'].astype(int)\n",
    "val_df['VALUE'] = val_df['VALUE'].astype(float)\n",
    "val_df['YEAR'] = val_df['YEAR'].astype(int)\n",
    "\n",
    "# Store Anlegg and Miljøgifter contain some duplicated information\n",
    "val_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop any existing values for this year\n",
    "#sql = (\"DELETE FROM resa2.rid_punktkilder_inpar_values \"\n",
    "#       \"WHERE year = %s\" % year)\n",
    "#res = conn.execute(sql)\n",
    "#\n",
    "## Add to RESA2.RID_PUNKTKILDER_INPAR_VALUES \n",
    "#val_df.to_sql('rid_punktkilder_inpar_values', con=engine, schema='resa2', \n",
    "#              if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Små anlegg (small treatment works)\n",
    "\n",
    "An example of the raw data format is here:\n",
    "\n",
    "K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Avløp\\TEOTIL små anlegg 2015 (sendt 18.08.2016).xlsx\n",
    "\n",
    "I have made a local copy of the 2016 file here:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\\avlop_sma_anlegg_2016_raw.xlsx\n",
    "\n",
    "and deleted unnecessary columns. All of this data can be added directly to `RESA2.RID_KILDER_SPREDT_VALUES`. The kommuner ID numbers and names are in `RESA2.KOMMUNER`, but not all kommune IDs in `RID_KILDER_SPREDT_VALUES` are in `KOMMUNER`. Need to check to see if Tore's code actually uses the `KOMMUNER` table to link kommuners to OSPAR areas. If it does, **need to be careful**, but perhaps it's done directly on kommuner ID?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year for the data in question\n",
    "year = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following locations are not in the database:\n",
      "    KOMMUNENR   KOMMUNENAVN        P_kg       N_kg\n",
      "114      0710    Sandefjord  2161.89135  17169.381\n",
      "257      1505  Kristiansund  1433.17980   9554.532\n",
      "290      1576          Aure  1438.50150   9951.360\n",
      "338      1756       Inderøy  1276.12395   8778.615\n",
      "384      1903       Harstad  1710.07245  11414.937\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KOMM_NO</th>\n",
       "      <th>INP_PAR_ID</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>AR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101</td>\n",
       "      <td>45</td>\n",
       "      <td>757.78380</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0104</td>\n",
       "      <td>45</td>\n",
       "      <td>92.89980</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0105</td>\n",
       "      <td>45</td>\n",
       "      <td>1216.30410</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0106</td>\n",
       "      <td>45</td>\n",
       "      <td>206.39655</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0111</td>\n",
       "      <td>45</td>\n",
       "      <td>23.32350</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  KOMM_NO INP_PAR_ID       VALUE    AR\n",
       "0    0101         45   757.78380  2017\n",
       "1    0104         45    92.89980  2017\n",
       "2    0105         45  1216.30410  2017\n",
       "3    0106         45   206.39655  2017\n",
       "4    0111         45    23.32350  2017"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read raw (tidied) data\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\point_data_%s\\avlop_sma_anlegg_%s_raw.xlsx' % (year, year))\n",
    "sman_df = pd.read_excel(in_xlsx, \n",
    "                        sheet_name='sma_anlegg_%s' % year)\n",
    "\n",
    "# Drop blank rows\n",
    "sman_df.dropna(how='all', inplace=True)\n",
    "\n",
    "# Kommune nr. should be a 4 char string, not a float\n",
    "fmt = lambda x: '%04d' % x\n",
    "sman_df['KOMMUNENR'] = sman_df['KOMMUNENR'].apply(fmt)\n",
    "\n",
    "# Check if any kommuner are not already in db\n",
    "sql = ('SELECT UNIQUE(kommune_no) '\n",
    "       'FROM resa2.kommuner')\n",
    "kmnr_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "not_in_db = set(sman_df['KOMMUNENR'].values) - set(kmnr_df['kommune_no'].values)\n",
    "\n",
    "print '\\nThe following locations are not in the database:'\n",
    "print sman_df[sman_df['KOMMUNENR'].isin(list(not_in_db))]\n",
    "\n",
    "# Get cols of interest for RID_KILDER_SPREDT_VALUES\n",
    "sman_df = sman_df[['KOMMUNENR', 'P_kg', 'N_kg']]\n",
    "\n",
    "# In RESA2.RID_PUNKTKILDER_INPAR_DEF, N is par_id 44 and P par_id 45\n",
    "sman_df.columns = ['KOMM_NO', 45, 44]\n",
    "\n",
    "# Melt to \"long\" format\n",
    "sman_df = pd.melt(sman_df, id_vars='KOMM_NO', value_vars=[45, 44],\n",
    "                  var_name='INP_PAR_ID', value_name='VALUE')\n",
    "\n",
    "# Add column for year\n",
    "sman_df['AR'] = year\n",
    "\n",
    "sman_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_KILDER_SPREDT_VALUES\n",
    "#sman_df.to_sql('rid_kilder_spredt_values', con=engine, schema='resa2', \n",
    "#               if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fish farms\n",
    "\n",
    "An example of the raw data is here:\n",
    "\n",
    " * K:\\Prosjekter\\Ferskvann\\O-13255-TEOTIL\\2016\\Rådata\\Fiskeoppdrett\\Teotil - 2015 (2) (pr. 09.08.16).xlsx.zip\n",
    "\n",
    "I have made a local copy of the 2016 file here:\n",
    "\n",
    " * C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\\fiske_oppdret_2016_raw.xlsx\n",
    "\n",
    "The data must be added to two tables in RESA2:\n",
    "\n",
    " * First, the site data must be added to `RESA2.RID_KILDER_AQUAKULTUR`. Most of the sites should already be there, but occasionally new sites are added. Any new stations must be be assigned lat/lon co-ordinates and the appropriate \"Regine\" catchment ID. This usually requires geocoding plus co-ordinate conversions and/or a spatial join to determine catchment IDs.\n",
    " \n",
    "    **Note:** The key ID fields in the raw data appear to be `LOKNR` and `LOKNAVN`. <br><br>\n",
    " \n",
    " * Secondly, the chemistry data for each site must be extracted and converted to \"long\" format, then added to `RESA2.RID_KILDER_AQKULT_VALUES`. Parameter IDs etc. are taken from `RESA2.RID_PUNKTKILDER_INPAR_DEF`.\n",
    " \n",
    "### 3.1. Basic data checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year for the data in question\n",
    "year = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw (tidied) data\n",
    "# Fish farms\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\point_data_%s\\fiske_oppdret_%s_raw.xlsx' % (year, year))\n",
    "fish_df = pd.read_excel(in_xlsx, sheet_name='Ark1')\n",
    "\n",
    "# Drop no data\n",
    "fish_df.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following locations are not in the database:\n",
      "Empty DataFrame\n",
      "Columns: [LOKNR, LOKNAVN, N_DESIMALGRADER_Y, O_DESIMALGRADER_X]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check if any sites are not already in db\n",
    "sql = ('SELECT UNIQUE(NR) '\n",
    "       'FROM resa2.rid_kilder_aquakultur')\n",
    "aqua_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "not_in_db = set(fish_df['LOKNR'].values) - set(aqua_df['nr'].values)\n",
    "\n",
    "nidb_df = fish_df[fish_df['LOKNR'].isin(list(not_in_db))][['LOKNR', 'LOKNAVN', \n",
    "                                                           'N_DESIMALGRADER_Y',\n",
    "                                                           'O_DESIMALGRADER_X']].drop_duplicates(subset=['LOKNR'])\n",
    "\n",
    "print '\\nThe following locations are not in the database:'\n",
    "print nidb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Geocode fish farms and add to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Regine catchment shapefile\n",
    "reg_shp_path = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "                r'\\Data\\gis\\shapefiles\\reg_minste_f_wgs84.shp')\n",
    "\n",
    "# Spatial join\n",
    "loc_df = rid.identify_point_in_polygon(nidb_df, reg_shp_path, \n",
    "                                       'LOKNR', 'VASSDRAGNR',\n",
    "                                       'N_DESIMALGRADER_Y',\n",
    "                                       'O_DESIMALGRADER_X')\n",
    "\n",
    "# Rename cols\n",
    "loc_df.columns = ['NR', 'NAVN', 'LENGDE', 'BREDDE', 'REGINE']\n",
    "\n",
    "loc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_KILDER_AQUAKULTUR\n",
    "#loc_df.to_sql('rid_kilder_aquakultur', con=engine, schema='resa2', \n",
    "#              if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Estimate nutrient inputs\n",
    "\n",
    "The methodology here is a little unclear. The following is my best guess, based on the files located here:\n",
    "\n",
    "K:\\Avdeling\\Vass\\316_Miljøinformatikk\\Prosjekter\\RID\\2016\\Rådata\\Fiskeoppdrett\n",
    "\n",
    "Old workflow:\n",
    "\n",
    " 1. Calculate the fish biomass from the raw data. See the equation in the `Biomasse` column of the spreadsheet *JSE_TEOTIL_2015.xlsx* <br><br>\n",
    " \n",
    " 2. Split the data according to salmon (\"laks\"; species ID 71101) and trout (\"øret\"; species ID 71401), then group by location and month, summing biomass and `FORFORBRUK_KILO` columns (see Fiskeoppdrett_biomasse_2016.accdb) <br><br>\n",
    " \n",
    " 3. Calculate production. This involves combining biomass for the current month with that for the previous month. See the calculations in e.g. *N_P_ørret_2015.xlsx*. <br><br>\n",
    " \n",
    " 4. Calculate NTAP and PTAP. **NB:** I don't know what these quantities are, so I'm just blindly duplicating the Excel calculations in the code below. The functions are therefore not very well explained <br><br>\n",
    " \n",
    " 5. Estimate copper usage at each fish farm by scaling the total annual Cu usage in proportion to P production. For 2016, John Rune has supplied an annual Cu value of **1088 tonnes** (see e-mail received 12/09/2017 at 09.49)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANLEGG_NR</th>\n",
       "      <th>INP_PAR_ID</th>\n",
       "      <th>AR</th>\n",
       "      <th>MANED</th>\n",
       "      <th>ART</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10041</td>\n",
       "      <td>39</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32509.116284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10050</td>\n",
       "      <td>39</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1399.387617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10054</td>\n",
       "      <td>39</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35261.629175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10078</td>\n",
       "      <td>39</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66272.257234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10080</td>\n",
       "      <td>39</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24954.537391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ANLEGG_NR INP_PAR_ID    AR  MANED  ART         VALUE\n",
       "0      10041         39  2017      6  NaN  32509.116284\n",
       "1      10050         39  2017      6  NaN   1399.387617\n",
       "2      10054         39  2017      6  NaN  35261.629175\n",
       "3      10078         39  2017      6  NaN  66272.257234\n",
       "4      10080         39  2017      6  NaN  24954.537391"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Annual Cu usage in tonnes\n",
    "an_cu = 1088\n",
    "\n",
    "# Estimate nutrient inputs from fish farns\n",
    "fish_nut = rid.estimate_fish_farm_nutrient_inputs(fish_df, year, an_cu)\n",
    "\n",
    "fish_nut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to RESA2.RID_KILDER_AQKULT_VALUES\n",
    "#fish_nut.to_sql('rid_kilder_aqkult_values', con=engine, schema='resa2', \n",
    "#                if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Land use\n",
    "\n",
    "An example of the raw data is here:\n",
    "\n",
    " * K:\\Avdeling\\Vass\\316_Miljøinformatikk\\Prosjekter\\RID\\2016\\Rådata\\Jordbruk\\to-niva.2015.xls\n",
    "\n",
    "Note that this file is not really an Excel file and opening it directly creates errors. I have corrected the data format, tidied the column headings and made a local copy of the 2016 data here:\n",
    "\n",
    " * C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet\\Data\\point_data_2016\\jordbruk_2016.xlsx\n",
    " \n",
    "This is added to the table `RESA2.RID_AGRI_INPUTS`.\n",
    "\n",
    "**Note:** In recent years, the entry for Oslo (fylke_sone = 3_1) has been missing from the data provided by Bioforsk. This row should be added manually to the Excel file using `omrade = \"osl1\"`. The values should be identical to those for område `ake2`. This works because the land areas in `RID_Fylke-Sone_LU_Areas.xlsx` have been made identical for `osl1` and `ake2` (even though this is not correct), so the inputs in terms of kg/km2 are calculated as being the same for both regions, which is what is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year for the data in question\n",
    "year = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>omrade</th>\n",
       "      <th>year</th>\n",
       "      <th>n_diff_kg</th>\n",
       "      <th>n_point_kg</th>\n",
       "      <th>n_back_kg</th>\n",
       "      <th>p_diff_kg</th>\n",
       "      <th>p_point_kg</th>\n",
       "      <th>p_back_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>øst1</td>\n",
       "      <td>2017</td>\n",
       "      <td>717665</td>\n",
       "      <td>8338</td>\n",
       "      <td>157590</td>\n",
       "      <td>41091</td>\n",
       "      <td>674</td>\n",
       "      <td>3563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>øst2</td>\n",
       "      <td>2017</td>\n",
       "      <td>1139830</td>\n",
       "      <td>5451</td>\n",
       "      <td>194922</td>\n",
       "      <td>21855</td>\n",
       "      <td>457</td>\n",
       "      <td>3422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>øst3</td>\n",
       "      <td>2017</td>\n",
       "      <td>214878</td>\n",
       "      <td>1048</td>\n",
       "      <td>39159</td>\n",
       "      <td>5143</td>\n",
       "      <td>90</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ake1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1594487</td>\n",
       "      <td>9164</td>\n",
       "      <td>237631</td>\n",
       "      <td>62668</td>\n",
       "      <td>1470</td>\n",
       "      <td>5554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ake2</td>\n",
       "      <td>2017</td>\n",
       "      <td>719786</td>\n",
       "      <td>1905</td>\n",
       "      <td>117703</td>\n",
       "      <td>21904</td>\n",
       "      <td>245</td>\n",
       "      <td>2221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  omrade  year  n_diff_kg  n_point_kg  n_back_kg  p_diff_kg  p_point_kg  \\\n",
       "0   øst1  2017     717665        8338     157590      41091         674   \n",
       "1   øst2  2017    1139830        5451     194922      21855         457   \n",
       "2   øst3  2017     214878        1048      39159       5143          90   \n",
       "3   ake1  2017    1594487        9164     237631      62668        1470   \n",
       "4   ake2  2017     719786        1905     117703      21904         245   \n",
       "\n",
       "   p_back_kg  \n",
       "0       3563  \n",
       "1       3422  \n",
       "2        759  \n",
       "3       5554  \n",
       "4       2221  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to (tidied) Bioforsk data\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Oeyvind_K\\Elveovervakingsprogrammet'\n",
    "           r'\\Data\\point_data_%s\\jordbruk_%s.xlsx' % (year, year))\n",
    "\n",
    "lu_df = pd.read_excel(in_xlsx)\n",
    "\n",
    "# Add year\n",
    "lu_df['year'] = year\n",
    "\n",
    "# Order cols\n",
    "lu_df = lu_df[['omrade', 'year', 'n_diff_kg', 'n_point_kg', \n",
    "               'n_back_kg', 'p_diff_kg', 'p_point_kg', \n",
    "               'p_back_kg']]\n",
    "\n",
    "lu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to RESA\n",
    "#lu_df.to_sql(name='rid_agri_inputs', con=engine, \n",
    "#             schema='resa2', index=False,\n",
    "#             if_exists='append',\n",
    "#             dtype={'omrade': types.VARCHAR(lu_df['omrade'].str.len().max())})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
